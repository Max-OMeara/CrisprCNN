{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4172d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2171f717c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Import libraries ====\n",
    "import math\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1f4a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "GPU device: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "# ==== Check GPU/CUDA availability ====\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"Training will use CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995c5deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=29452509  val=3681564  test=3681564\n",
      "cells=420  phenotypes=34  chrs=279  strands=3  screentypes=2\n",
      "Target stats: mu=-0.0878, sigma=0.8148\n"
     ]
    }
   ],
   "source": [
    "DATA_CSV = \"data/GenomeCRISPR_+_strands.csv\"\n",
    "SEQ_LEN  = 23\n",
    "VAL_FRAC = 0.10\n",
    "TEST_FRAC= 0.10\n",
    "\n",
    "seq_col   = \"sequence\"\n",
    "cell_col  = \"cellline\"\n",
    "phen_col  = \"condition\"\n",
    "chr_col   = \"chr\"\n",
    "strand_col= \"strand\"\n",
    "screen_col= \"screentype\"\n",
    "target_col= \"log2fc\"\n",
    "\n",
    "# Read & keep only what we need\n",
    "df = pd.read_csv(DATA_CSV, low_memory=False)\n",
    "required_cols = [seq_col, cell_col, phen_col, chr_col, target_col]\n",
    "optional_cols = [strand_col, screen_col]\n",
    "\n",
    "# Check for required columns\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing expected columns: {missing}. Got: {list(df.columns)}\")\n",
    "\n",
    "# Check for optional columns (strand, screentype)\n",
    "has_strand = strand_col in df.columns\n",
    "has_screen = screen_col in df.columns\n",
    "cols_to_keep = required_cols + ([strand_col] if has_strand else []) + ([screen_col] if has_screen else [])\n",
    "\n",
    "df = df[cols_to_keep].copy()\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# Clean sequences: uppercase A/C/G/T and enforce length 23\n",
    "df[seq_col] = df[seq_col].astype(str).str.upper().str.strip()\n",
    "df = df[df[seq_col].str.len() == SEQ_LEN]\n",
    "df = df[df[seq_col].str.match(r\"^[ACGT]+$\")]\n",
    "\n",
    "# Factorize categoricals (one-liners)\n",
    "cell_codes, cell_uniques = pd.factorize(df[cell_col].astype(str).str.strip(), sort=True)\n",
    "phen_codes, phen_uniques = pd.factorize(df[phen_col].astype(str).str.strip(), sort=True)\n",
    "# cast chr to string so 10/11/X/Y are handled uniformly\n",
    "chr_codes,  chr_uniques  = pd.factorize(df[chr_col].astype(str).str.strip(),  sort=True)\n",
    "\n",
    "# Factorize strand if available, otherwise create dummy\n",
    "if has_strand:\n",
    "    strand_codes, strand_uniques = pd.factorize(df[strand_col].astype(str).str.strip(), sort=True)\n",
    "    n_strand = len(strand_uniques)\n",
    "else:\n",
    "    # Create dummy strand codes (all zeros) if not available\n",
    "    strand_codes = np.zeros(len(df), dtype=np.int64)\n",
    "    strand_uniques = np.array([\"+\"] if \"+\" in str(df.get(strand_col, \"+\").iloc[0] if len(df) > 0 else \"+\") else [\"+\"])\n",
    "    n_strand = 1\n",
    "\n",
    "# Factorize screentype if available, otherwise create dummy\n",
    "if has_screen:\n",
    "    screen_codes, screen_uniques = pd.factorize(df[screen_col].astype(str).str.strip(), sort=True)\n",
    "    n_screen = len(screen_uniques)\n",
    "else:\n",
    "    # Create dummy screentype codes (all zeros) if not available\n",
    "    screen_codes = np.zeros(len(df), dtype=np.int64)\n",
    "    screen_uniques = np.array([\"unknown\"])\n",
    "    n_screen = 1\n",
    "\n",
    "n_cell, n_ph, n_chr = len(cell_uniques), len(phen_uniques), len(chr_uniques)\n",
    "\n",
    "# One-hot the 23-mer sequences\n",
    "BASE2IDX = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "def onehot_batch(seqs, L=SEQ_LEN):\n",
    "    N = len(seqs)\n",
    "    X = np.zeros((N, 4, L), dtype=np.float32)\n",
    "    for i, s in enumerate(seqs):\n",
    "        for j, ch in enumerate(s):\n",
    "            X[i, BASE2IDX[ch], j] = 1.0\n",
    "    return X\n",
    "\n",
    "X_seq = onehot_batch(df[seq_col].tolist())\n",
    "X_cell = cell_codes.astype(np.int64)\n",
    "X_ph   = phen_codes.astype(np.int64)\n",
    "X_chr  = chr_codes.astype(np.int64)\n",
    "X_strand = strand_codes.astype(np.int64)\n",
    "X_screen = screen_codes.astype(np.int64)\n",
    "y      = df[target_col].astype(np.float32).to_numpy()\n",
    "\n",
    "# Simple random split\n",
    "idx_all = np.arange(len(df))\n",
    "idx_train, idx_test = train_test_split(idx_all, test_size=TEST_FRAC, random_state=42)\n",
    "idx_train, idx_val  = train_test_split(idx_train, test_size=VAL_FRAC/(1-TEST_FRAC), random_state=42)\n",
    "\n",
    "def take(a, idx): return a[idx]\n",
    "Xtr_seq, Xva_seq, Xte_seq = take(X_seq, idx_train), take(X_seq, idx_val), take(X_seq, idx_test)\n",
    "Xtr_cel, Xva_cel, Xte_cel = take(X_cell, idx_train), take(X_cell, idx_val), take(X_cell, idx_test)\n",
    "Xtr_ph,  Xva_ph,  Xte_ph  = take(X_ph,  idx_train), take(X_ph,  idx_val), take(X_ph,  idx_test)\n",
    "Xtr_chr, Xva_chr, Xte_chr = take(X_chr, idx_train), take(X_chr, idx_val), take(X_chr, idx_test)\n",
    "Xtr_str, Xva_str, Xte_str = take(X_strand, idx_train), take(X_strand, idx_val), take(X_strand, idx_test)\n",
    "Xtr_scr, Xva_scr, Xte_scr = take(X_screen, idx_train), take(X_screen, idx_val), take(X_screen, idx_test)\n",
    "y_tr,    y_va,    y_te    = take(y,     idx_train), take(y,     idx_val), take(y,     idx_test)\n",
    "\n",
    "# Standardize targets using training set statistics\n",
    "mu = y_tr.mean()\n",
    "sigma = y_tr.std()\n",
    "y_tr_norm = (y_tr - mu) / sigma\n",
    "y_va_norm = (y_va - mu) / sigma\n",
    "y_te_norm = (y_te - mu) / sigma\n",
    "\n",
    "# Create full normalized array for easy indexing\n",
    "y_norm = np.zeros_like(y)\n",
    "y_norm[idx_train] = y_tr_norm\n",
    "y_norm[idx_val] = y_va_norm\n",
    "y_norm[idx_test] = y_te_norm\n",
    "\n",
    "print(f\"train={len(idx_train)}  val={len(idx_val)}  test={len(idx_test)}\")\n",
    "print(f\"cells={n_cell}  phenotypes={n_ph}  chrs={n_chr}  strands={n_strand}  screentypes={n_screen}\")\n",
    "print(f\"Target stats: mu={mu:.4f}, sigma={sigma:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "params: 1636641\n"
     ]
    }
   ],
   "source": [
    "class EnhancedCrisprCNN(nn.Module):\n",
    "    def __init__(self, base_channels=64, \n",
    "                 n_cell=420, n_phen=34, n_chr=301, n_strand=2, n_screen=1,\n",
    "                 emb_dim=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv2d_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        self.conv2d_2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels * 2, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        self.conv2d_3_1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        self.conv2d_3_2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.Dropout(dropout * 0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv2d_4 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv_multi1 = nn.Conv2d(base_channels * 2, base_channels, kernel_size=(1, 1))\n",
    "        self.conv_multi2 = nn.Conv2d(base_channels * 2, base_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.conv_multi3 = nn.Conv2d(base_channels * 2, base_channels, kernel_size=(5, 5), padding=(2, 2))\n",
    "        \n",
    "        seq_feat_dim = base_channels * 6\n",
    "    \n",
    "        self.cell_emb = nn.Embedding(n_cell, emb_dim)\n",
    "        self.phen_emb = nn.Embedding(n_phen, emb_dim)\n",
    "        self.chr_emb = nn.Embedding(n_chr, emb_dim)\n",
    "        self.strand_emb = nn.Embedding(n_strand, emb_dim)\n",
    "        self.screen_emb = nn.Embedding(n_screen, emb_dim)\n",
    "        \n",
    "        self.cell_phen_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.cell_chr_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.phen_chr_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.triple_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 3, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.screen_cell_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.screen_phen_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.screen_chr_interaction = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.BatchNorm1d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.4)\n",
    "        )\n",
    "        \n",
    "        self.seq_proj1 = nn.Sequential(\n",
    "            nn.Linear(seq_feat_dim, emb_dim * 2),\n",
    "            nn.BatchNorm1d(emb_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        self.seq_proj2 = nn.Sequential(\n",
    "            nn.Linear(seq_feat_dim, emb_dim * 2),\n",
    "            nn.BatchNorm1d(emb_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        self.seq_proj3 = nn.Sequential(\n",
    "            nn.Linear(seq_feat_dim, emb_dim * 2),\n",
    "            nn.BatchNorm1d(emb_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        interaction_features = emb_dim * 7\n",
    "        total_features = (emb_dim * 6) + (emb_dim * 5) + interaction_features\n",
    "        \n",
    "        self.fusion1 = nn.Sequential(\n",
    "            nn.Linear(total_features, 320),\n",
    "            nn.BatchNorm1d(320),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.fusion2 = nn.Sequential(\n",
    "            nn.Linear(320, 320),\n",
    "            nn.BatchNorm1d(320),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.9)\n",
    "        )\n",
    "        \n",
    "        self.fusion3 = nn.Sequential(\n",
    "            nn.Linear(320, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.8)\n",
    "        )\n",
    "        \n",
    "        self.fusion4 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7)\n",
    "        )\n",
    "        \n",
    "        self.fusion5 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, seq4x23, cell_idx, phen_idx, chr_idx, strand_idx, screen_idx):\n",
    "        x = seq4x23.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv2d_3_1(x)\n",
    "        x = self.conv2d_3_2(x)\n",
    "        x = F.relu(x + residual)\n",
    "        \n",
    "        x = self.conv2d_4(x)\n",
    "        \n",
    "        x1 = self.conv_multi1(x)\n",
    "        x2 = self.conv_multi2(x)\n",
    "        x3 = self.conv_multi3(x)\n",
    "        \n",
    "        x1_avg = F.adaptive_avg_pool2d(x1, 1).squeeze(-1).squeeze(-1)\n",
    "        x1_max = F.adaptive_max_pool2d(x1, 1).squeeze(-1).squeeze(-1)\n",
    "        x2_avg = F.adaptive_avg_pool2d(x2, 1).squeeze(-1).squeeze(-1)\n",
    "        x2_max = F.adaptive_max_pool2d(x2, 1).squeeze(-1).squeeze(-1)\n",
    "        x3_avg = F.adaptive_avg_pool2d(x3, 1).squeeze(-1).squeeze(-1)\n",
    "        x3_max = F.adaptive_max_pool2d(x3, 1).squeeze(-1).squeeze(-1)\n",
    "        \n",
    "        x_seq = torch.cat([x1_avg, x1_max, x2_avg, x2_max, x3_avg, x3_max], dim=1)\n",
    "        \n",
    "        x_seq_proj1 = self.seq_proj1(x_seq)\n",
    "        x_seq_proj2 = self.seq_proj2(x_seq)\n",
    "        x_seq_proj3 = self.seq_proj3(x_seq)\n",
    "        x_seq_proj = torch.cat([x_seq_proj1, x_seq_proj2, x_seq_proj3], dim=1)\n",
    "        \n",
    "        x_cell = self.cell_emb(cell_idx)\n",
    "        x_phen = self.phen_emb(phen_idx)\n",
    "        x_chr = self.chr_emb(chr_idx)\n",
    "        x_strand = self.strand_emb(strand_idx)\n",
    "        x_screen = self.screen_emb(screen_idx)\n",
    "        \n",
    "        cell_phen_inter = self.cell_phen_interaction(torch.cat([x_cell, x_phen], dim=1))\n",
    "        cell_chr_inter = self.cell_chr_interaction(torch.cat([x_cell, x_chr], dim=1))\n",
    "        phen_chr_inter = self.phen_chr_interaction(torch.cat([x_phen, x_chr], dim=1))\n",
    "        triple_inter = self.triple_interaction(torch.cat([x_cell, x_phen, x_chr], dim=1))\n",
    "        screen_cell_inter = self.screen_cell_interaction(torch.cat([x_screen, x_cell], dim=1))\n",
    "        screen_phen_inter = self.screen_phen_interaction(torch.cat([x_screen, x_phen], dim=1))\n",
    "        screen_chr_inter = self.screen_chr_interaction(torch.cat([x_screen, x_chr], dim=1))\n",
    "        \n",
    "        x = torch.cat([\n",
    "            x_seq_proj,\n",
    "            x_cell, x_phen, x_chr, x_strand, x_screen,\n",
    "            cell_phen_inter, cell_chr_inter, phen_chr_inter, triple_inter, screen_cell_inter, screen_phen_inter, screen_chr_inter\n",
    "        ], dim=1)\n",
    "        \n",
    "        x = self.fusion1(x)\n",
    "        x = self.fusion2(x) + x\n",
    "        x = self.fusion3(x)\n",
    "        x = self.fusion4(x)\n",
    "        x = self.fusion5(x)\n",
    "        \n",
    "        return self.head(x).squeeze(-1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = EnhancedCrisprCNN(\n",
    "    base_channels=64,\n",
    "    n_cell=n_cell, n_phen=n_ph, n_chr=n_chr, n_strand=n_strand, n_screen=n_screen,\n",
    "    emb_dim=36,\n",
    "    dropout=0.35\n",
    ").to(device)\n",
    "print(\"params:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9aecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 01/5\n",
      "============================================================\n",
      "  Train: [  100/57525] (  0.2%) | Loss: 1.0259 | Speed: 27.5 batches/s | ETA: 34:49\n",
      "  Train: [  200/57525] (  0.3%) | Loss: 1.0036 | Speed: 33.5 batches/s | ETA: 28:29\n",
      "  Train: [  300/57525] (  0.5%) | Loss: 1.0017 | Speed: 36.2 batches/s | ETA: 26:20\n",
      "  Train: [  400/57525] (  0.7%) | Loss: 0.9966 | Speed: 37.7 batches/s | ETA: 25:13\n",
      "  Train: [  500/57525] (  0.9%) | Loss: 0.9978 | Speed: 38.8 batches/s | ETA: 24:28\n",
      "  Train: [  600/57525] (  1.0%) | Loss: 0.9895 | Speed: 39.6 batches/s | ETA: 23:57\n",
      "  Train: [  700/57525] (  1.2%) | Loss: 0.9822 | Speed: 40.2 batches/s | ETA: 23:31\n",
      "  Train: [  800/57525] (  1.4%) | Loss: 0.9775 | Speed: 40.7 batches/s | ETA: 23:12\n",
      "  Train: [  900/57525] (  1.6%) | Loss: 0.9731 | Speed: 41.2 batches/s | ETA: 22:55\n",
      "  Train: [ 1000/57525] (  1.7%) | Loss: 0.9689 | Speed: 41.5 batches/s | ETA: 22:41\n",
      "  Train: [ 1100/57525] (  1.9%) | Loss: 0.9664 | Speed: 41.8 batches/s | ETA: 22:29\n",
      "  Train: [ 1200/57525] (  2.1%) | Loss: 0.9654 | Speed: 42.0 batches/s | ETA: 22:20\n",
      "  Train: [ 1300/57525] (  2.3%) | Loss: 0.9623 | Speed: 42.2 batches/s | ETA: 22:11\n",
      "  Train: [ 1400/57525] (  2.4%) | Loss: 0.9590 | Speed: 42.4 batches/s | ETA: 22:04\n",
      "  Train: [ 1500/57525] (  2.6%) | Loss: 0.9583 | Speed: 42.5 batches/s | ETA: 21:58\n",
      "  Train: [ 1600/57525] (  2.8%) | Loss: 0.9567 | Speed: 42.6 batches/s | ETA: 21:51\n",
      "  Train: [ 1700/57525] (  3.0%) | Loss: 0.9554 | Speed: 42.7 batches/s | ETA: 21:46\n",
      "  Train: [ 1800/57525] (  3.1%) | Loss: 0.9547 | Speed: 42.8 batches/s | ETA: 21:42\n",
      "  Train: [ 1900/57525] (  3.3%) | Loss: 0.9526 | Speed: 42.9 batches/s | ETA: 21:38\n",
      "  Train: [ 2000/57525] (  3.5%) | Loss: 0.9496 | Speed: 42.9 batches/s | ETA: 21:33\n",
      "  Train: [ 2100/57525] (  3.7%) | Loss: 0.9481 | Speed: 43.0 batches/s | ETA: 21:29\n",
      "  Train: [ 2200/57525] (  3.8%) | Loss: 0.9471 | Speed: 43.0 batches/s | ETA: 21:25\n",
      "  Train: [ 2300/57525] (  4.0%) | Loss: 0.9460 | Speed: 43.1 batches/s | ETA: 21:21\n",
      "  Train: [ 2400/57525] (  4.2%) | Loss: 0.9440 | Speed: 43.2 batches/s | ETA: 21:17\n",
      "  Train: [ 2500/57525] (  4.3%) | Loss: 0.9411 | Speed: 43.2 batches/s | ETA: 21:13\n",
      "  Train: [ 2600/57525] (  4.5%) | Loss: 0.9392 | Speed: 43.3 batches/s | ETA: 21:09\n",
      "  Train: [ 2700/57525] (  4.7%) | Loss: 0.9381 | Speed: 43.3 batches/s | ETA: 21:05\n",
      "  Train: [ 2800/57525] (  4.9%) | Loss: 0.9370 | Speed: 43.4 batches/s | ETA: 21:01\n",
      "  Train: [ 2900/57525] (  5.0%) | Loss: 0.9351 | Speed: 43.4 batches/s | ETA: 20:58\n",
      "  Train: [ 3000/57525] (  5.2%) | Loss: 0.9346 | Speed: 43.5 batches/s | ETA: 20:54\n",
      "  Train: [ 3100/57525] (  5.4%) | Loss: 0.9342 | Speed: 43.5 batches/s | ETA: 20:51\n",
      "  Train: [ 3200/57525] (  5.6%) | Loss: 0.9330 | Speed: 43.5 batches/s | ETA: 20:48\n",
      "  Train: [ 3300/57525] (  5.7%) | Loss: 0.9312 | Speed: 43.5 batches/s | ETA: 20:45\n",
      "  Train: [ 3400/57525] (  5.9%) | Loss: 0.9303 | Speed: 43.6 batches/s | ETA: 20:42\n",
      "  Train: [ 3500/57525] (  6.1%) | Loss: 0.9296 | Speed: 43.6 batches/s | ETA: 20:39\n",
      "  Train: [ 3600/57525] (  6.3%) | Loss: 0.9292 | Speed: 43.6 batches/s | ETA: 20:36\n",
      "  Train: [ 3700/57525] (  6.4%) | Loss: 0.9280 | Speed: 43.6 batches/s | ETA: 20:33\n",
      "  Train: [ 3800/57525] (  6.6%) | Loss: 0.9276 | Speed: 43.7 batches/s | ETA: 20:30\n",
      "  Train: [ 3900/57525] (  6.8%) | Loss: 0.9262 | Speed: 43.7 batches/s | ETA: 20:27\n",
      "  Train: [ 4000/57525] (  7.0%) | Loss: 0.9248 | Speed: 43.7 batches/s | ETA: 20:24\n",
      "  Train: [ 4100/57525] (  7.1%) | Loss: 0.9233 | Speed: 43.7 batches/s | ETA: 20:21\n",
      "  Train: [ 4200/57525] (  7.3%) | Loss: 0.9228 | Speed: 43.8 batches/s | ETA: 20:18\n",
      "  Train: [ 4300/57525] (  7.5%) | Loss: 0.9218 | Speed: 43.8 batches/s | ETA: 20:15\n",
      "  Train: [ 4400/57525] (  7.6%) | Loss: 0.9206 | Speed: 43.8 batches/s | ETA: 20:12\n",
      "  Train: [ 4500/57525] (  7.8%) | Loss: 0.9204 | Speed: 43.8 batches/s | ETA: 20:10\n",
      "  Train: [ 4600/57525] (  8.0%) | Loss: 0.9193 | Speed: 43.8 batches/s | ETA: 20:07\n",
      "  Train: [ 4700/57525] (  8.2%) | Loss: 0.9187 | Speed: 43.9 batches/s | ETA: 20:04\n",
      "  Train: [ 4800/57525] (  8.3%) | Loss: 0.9175 | Speed: 43.9 batches/s | ETA: 20:01\n",
      "  Train: [ 4900/57525] (  8.5%) | Loss: 0.9159 | Speed: 43.9 batches/s | ETA: 19:59\n",
      "  Train: [ 5000/57525] (  8.7%) | Loss: 0.9153 | Speed: 43.9 batches/s | ETA: 19:56\n",
      "  Train: [ 5100/57525] (  8.9%) | Loss: 0.9144 | Speed: 43.9 batches/s | ETA: 19:53\n",
      "  Train: [ 5200/57525] (  9.0%) | Loss: 0.9130 | Speed: 43.9 batches/s | ETA: 19:51\n",
      "  Train: [ 5300/57525] (  9.2%) | Loss: 0.9121 | Speed: 43.9 batches/s | ETA: 19:48\n",
      "  Train: [ 5400/57525] (  9.4%) | Loss: 0.9114 | Speed: 43.9 batches/s | ETA: 19:46\n",
      "  Train: [ 5500/57525] (  9.6%) | Loss: 0.9103 | Speed: 44.0 batches/s | ETA: 19:43\n",
      "  Train: [ 5600/57525] (  9.7%) | Loss: 0.9087 | Speed: 44.0 batches/s | ETA: 19:41\n",
      "  Train: [ 5700/57525] (  9.9%) | Loss: 0.9072 | Speed: 44.0 batches/s | ETA: 19:38\n",
      "  Train: [ 5800/57525] ( 10.1%) | Loss: 0.9064 | Speed: 44.0 batches/s | ETA: 19:35\n",
      "  Train: [ 5900/57525] ( 10.3%) | Loss: 0.9055 | Speed: 44.0 batches/s | ETA: 19:33\n",
      "  Train: [ 6000/57525] ( 10.4%) | Loss: 0.9046 | Speed: 44.0 batches/s | ETA: 19:30\n",
      "  Train: [ 6100/57525] ( 10.6%) | Loss: 0.9036 | Speed: 44.0 batches/s | ETA: 19:27\n",
      "  Train: [ 6200/57525] ( 10.8%) | Loss: 0.9031 | Speed: 44.0 batches/s | ETA: 19:25\n",
      "  Train: [ 6300/57525] ( 11.0%) | Loss: 0.9019 | Speed: 44.1 batches/s | ETA: 19:22\n",
      "  Train: [ 6400/57525] ( 11.1%) | Loss: 0.9015 | Speed: 44.1 batches/s | ETA: 19:20\n",
      "  Train: [ 6500/57525] ( 11.3%) | Loss: 0.9007 | Speed: 44.1 batches/s | ETA: 19:17\n",
      "  Train: [ 6600/57525] ( 11.5%) | Loss: 0.8998 | Speed: 44.1 batches/s | ETA: 19:15\n",
      "  Train: [ 6700/57525] ( 11.6%) | Loss: 0.8992 | Speed: 44.1 batches/s | ETA: 19:13\n",
      "  Train: [ 6800/57525] ( 11.8%) | Loss: 0.8980 | Speed: 44.1 batches/s | ETA: 19:10\n",
      "  Train: [ 6900/57525] ( 12.0%) | Loss: 0.8970 | Speed: 44.1 batches/s | ETA: 19:08\n",
      "  Train: [ 7000/57525] ( 12.2%) | Loss: 0.8965 | Speed: 44.1 batches/s | ETA: 19:05\n",
      "  Train: [ 7100/57525] ( 12.3%) | Loss: 0.8954 | Speed: 44.1 batches/s | ETA: 19:03\n",
      "  Train: [ 7200/57525] ( 12.5%) | Loss: 0.8948 | Speed: 44.1 batches/s | ETA: 19:00\n",
      "  Train: [ 7300/57525] ( 12.7%) | Loss: 0.8935 | Speed: 44.1 batches/s | ETA: 18:58\n",
      "  Train: [ 7400/57525] ( 12.9%) | Loss: 0.8928 | Speed: 44.1 batches/s | ETA: 18:55\n",
      "  Train: [ 7500/57525] ( 13.0%) | Loss: 0.8918 | Speed: 44.1 batches/s | ETA: 18:53\n",
      "  Train: [ 7600/57525] ( 13.2%) | Loss: 0.8912 | Speed: 44.1 batches/s | ETA: 18:50\n",
      "  Train: [ 7700/57525] ( 13.4%) | Loss: 0.8900 | Speed: 44.2 batches/s | ETA: 18:48\n",
      "  Train: [ 7800/57525] ( 13.6%) | Loss: 0.8894 | Speed: 44.2 batches/s | ETA: 18:45\n",
      "  Train: [ 7900/57525] ( 13.7%) | Loss: 0.8884 | Speed: 44.2 batches/s | ETA: 18:43\n",
      "  Train: [ 8000/57525] ( 13.9%) | Loss: 0.8873 | Speed: 44.2 batches/s | ETA: 18:41\n",
      "  Train: [ 8100/57525] ( 14.1%) | Loss: 0.8863 | Speed: 44.2 batches/s | ETA: 18:38\n",
      "  Train: [ 8200/57525] ( 14.3%) | Loss: 0.8859 | Speed: 44.2 batches/s | ETA: 18:36\n",
      "  Train: [ 8300/57525] ( 14.4%) | Loss: 0.8851 | Speed: 44.2 batches/s | ETA: 18:34\n",
      "  Train: [ 8400/57525] ( 14.6%) | Loss: 0.8844 | Speed: 44.2 batches/s | ETA: 18:31\n",
      "  Train: [ 8500/57525] ( 14.8%) | Loss: 0.8838 | Speed: 44.2 batches/s | ETA: 18:29\n",
      "  Train: [ 8600/57525] ( 15.0%) | Loss: 0.8832 | Speed: 44.2 batches/s | ETA: 18:27\n",
      "  Train: [ 8700/57525] ( 15.1%) | Loss: 0.8822 | Speed: 44.2 batches/s | ETA: 18:24\n",
      "  Train: [ 8800/57525] ( 15.3%) | Loss: 0.8811 | Speed: 44.2 batches/s | ETA: 18:22\n",
      "  Train: [ 8900/57525] ( 15.5%) | Loss: 0.8804 | Speed: 44.2 batches/s | ETA: 18:19\n",
      "  Train: [ 9000/57525] ( 15.6%) | Loss: 0.8796 | Speed: 44.2 batches/s | ETA: 18:17\n",
      "  Train: [ 9100/57525] ( 15.8%) | Loss: 0.8788 | Speed: 44.2 batches/s | ETA: 18:14\n",
      "  Train: [ 9200/57525] ( 16.0%) | Loss: 0.8779 | Speed: 44.2 batches/s | ETA: 18:12\n",
      "  Train: [ 9300/57525] ( 16.2%) | Loss: 0.8773 | Speed: 44.2 batches/s | ETA: 18:10\n",
      "  Train: [ 9400/57525] ( 16.3%) | Loss: 0.8766 | Speed: 44.2 batches/s | ETA: 18:07\n",
      "  Train: [ 9500/57525] ( 16.5%) | Loss: 0.8759 | Speed: 44.2 batches/s | ETA: 18:05\n",
      "  Train: [ 9600/57525] ( 16.7%) | Loss: 0.8752 | Speed: 44.2 batches/s | ETA: 18:03\n",
      "  Train: [ 9700/57525] ( 16.9%) | Loss: 0.8744 | Speed: 44.2 batches/s | ETA: 18:00\n",
      "  Train: [ 9800/57525] ( 17.0%) | Loss: 0.8735 | Speed: 44.2 batches/s | ETA: 17:58\n",
      "  Train: [ 9900/57525] ( 17.2%) | Loss: 0.8730 | Speed: 44.2 batches/s | ETA: 17:56\n",
      "  Train: [10000/57525] ( 17.4%) | Loss: 0.8722 | Speed: 44.3 batches/s | ETA: 17:53\n",
      "  Train: [10100/57525] ( 17.6%) | Loss: 0.8711 | Speed: 44.3 batches/s | ETA: 17:51\n",
      "  Train: [10200/57525] ( 17.7%) | Loss: 0.8705 | Speed: 44.3 batches/s | ETA: 17:49\n",
      "  Train: [10300/57525] ( 17.9%) | Loss: 0.8696 | Speed: 44.3 batches/s | ETA: 17:46\n",
      "  Train: [10400/57525] ( 18.1%) | Loss: 0.8687 | Speed: 44.3 batches/s | ETA: 17:44\n",
      "  Train: [10500/57525] ( 18.3%) | Loss: 0.8680 | Speed: 44.3 batches/s | ETA: 17:42\n",
      "  Train: [10600/57525] ( 18.4%) | Loss: 0.8673 | Speed: 44.3 batches/s | ETA: 17:39\n",
      "  Train: [10700/57525] ( 18.6%) | Loss: 0.8665 | Speed: 44.3 batches/s | ETA: 17:37\n",
      "  Train: [10800/57525] ( 18.8%) | Loss: 0.8658 | Speed: 44.3 batches/s | ETA: 17:35\n",
      "  Train: [10900/57525] ( 18.9%) | Loss: 0.8651 | Speed: 44.3 batches/s | ETA: 17:32\n",
      "  Train: [11000/57525] ( 19.1%) | Loss: 0.8645 | Speed: 44.3 batches/s | ETA: 17:30\n",
      "  Train: [11100/57525] ( 19.3%) | Loss: 0.8640 | Speed: 44.3 batches/s | ETA: 17:28\n",
      "  Train: [11200/57525] ( 19.5%) | Loss: 0.8634 | Speed: 44.3 batches/s | ETA: 17:25\n",
      "  Train: [11300/57525] ( 19.6%) | Loss: 0.8628 | Speed: 44.3 batches/s | ETA: 17:23\n",
      "  Train: [11400/57525] ( 19.8%) | Loss: 0.8621 | Speed: 44.3 batches/s | ETA: 17:21\n",
      "  Train: [11500/57525] ( 20.0%) | Loss: 0.8611 | Speed: 44.3 batches/s | ETA: 17:18\n",
      "  Train: [11600/57525] ( 20.2%) | Loss: 0.8605 | Speed: 44.3 batches/s | ETA: 17:16\n",
      "  Train: [11700/57525] ( 20.3%) | Loss: 0.8597 | Speed: 44.3 batches/s | ETA: 17:14\n",
      "  Train: [11800/57525] ( 20.5%) | Loss: 0.8589 | Speed: 44.3 batches/s | ETA: 17:11\n",
      "  Train: [11900/57525] ( 20.7%) | Loss: 0.8581 | Speed: 44.3 batches/s | ETA: 17:09\n",
      "  Train: [12000/57525] ( 20.9%) | Loss: 0.8573 | Speed: 44.3 batches/s | ETA: 17:07\n",
      "  Train: [12100/57525] ( 21.0%) | Loss: 0.8565 | Speed: 44.3 batches/s | ETA: 17:04\n",
      "  Train: [12200/57525] ( 21.2%) | Loss: 0.8557 | Speed: 44.3 batches/s | ETA: 17:02\n",
      "  Train: [12300/57525] ( 21.4%) | Loss: 0.8551 | Speed: 44.3 batches/s | ETA: 17:00\n",
      "  Train: [12400/57525] ( 21.6%) | Loss: 0.8542 | Speed: 44.3 batches/s | ETA: 16:57\n",
      "  Train: [12500/57525] ( 21.7%) | Loss: 0.8535 | Speed: 44.3 batches/s | ETA: 16:55\n",
      "  Train: [12600/57525] ( 21.9%) | Loss: 0.8527 | Speed: 44.3 batches/s | ETA: 16:53\n",
      "  Train: [12700/57525] ( 22.1%) | Loss: 0.8521 | Speed: 44.3 batches/s | ETA: 16:51\n",
      "  Train: [12800/57525] ( 22.3%) | Loss: 0.8514 | Speed: 44.3 batches/s | ETA: 16:48\n",
      "  Train: [12900/57525] ( 22.4%) | Loss: 0.8507 | Speed: 44.3 batches/s | ETA: 16:46\n",
      "  Train: [13000/57525] ( 22.6%) | Loss: 0.8501 | Speed: 44.3 batches/s | ETA: 16:44\n",
      "  Train: [13100/57525] ( 22.8%) | Loss: 0.8494 | Speed: 44.3 batches/s | ETA: 16:42\n",
      "  Train: [13200/57525] ( 22.9%) | Loss: 0.8487 | Speed: 44.3 batches/s | ETA: 16:39\n",
      "  Train: [13300/57525] ( 23.1%) | Loss: 0.8481 | Speed: 44.3 batches/s | ETA: 16:37\n",
      "  Train: [13400/57525] ( 23.3%) | Loss: 0.8474 | Speed: 44.3 batches/s | ETA: 16:35\n",
      "  Train: [13500/57525] ( 23.5%) | Loss: 0.8470 | Speed: 44.3 batches/s | ETA: 16:32\n",
      "  Train: [13600/57525] ( 23.6%) | Loss: 0.8464 | Speed: 44.3 batches/s | ETA: 16:30\n",
      "  Train: [13700/57525] ( 23.8%) | Loss: 0.8456 | Speed: 44.3 batches/s | ETA: 16:28\n",
      "  Train: [13800/57525] ( 24.0%) | Loss: 0.8449 | Speed: 44.3 batches/s | ETA: 16:25\n",
      "  Train: [13900/57525] ( 24.2%) | Loss: 0.8443 | Speed: 44.4 batches/s | ETA: 16:23\n",
      "  Train: [14000/57525] ( 24.3%) | Loss: 0.8435 | Speed: 44.4 batches/s | ETA: 16:21\n",
      "  Train: [14100/57525] ( 24.5%) | Loss: 0.8429 | Speed: 44.4 batches/s | ETA: 16:18\n",
      "  Train: [14200/57525] ( 24.7%) | Loss: 0.8423 | Speed: 44.4 batches/s | ETA: 16:16\n",
      "  Train: [14300/57525] ( 24.9%) | Loss: 0.8418 | Speed: 44.4 batches/s | ETA: 16:14\n",
      "  Train: [14400/57525] ( 25.0%) | Loss: 0.8413 | Speed: 44.4 batches/s | ETA: 16:12\n",
      "  Train: [14500/57525] ( 25.2%) | Loss: 0.8408 | Speed: 44.4 batches/s | ETA: 16:09\n",
      "  Train: [14600/57525] ( 25.4%) | Loss: 0.8404 | Speed: 44.4 batches/s | ETA: 16:07\n",
      "  Train: [14700/57525] ( 25.6%) | Loss: 0.8397 | Speed: 44.4 batches/s | ETA: 16:05\n",
      "  Train: [14800/57525] ( 25.7%) | Loss: 0.8391 | Speed: 44.4 batches/s | ETA: 16:03\n",
      "  Train: [14900/57525] ( 25.9%) | Loss: 0.8385 | Speed: 44.4 batches/s | ETA: 16:00\n",
      "  Train: [15000/57525] ( 26.1%) | Loss: 0.8379 | Speed: 44.4 batches/s | ETA: 15:58\n",
      "  Train: [15100/57525] ( 26.2%) | Loss: 0.8374 | Speed: 44.4 batches/s | ETA: 15:56\n",
      "  Train: [15200/57525] ( 26.4%) | Loss: 0.8367 | Speed: 44.4 batches/s | ETA: 15:53\n",
      "  Train: [15300/57525] ( 26.6%) | Loss: 0.8362 | Speed: 44.4 batches/s | ETA: 15:51\n",
      "  Train: [15400/57525] ( 26.8%) | Loss: 0.8354 | Speed: 44.4 batches/s | ETA: 15:49\n",
      "  Train: [15500/57525] ( 26.9%) | Loss: 0.8350 | Speed: 44.4 batches/s | ETA: 15:46\n",
      "  Train: [15600/57525] ( 27.1%) | Loss: 0.8344 | Speed: 44.4 batches/s | ETA: 15:44\n",
      "  Train: [15700/57525] ( 27.3%) | Loss: 0.8338 | Speed: 44.4 batches/s | ETA: 15:42\n",
      "  Train: [15800/57525] ( 27.5%) | Loss: 0.8332 | Speed: 44.4 batches/s | ETA: 15:40\n",
      "  Train: [15900/57525] ( 27.6%) | Loss: 0.8327 | Speed: 44.4 batches/s | ETA: 15:37\n",
      "  Train: [16000/57525] ( 27.8%) | Loss: 0.8321 | Speed: 44.4 batches/s | ETA: 15:35\n",
      "  Train: [16100/57525] ( 28.0%) | Loss: 0.8315 | Speed: 44.4 batches/s | ETA: 15:33\n",
      "  Train: [16200/57525] ( 28.2%) | Loss: 0.8309 | Speed: 44.4 batches/s | ETA: 15:31\n",
      "  Train: [16300/57525] ( 28.3%) | Loss: 0.8304 | Speed: 44.4 batches/s | ETA: 15:28\n",
      "  Train: [16400/57525] ( 28.5%) | Loss: 0.8299 | Speed: 44.4 batches/s | ETA: 15:26\n",
      "  Train: [16500/57525] ( 28.7%) | Loss: 0.8294 | Speed: 44.4 batches/s | ETA: 15:24\n",
      "  Train: [16600/57525] ( 28.9%) | Loss: 0.8289 | Speed: 44.4 batches/s | ETA: 15:21\n",
      "  Train: [16700/57525] ( 29.0%) | Loss: 0.8284 | Speed: 44.4 batches/s | ETA: 15:19\n",
      "  Train: [16800/57525] ( 29.2%) | Loss: 0.8278 | Speed: 44.4 batches/s | ETA: 15:17\n",
      "  Train: [16900/57525] ( 29.4%) | Loss: 0.8273 | Speed: 44.4 batches/s | ETA: 15:15\n",
      "  Train: [17000/57525] ( 29.6%) | Loss: 0.8267 | Speed: 44.4 batches/s | ETA: 15:12\n",
      "  Train: [17100/57525] ( 29.7%) | Loss: 0.8263 | Speed: 44.4 batches/s | ETA: 15:10\n",
      "  Train: [17200/57525] ( 29.9%) | Loss: 0.8258 | Speed: 44.4 batches/s | ETA: 15:08\n",
      "  Train: [17300/57525] ( 30.1%) | Loss: 0.8256 | Speed: 44.4 batches/s | ETA: 15:05\n",
      "  Train: [17400/57525] ( 30.2%) | Loss: 0.8251 | Speed: 44.4 batches/s | ETA: 15:03\n",
      "  Train: [17500/57525] ( 30.4%) | Loss: 0.8247 | Speed: 44.4 batches/s | ETA: 15:01\n",
      "  Train: [17600/57525] ( 30.6%) | Loss: 0.8241 | Speed: 44.4 batches/s | ETA: 14:58\n",
      "  Train: [17700/57525] ( 30.8%) | Loss: 0.8234 | Speed: 44.4 batches/s | ETA: 14:56\n",
      "  Train: [17800/57525] ( 30.9%) | Loss: 0.8229 | Speed: 44.4 batches/s | ETA: 14:54\n",
      "  Train: [17900/57525] ( 31.1%) | Loss: 0.8223 | Speed: 44.4 batches/s | ETA: 14:52\n",
      "  Train: [18000/57525] ( 31.3%) | Loss: 0.8217 | Speed: 44.4 batches/s | ETA: 14:49\n",
      "  Train: [18100/57525] ( 31.5%) | Loss: 0.8212 | Speed: 44.4 batches/s | ETA: 14:47\n",
      "  Train: [18200/57525] ( 31.6%) | Loss: 0.8208 | Speed: 44.4 batches/s | ETA: 14:45\n",
      "  Train: [18300/57525] ( 31.8%) | Loss: 0.8200 | Speed: 44.4 batches/s | ETA: 14:43\n",
      "  Train: [18400/57525] ( 32.0%) | Loss: 0.8194 | Speed: 44.4 batches/s | ETA: 14:40\n",
      "  Train: [18500/57525] ( 32.2%) | Loss: 0.8190 | Speed: 44.4 batches/s | ETA: 14:38\n",
      "  Train: [18600/57525] ( 32.3%) | Loss: 0.8186 | Speed: 44.4 batches/s | ETA: 14:36\n",
      "  Train: [18700/57525] ( 32.5%) | Loss: 0.8180 | Speed: 44.4 batches/s | ETA: 14:33\n",
      "  Train: [18800/57525] ( 32.7%) | Loss: 0.8175 | Speed: 44.4 batches/s | ETA: 14:31\n",
      "  Train: [18900/57525] ( 32.9%) | Loss: 0.8170 | Speed: 44.4 batches/s | ETA: 14:29\n",
      "  Train: [19000/57525] ( 33.0%) | Loss: 0.8166 | Speed: 44.4 batches/s | ETA: 14:27\n",
      "  Train: [19100/57525] ( 33.2%) | Loss: 0.8162 | Speed: 44.4 batches/s | ETA: 14:24\n",
      "  Train: [19200/57525] ( 33.4%) | Loss: 0.8156 | Speed: 44.4 batches/s | ETA: 14:22\n",
      "  Train: [19300/57525] ( 33.6%) | Loss: 0.8152 | Speed: 44.4 batches/s | ETA: 14:20\n",
      "  Train: [19400/57525] ( 33.7%) | Loss: 0.8147 | Speed: 44.4 batches/s | ETA: 14:18\n",
      "  Train: [19500/57525] ( 33.9%) | Loss: 0.8143 | Speed: 44.4 batches/s | ETA: 14:15\n",
      "  Train: [19600/57525] ( 34.1%) | Loss: 0.8139 | Speed: 44.4 batches/s | ETA: 14:13\n",
      "  Train: [19700/57525] ( 34.2%) | Loss: 0.8134 | Speed: 44.4 batches/s | ETA: 14:11\n",
      "  Train: [19800/57525] ( 34.4%) | Loss: 0.8129 | Speed: 44.4 batches/s | ETA: 14:09\n",
      "  Train: [19900/57525] ( 34.6%) | Loss: 0.8124 | Speed: 44.4 batches/s | ETA: 14:06\n",
      "  Train: [20000/57525] ( 34.8%) | Loss: 0.8120 | Speed: 44.4 batches/s | ETA: 14:04\n",
      "  Train: [20100/57525] ( 34.9%) | Loss: 0.8115 | Speed: 44.4 batches/s | ETA: 14:02\n",
      "  Train: [20200/57525] ( 35.1%) | Loss: 0.8111 | Speed: 44.4 batches/s | ETA: 13:59\n",
      "  Train: [20300/57525] ( 35.3%) | Loss: 0.8107 | Speed: 44.4 batches/s | ETA: 13:57\n",
      "  Train: [20400/57525] ( 35.5%) | Loss: 0.8103 | Speed: 44.4 batches/s | ETA: 13:55\n",
      "  Train: [20500/57525] ( 35.6%) | Loss: 0.8098 | Speed: 44.4 batches/s | ETA: 13:53\n",
      "  Train: [20600/57525] ( 35.8%) | Loss: 0.8093 | Speed: 44.4 batches/s | ETA: 13:50\n",
      "  Train: [20700/57525] ( 36.0%) | Loss: 0.8089 | Speed: 44.4 batches/s | ETA: 13:48\n",
      "  Train: [20800/57525] ( 36.2%) | Loss: 0.8085 | Speed: 44.4 batches/s | ETA: 13:46\n",
      "  Train: [20900/57525] ( 36.3%) | Loss: 0.8080 | Speed: 44.4 batches/s | ETA: 13:44\n",
      "  Train: [21000/57525] ( 36.5%) | Loss: 0.8075 | Speed: 44.4 batches/s | ETA: 13:41\n",
      "  Train: [21100/57525] ( 36.7%) | Loss: 0.8072 | Speed: 44.4 batches/s | ETA: 13:39\n",
      "  Train: [21200/57525] ( 36.9%) | Loss: 0.8069 | Speed: 44.4 batches/s | ETA: 13:37\n",
      "  Train: [21300/57525] ( 37.0%) | Loss: 0.8065 | Speed: 44.4 batches/s | ETA: 13:35\n",
      "  Train: [21400/57525] ( 37.2%) | Loss: 0.8060 | Speed: 44.4 batches/s | ETA: 13:32\n",
      "  Train: [21500/57525] ( 37.4%) | Loss: 0.8056 | Speed: 44.4 batches/s | ETA: 13:30\n",
      "  Train: [21600/57525] ( 37.5%) | Loss: 0.8052 | Speed: 44.4 batches/s | ETA: 13:28\n",
      "  Train: [21700/57525] ( 37.7%) | Loss: 0.8049 | Speed: 44.4 batches/s | ETA: 13:25\n",
      "  Train: [21800/57525] ( 37.9%) | Loss: 0.8044 | Speed: 44.4 batches/s | ETA: 13:23\n",
      "  Train: [21900/57525] ( 38.1%) | Loss: 0.8041 | Speed: 44.4 batches/s | ETA: 13:21\n",
      "  Train: [22000/57525] ( 38.2%) | Loss: 0.8038 | Speed: 44.5 batches/s | ETA: 13:19\n",
      "  Train: [22100/57525] ( 38.4%) | Loss: 0.8032 | Speed: 44.5 batches/s | ETA: 13:16\n",
      "  Train: [22200/57525] ( 38.6%) | Loss: 0.8028 | Speed: 44.5 batches/s | ETA: 13:14\n",
      "  Train: [22300/57525] ( 38.8%) | Loss: 0.8023 | Speed: 44.5 batches/s | ETA: 13:12\n",
      "  Train: [22400/57525] ( 38.9%) | Loss: 0.8019 | Speed: 44.5 batches/s | ETA: 13:10\n",
      "  Train: [22500/57525] ( 39.1%) | Loss: 0.8014 | Speed: 44.5 batches/s | ETA: 13:07\n",
      "  Train: [22600/57525] ( 39.3%) | Loss: 0.8010 | Speed: 44.5 batches/s | ETA: 13:05\n",
      "  Train: [22700/57525] ( 39.5%) | Loss: 0.8005 | Speed: 44.5 batches/s | ETA: 13:03\n",
      "  Train: [22800/57525] ( 39.6%) | Loss: 0.8000 | Speed: 44.5 batches/s | ETA: 13:01\n",
      "  Train: [22900/57525] ( 39.8%) | Loss: 0.7995 | Speed: 44.5 batches/s | ETA: 12:58\n",
      "  Train: [23000/57525] ( 40.0%) | Loss: 0.7992 | Speed: 44.5 batches/s | ETA: 12:56\n",
      "  Train: [23100/57525] ( 40.2%) | Loss: 0.7988 | Speed: 44.5 batches/s | ETA: 12:54\n",
      "  Train: [23200/57525] ( 40.3%) | Loss: 0.7984 | Speed: 44.5 batches/s | ETA: 12:52\n",
      "  Train: [23300/57525] ( 40.5%) | Loss: 0.7981 | Speed: 44.5 batches/s | ETA: 12:49\n",
      "  Train: [23400/57525] ( 40.7%) | Loss: 0.7977 | Speed: 44.5 batches/s | ETA: 12:47\n",
      "  Train: [23500/57525] ( 40.9%) | Loss: 0.7974 | Speed: 44.5 batches/s | ETA: 12:45\n",
      "  Train: [23600/57525] ( 41.0%) | Loss: 0.7969 | Speed: 44.5 batches/s | ETA: 12:43\n",
      "  Train: [23700/57525] ( 41.2%) | Loss: 0.7964 | Speed: 44.5 batches/s | ETA: 12:40\n",
      "  Train: [23800/57525] ( 41.4%) | Loss: 0.7959 | Speed: 44.5 batches/s | ETA: 12:38\n",
      "  Train: [23900/57525] ( 41.5%) | Loss: 0.7955 | Speed: 44.5 batches/s | ETA: 12:36\n",
      "  Train: [24000/57525] ( 41.7%) | Loss: 0.7952 | Speed: 44.5 batches/s | ETA: 12:34\n",
      "  Train: [24100/57525] ( 41.9%) | Loss: 0.7949 | Speed: 44.5 batches/s | ETA: 12:31\n",
      "  Train: [24200/57525] ( 42.1%) | Loss: 0.7945 | Speed: 44.5 batches/s | ETA: 12:29\n",
      "  Train: [24300/57525] ( 42.2%) | Loss: 0.7941 | Speed: 44.5 batches/s | ETA: 12:27\n",
      "  Train: [24400/57525] ( 42.4%) | Loss: 0.7937 | Speed: 44.5 batches/s | ETA: 12:24\n",
      "  Train: [24500/57525] ( 42.6%) | Loss: 0.7934 | Speed: 44.5 batches/s | ETA: 12:22\n",
      "  Train: [24600/57525] ( 42.8%) | Loss: 0.7930 | Speed: 44.5 batches/s | ETA: 12:20\n",
      "  Train: [24700/57525] ( 42.9%) | Loss: 0.7927 | Speed: 44.5 batches/s | ETA: 12:18\n",
      "  Train: [24800/57525] ( 43.1%) | Loss: 0.7924 | Speed: 44.5 batches/s | ETA: 12:15\n",
      "  Train: [24900/57525] ( 43.3%) | Loss: 0.7920 | Speed: 44.5 batches/s | ETA: 12:13\n",
      "  Train: [25000/57525] ( 43.5%) | Loss: 0.7917 | Speed: 44.5 batches/s | ETA: 12:11\n",
      "  Train: [25100/57525] ( 43.6%) | Loss: 0.7915 | Speed: 44.5 batches/s | ETA: 12:09\n",
      "  Train: [25200/57525] ( 43.8%) | Loss: 0.7912 | Speed: 44.5 batches/s | ETA: 12:06\n",
      "  Train: [25300/57525] ( 44.0%) | Loss: 0.7907 | Speed: 44.5 batches/s | ETA: 12:04\n",
      "  Train: [25400/57525] ( 44.2%) | Loss: 0.7904 | Speed: 44.5 batches/s | ETA: 12:02\n",
      "  Train: [25500/57525] ( 44.3%) | Loss: 0.7900 | Speed: 44.5 batches/s | ETA: 12:00\n",
      "  Train: [25600/57525] ( 44.5%) | Loss: 0.7897 | Speed: 44.5 batches/s | ETA: 11:57\n",
      "  Train: [25700/57525] ( 44.7%) | Loss: 0.7894 | Speed: 44.5 batches/s | ETA: 11:55\n",
      "  Train: [25800/57525] ( 44.9%) | Loss: 0.7891 | Speed: 44.5 batches/s | ETA: 11:53\n",
      "  Train: [25900/57525] ( 45.0%) | Loss: 0.7888 | Speed: 44.5 batches/s | ETA: 11:51\n",
      "  Train: [26000/57525] ( 45.2%) | Loss: 0.7884 | Speed: 44.5 batches/s | ETA: 11:48\n",
      "  Train: [26100/57525] ( 45.4%) | Loss: 0.7882 | Speed: 44.5 batches/s | ETA: 11:46\n",
      "  Train: [26200/57525] ( 45.5%) | Loss: 0.7878 | Speed: 44.5 batches/s | ETA: 11:44\n",
      "  Train: [26300/57525] ( 45.7%) | Loss: 0.7874 | Speed: 44.5 batches/s | ETA: 11:41\n",
      "  Train: [26400/57525] ( 45.9%) | Loss: 0.7872 | Speed: 44.5 batches/s | ETA: 11:39\n",
      "  Train: [26500/57525] ( 46.1%) | Loss: 0.7869 | Speed: 44.5 batches/s | ETA: 11:37\n",
      "  Train: [26600/57525] ( 46.2%) | Loss: 0.7866 | Speed: 44.5 batches/s | ETA: 11:35\n",
      "  Train: [26700/57525] ( 46.4%) | Loss: 0.7862 | Speed: 44.5 batches/s | ETA: 11:32\n",
      "  Train: [26800/57525] ( 46.6%) | Loss: 0.7858 | Speed: 44.5 batches/s | ETA: 11:30\n",
      "  Train: [26900/57525] ( 46.8%) | Loss: 0.7855 | Speed: 44.5 batches/s | ETA: 11:28\n",
      "  Train: [27000/57525] ( 46.9%) | Loss: 0.7852 | Speed: 44.5 batches/s | ETA: 11:26\n",
      "  Train: [27100/57525] ( 47.1%) | Loss: 0.7848 | Speed: 44.5 batches/s | ETA: 11:23\n",
      "  Train: [27200/57525] ( 47.3%) | Loss: 0.7845 | Speed: 44.5 batches/s | ETA: 11:21\n",
      "  Train: [27300/57525] ( 47.5%) | Loss: 0.7843 | Speed: 44.5 batches/s | ETA: 11:19\n",
      "  Train: [27400/57525] ( 47.6%) | Loss: 0.7839 | Speed: 44.5 batches/s | ETA: 11:17\n",
      "  Train: [27500/57525] ( 47.8%) | Loss: 0.7834 | Speed: 44.5 batches/s | ETA: 11:14\n",
      "  Train: [27600/57525] ( 48.0%) | Loss: 0.7832 | Speed: 44.5 batches/s | ETA: 11:12\n",
      "  Train: [27700/57525] ( 48.2%) | Loss: 0.7830 | Speed: 44.5 batches/s | ETA: 11:10\n",
      "  Train: [27800/57525] ( 48.3%) | Loss: 0.7826 | Speed: 44.5 batches/s | ETA: 11:08\n",
      "  Train: [27900/57525] ( 48.5%) | Loss: 0.7823 | Speed: 44.5 batches/s | ETA: 11:05\n",
      "  Train: [28000/57525] ( 48.7%) | Loss: 0.7821 | Speed: 44.5 batches/s | ETA: 11:03\n",
      "  Train: [28100/57525] ( 48.8%) | Loss: 0.7818 | Speed: 44.5 batches/s | ETA: 11:01\n",
      "  Train: [28200/57525] ( 49.0%) | Loss: 0.7815 | Speed: 44.5 batches/s | ETA: 10:59\n",
      "  Train: [28300/57525] ( 49.2%) | Loss: 0.7812 | Speed: 44.5 batches/s | ETA: 10:56\n",
      "  Train: [28400/57525] ( 49.4%) | Loss: 0.7808 | Speed: 44.5 batches/s | ETA: 10:54\n",
      "  Train: [28500/57525] ( 49.5%) | Loss: 0.7804 | Speed: 44.5 batches/s | ETA: 10:52\n",
      "  Train: [28600/57525] ( 49.7%) | Loss: 0.7801 | Speed: 44.5 batches/s | ETA: 10:49\n",
      "  Train: [28700/57525] ( 49.9%) | Loss: 0.7797 | Speed: 44.5 batches/s | ETA: 10:47\n",
      "  Train: [28800/57525] ( 50.1%) | Loss: 0.7794 | Speed: 44.5 batches/s | ETA: 10:45\n",
      "  Train: [28900/57525] ( 50.2%) | Loss: 0.7791 | Speed: 44.5 batches/s | ETA: 10:43\n",
      "  Train: [29000/57525] ( 50.4%) | Loss: 0.7787 | Speed: 44.5 batches/s | ETA: 10:41\n",
      "  Train: [29100/57525] ( 50.6%) | Loss: 0.7784 | Speed: 44.5 batches/s | ETA: 10:38\n",
      "  Train: [29200/57525] ( 50.8%) | Loss: 0.7780 | Speed: 44.5 batches/s | ETA: 10:36\n",
      "  Train: [29300/57525] ( 50.9%) | Loss: 0.7778 | Speed: 44.5 batches/s | ETA: 10:34\n",
      "  Train: [29400/57525] ( 51.1%) | Loss: 0.7775 | Speed: 44.5 batches/s | ETA: 10:32\n",
      "  Train: [29500/57525] ( 51.3%) | Loss: 0.7771 | Speed: 44.5 batches/s | ETA: 10:30\n",
      "  Train: [29600/57525] ( 51.5%) | Loss: 0.7768 | Speed: 44.5 batches/s | ETA: 10:27\n",
      "  Train: [29700/57525] ( 51.6%) | Loss: 0.7765 | Speed: 44.5 batches/s | ETA: 10:25\n",
      "  Train: [29800/57525] ( 51.8%) | Loss: 0.7761 | Speed: 44.5 batches/s | ETA: 10:23\n",
      "  Train: [29900/57525] ( 52.0%) | Loss: 0.7759 | Speed: 44.5 batches/s | ETA: 10:21\n",
      "  Train: [30000/57525] ( 52.2%) | Loss: 0.7755 | Speed: 44.5 batches/s | ETA: 10:19\n",
      "  Train: [30100/57525] ( 52.3%) | Loss: 0.7753 | Speed: 44.5 batches/s | ETA: 10:16\n",
      "  Train: [30200/57525] ( 52.5%) | Loss: 0.7750 | Speed: 44.4 batches/s | ETA: 10:14\n",
      "  Train: [30300/57525] ( 52.7%) | Loss: 0.7747 | Speed: 44.4 batches/s | ETA: 10:12\n",
      "  Train: [30400/57525] ( 52.8%) | Loss: 0.7744 | Speed: 44.4 batches/s | ETA: 10:10\n",
      "  Train: [30500/57525] ( 53.0%) | Loss: 0.7741 | Speed: 44.4 batches/s | ETA: 10:08\n",
      "  Train: [30600/57525] ( 53.2%) | Loss: 0.7738 | Speed: 44.4 batches/s | ETA: 10:06\n",
      "  Train: [30700/57525] ( 53.4%) | Loss: 0.7735 | Speed: 44.4 batches/s | ETA: 10:03\n",
      "  Train: [30800/57525] ( 53.5%) | Loss: 0.7732 | Speed: 44.4 batches/s | ETA: 10:01\n",
      "  Train: [30900/57525] ( 53.7%) | Loss: 0.7729 | Speed: 44.4 batches/s | ETA: 09:59\n",
      "  Train: [31000/57525] ( 53.9%) | Loss: 0.7727 | Speed: 44.4 batches/s | ETA: 09:57\n",
      "  Train: [31100/57525] ( 54.1%) | Loss: 0.7724 | Speed: 44.4 batches/s | ETA: 09:55\n",
      "  Train: [31200/57525] ( 54.2%) | Loss: 0.7721 | Speed: 44.4 batches/s | ETA: 09:52\n",
      "  Train: [31300/57525] ( 54.4%) | Loss: 0.7717 | Speed: 44.4 batches/s | ETA: 09:50\n",
      "  Train: [31400/57525] ( 54.6%) | Loss: 0.7715 | Speed: 44.4 batches/s | ETA: 09:48\n",
      "  Train: [31500/57525] ( 54.8%) | Loss: 0.7712 | Speed: 44.4 batches/s | ETA: 09:46\n",
      "  Train: [31600/57525] ( 54.9%) | Loss: 0.7709 | Speed: 44.4 batches/s | ETA: 09:43\n",
      "  Train: [31700/57525] ( 55.1%) | Loss: 0.7707 | Speed: 44.4 batches/s | ETA: 09:41\n",
      "  Train: [31800/57525] ( 55.3%) | Loss: 0.7704 | Speed: 44.4 batches/s | ETA: 09:39\n",
      "  Train: [31900/57525] ( 55.5%) | Loss: 0.7701 | Speed: 44.4 batches/s | ETA: 09:37\n",
      "  Train: [32000/57525] ( 55.6%) | Loss: 0.7698 | Speed: 44.4 batches/s | ETA: 09:35\n",
      "  Train: [32100/57525] ( 55.8%) | Loss: 0.7695 | Speed: 44.4 batches/s | ETA: 09:32\n",
      "  Train: [32200/57525] ( 56.0%) | Loss: 0.7693 | Speed: 44.4 batches/s | ETA: 09:30\n",
      "  Train: [32300/57525] ( 56.1%) | Loss: 0.7690 | Speed: 44.4 batches/s | ETA: 09:28\n",
      "  Train: [32400/57525] ( 56.3%) | Loss: 0.7688 | Speed: 44.4 batches/s | ETA: 09:26\n",
      "  Train: [32500/57525] ( 56.5%) | Loss: 0.7684 | Speed: 44.4 batches/s | ETA: 09:24\n",
      "  Train: [32600/57525] ( 56.7%) | Loss: 0.7682 | Speed: 44.4 batches/s | ETA: 09:21\n",
      "  Train: [32700/57525] ( 56.8%) | Loss: 0.7679 | Speed: 44.4 batches/s | ETA: 09:19\n",
      "  Train: [32800/57525] ( 57.0%) | Loss: 0.7676 | Speed: 44.4 batches/s | ETA: 09:17\n",
      "  Train: [32900/57525] ( 57.2%) | Loss: 0.7674 | Speed: 44.4 batches/s | ETA: 09:15\n",
      "  Train: [33000/57525] ( 57.4%) | Loss: 0.7671 | Speed: 44.4 batches/s | ETA: 09:12\n",
      "  Train: [33100/57525] ( 57.5%) | Loss: 0.7668 | Speed: 44.4 batches/s | ETA: 09:10\n",
      "  Train: [33200/57525] ( 57.7%) | Loss: 0.7666 | Speed: 44.3 batches/s | ETA: 09:08\n",
      "  Train: [33300/57525] ( 57.9%) | Loss: 0.7663 | Speed: 44.3 batches/s | ETA: 09:06\n",
      "  Train: [33400/57525] ( 58.1%) | Loss: 0.7660 | Speed: 44.3 batches/s | ETA: 09:04\n",
      "  Train: [33500/57525] ( 58.2%) | Loss: 0.7657 | Speed: 44.3 batches/s | ETA: 09:01\n",
      "  Train: [33600/57525] ( 58.4%) | Loss: 0.7654 | Speed: 44.3 batches/s | ETA: 08:59\n",
      "  Train: [33700/57525] ( 58.6%) | Loss: 0.7653 | Speed: 44.3 batches/s | ETA: 08:57\n",
      "  Train: [33800/57525] ( 58.8%) | Loss: 0.7650 | Speed: 44.3 batches/s | ETA: 08:55\n",
      "  Train: [33900/57525] ( 58.9%) | Loss: 0.7648 | Speed: 44.3 batches/s | ETA: 08:53\n",
      "  Train: [34000/57525] ( 59.1%) | Loss: 0.7645 | Speed: 44.3 batches/s | ETA: 08:50\n",
      "  Train: [34100/57525] ( 59.3%) | Loss: 0.7642 | Speed: 44.3 batches/s | ETA: 08:48\n",
      "  Train: [34200/57525] ( 59.5%) | Loss: 0.7640 | Speed: 44.3 batches/s | ETA: 08:46\n",
      "  Train: [34300/57525] ( 59.6%) | Loss: 0.7638 | Speed: 44.3 batches/s | ETA: 08:44\n",
      "  Train: [34400/57525] ( 59.8%) | Loss: 0.7634 | Speed: 44.3 batches/s | ETA: 08:41\n",
      "  Train: [34500/57525] ( 60.0%) | Loss: 0.7632 | Speed: 44.3 batches/s | ETA: 08:39\n",
      "  Train: [34600/57525] ( 60.1%) | Loss: 0.7629 | Speed: 44.3 batches/s | ETA: 08:37\n",
      "  Train: [34700/57525] ( 60.3%) | Loss: 0.7626 | Speed: 44.3 batches/s | ETA: 08:35\n",
      "  Train: [34800/57525] ( 60.5%) | Loss: 0.7624 | Speed: 44.3 batches/s | ETA: 08:33\n",
      "  Train: [34900/57525] ( 60.7%) | Loss: 0.7621 | Speed: 44.3 batches/s | ETA: 08:30\n",
      "  Train: [35000/57525] ( 60.8%) | Loss: 0.7619 | Speed: 44.3 batches/s | ETA: 08:28\n",
      "  Train: [35100/57525] ( 61.0%) | Loss: 0.7616 | Speed: 44.3 batches/s | ETA: 08:26\n",
      "  Train: [35200/57525] ( 61.2%) | Loss: 0.7614 | Speed: 44.3 batches/s | ETA: 08:24\n",
      "  Train: [35300/57525] ( 61.4%) | Loss: 0.7611 | Speed: 44.3 batches/s | ETA: 08:21\n",
      "  Train: [35400/57525] ( 61.5%) | Loss: 0.7609 | Speed: 44.3 batches/s | ETA: 08:19\n",
      "  Train: [35500/57525] ( 61.7%) | Loss: 0.7607 | Speed: 44.3 batches/s | ETA: 08:17\n",
      "  Train: [35600/57525] ( 61.9%) | Loss: 0.7605 | Speed: 44.3 batches/s | ETA: 08:15\n",
      "  Train: [35700/57525] ( 62.1%) | Loss: 0.7602 | Speed: 44.3 batches/s | ETA: 08:12\n",
      "  Train: [35800/57525] ( 62.2%) | Loss: 0.7600 | Speed: 44.3 batches/s | ETA: 08:10\n",
      "  Train: [35900/57525] ( 62.4%) | Loss: 0.7597 | Speed: 44.3 batches/s | ETA: 08:08\n",
      "  Train: [36000/57525] ( 62.6%) | Loss: 0.7596 | Speed: 44.3 batches/s | ETA: 08:06\n",
      "  Train: [36100/57525] ( 62.8%) | Loss: 0.7594 | Speed: 44.3 batches/s | ETA: 08:04\n",
      "  Train: [36200/57525] ( 62.9%) | Loss: 0.7591 | Speed: 44.3 batches/s | ETA: 08:01\n",
      "  Train: [36300/57525] ( 63.1%) | Loss: 0.7589 | Speed: 44.3 batches/s | ETA: 07:59\n",
      "  Train: [36400/57525] ( 63.3%) | Loss: 0.7587 | Speed: 44.3 batches/s | ETA: 07:57\n",
      "  Train: [36500/57525] ( 63.5%) | Loss: 0.7585 | Speed: 44.3 batches/s | ETA: 07:55\n",
      "  Train: [36600/57525] ( 63.6%) | Loss: 0.7582 | Speed: 44.3 batches/s | ETA: 07:52\n",
      "  Train: [36700/57525] ( 63.8%) | Loss: 0.7579 | Speed: 44.2 batches/s | ETA: 07:50\n",
      "  Train: [36800/57525] ( 64.0%) | Loss: 0.7577 | Speed: 44.2 batches/s | ETA: 07:48\n",
      "  Train: [36900/57525] ( 64.1%) | Loss: 0.7575 | Speed: 44.2 batches/s | ETA: 07:46\n",
      "  Train: [37000/57525] ( 64.3%) | Loss: 0.7572 | Speed: 44.2 batches/s | ETA: 07:44\n",
      "  Train: [37100/57525] ( 64.5%) | Loss: 0.7570 | Speed: 44.2 batches/s | ETA: 07:41\n",
      "  Train: [37200/57525] ( 64.7%) | Loss: 0.7568 | Speed: 44.2 batches/s | ETA: 07:39\n",
      "  Train: [37300/57525] ( 64.8%) | Loss: 0.7565 | Speed: 44.2 batches/s | ETA: 07:37\n",
      "  Train: [37400/57525] ( 65.0%) | Loss: 0.7563 | Speed: 44.2 batches/s | ETA: 07:35\n",
      "  Train: [37500/57525] ( 65.2%) | Loss: 0.7561 | Speed: 44.2 batches/s | ETA: 07:32\n",
      "  Train: [37600/57525] ( 65.4%) | Loss: 0.7558 | Speed: 44.2 batches/s | ETA: 07:30\n",
      "  Train: [37700/57525] ( 65.5%) | Loss: 0.7555 | Speed: 44.2 batches/s | ETA: 07:28\n",
      "  Train: [37800/57525] ( 65.7%) | Loss: 0.7553 | Speed: 44.2 batches/s | ETA: 07:26\n",
      "  Train: [37900/57525] ( 65.9%) | Loss: 0.7551 | Speed: 44.2 batches/s | ETA: 07:23\n",
      "  Train: [38000/57525] ( 66.1%) | Loss: 0.7549 | Speed: 44.2 batches/s | ETA: 07:21\n",
      "  Train: [38100/57525] ( 66.2%) | Loss: 0.7546 | Speed: 44.2 batches/s | ETA: 07:19\n",
      "  Train: [38200/57525] ( 66.4%) | Loss: 0.7543 | Speed: 44.2 batches/s | ETA: 07:17\n",
      "  Train: [38300/57525] ( 66.6%) | Loss: 0.7542 | Speed: 44.2 batches/s | ETA: 07:14\n",
      "  Train: [38400/57525] ( 66.8%) | Loss: 0.7539 | Speed: 44.2 batches/s | ETA: 07:12\n",
      "  Train: [38500/57525] ( 66.9%) | Loss: 0.7537 | Speed: 44.2 batches/s | ETA: 07:10\n",
      "  Train: [38600/57525] ( 67.1%) | Loss: 0.7535 | Speed: 44.2 batches/s | ETA: 07:08\n",
      "  Train: [38700/57525] ( 67.3%) | Loss: 0.7533 | Speed: 44.2 batches/s | ETA: 07:05\n",
      "  Train: [38800/57525] ( 67.4%) | Loss: 0.7531 | Speed: 44.2 batches/s | ETA: 07:03\n",
      "  Train: [38900/57525] ( 67.6%) | Loss: 0.7528 | Speed: 44.2 batches/s | ETA: 07:01\n",
      "  Train: [39000/57525] ( 67.8%) | Loss: 0.7527 | Speed: 44.2 batches/s | ETA: 06:59\n",
      "  Train: [39100/57525] ( 68.0%) | Loss: 0.7524 | Speed: 44.2 batches/s | ETA: 06:56\n",
      "  Train: [39200/57525] ( 68.1%) | Loss: 0.7522 | Speed: 44.2 batches/s | ETA: 06:54\n",
      "  Train: [39300/57525] ( 68.3%) | Loss: 0.7520 | Speed: 44.2 batches/s | ETA: 06:52\n",
      "  Train: [39400/57525] ( 68.5%) | Loss: 0.7518 | Speed: 44.2 batches/s | ETA: 06:49\n",
      "  Train: [39500/57525] ( 68.7%) | Loss: 0.7516 | Speed: 44.2 batches/s | ETA: 06:47\n",
      "  Train: [39600/57525] ( 68.8%) | Loss: 0.7514 | Speed: 44.2 batches/s | ETA: 06:45\n",
      "  Train: [39700/57525] ( 69.0%) | Loss: 0.7512 | Speed: 44.2 batches/s | ETA: 06:43\n",
      "  Train: [39800/57525] ( 69.2%) | Loss: 0.7510 | Speed: 44.2 batches/s | ETA: 06:40\n",
      "  Train: [39900/57525] ( 69.4%) | Loss: 0.7508 | Speed: 44.2 batches/s | ETA: 06:38\n",
      "  Train: [40000/57525] ( 69.5%) | Loss: 0.7506 | Speed: 44.2 batches/s | ETA: 06:36\n",
      "  Train: [40100/57525] ( 69.7%) | Loss: 0.7504 | Speed: 44.2 batches/s | ETA: 06:34\n",
      "  Train: [40200/57525] ( 69.9%) | Loss: 0.7502 | Speed: 44.2 batches/s | ETA: 06:31\n",
      "  Train: [40300/57525] ( 70.1%) | Loss: 0.7500 | Speed: 44.2 batches/s | ETA: 06:29\n",
      "  Train: [40400/57525] ( 70.2%) | Loss: 0.7498 | Speed: 44.2 batches/s | ETA: 06:27\n",
      "  Train: [40500/57525] ( 70.4%) | Loss: 0.7496 | Speed: 44.2 batches/s | ETA: 06:24\n",
      "  Train: [40600/57525] ( 70.6%) | Loss: 0.7494 | Speed: 44.2 batches/s | ETA: 06:22\n",
      "  Train: [40700/57525] ( 70.8%) | Loss: 0.7492 | Speed: 44.2 batches/s | ETA: 06:20\n",
      "  Train: [40800/57525] ( 70.9%) | Loss: 0.7491 | Speed: 44.2 batches/s | ETA: 06:18\n",
      "  Train: [40900/57525] ( 71.1%) | Loss: 0.7489 | Speed: 44.2 batches/s | ETA: 06:15\n",
      "  Train: [41000/57525] ( 71.3%) | Loss: 0.7486 | Speed: 44.2 batches/s | ETA: 06:13\n",
      "  Train: [41100/57525] ( 71.4%) | Loss: 0.7485 | Speed: 44.2 batches/s | ETA: 06:11\n",
      "  Train: [41200/57525] ( 71.6%) | Loss: 0.7483 | Speed: 44.2 batches/s | ETA: 06:09\n",
      "  Train: [41300/57525] ( 71.8%) | Loss: 0.7481 | Speed: 44.2 batches/s | ETA: 06:06\n",
      "  Train: [41400/57525] ( 72.0%) | Loss: 0.7480 | Speed: 44.2 batches/s | ETA: 06:04\n",
      "  Train: [41500/57525] ( 72.1%) | Loss: 0.7478 | Speed: 44.2 batches/s | ETA: 06:02\n",
      "  Train: [41600/57525] ( 72.3%) | Loss: 0.7476 | Speed: 44.2 batches/s | ETA: 06:00\n",
      "  Train: [41700/57525] ( 72.5%) | Loss: 0.7474 | Speed: 44.2 batches/s | ETA: 05:57\n",
      "  Train: [41800/57525] ( 72.7%) | Loss: 0.7472 | Speed: 44.2 batches/s | ETA: 05:55\n",
      "  Train: [41900/57525] ( 72.8%) | Loss: 0.7470 | Speed: 44.2 batches/s | ETA: 05:53\n",
      "  Train: [42000/57525] ( 73.0%) | Loss: 0.7468 | Speed: 44.2 batches/s | ETA: 05:50\n",
      "  Train: [42100/57525] ( 73.2%) | Loss: 0.7466 | Speed: 44.2 batches/s | ETA: 05:48\n",
      "  Train: [42200/57525] ( 73.4%) | Loss: 0.7464 | Speed: 44.2 batches/s | ETA: 05:46\n",
      "  Train: [42300/57525] ( 73.5%) | Loss: 0.7462 | Speed: 44.2 batches/s | ETA: 05:44\n",
      "  Train: [42400/57525] ( 73.7%) | Loss: 0.7460 | Speed: 44.2 batches/s | ETA: 05:41\n",
      "  Train: [42500/57525] ( 73.9%) | Loss: 0.7458 | Speed: 44.3 batches/s | ETA: 05:39\n",
      "  Train: [42600/57525] ( 74.1%) | Loss: 0.7456 | Speed: 44.3 batches/s | ETA: 05:37\n",
      "  Train: [42700/57525] ( 74.2%) | Loss: 0.7454 | Speed: 44.3 batches/s | ETA: 05:34\n",
      "  Train: [42800/57525] ( 74.4%) | Loss: 0.7452 | Speed: 44.3 batches/s | ETA: 05:32\n",
      "  Train: [42900/57525] ( 74.6%) | Loss: 0.7451 | Speed: 44.3 batches/s | ETA: 05:30\n",
      "  Train: [43000/57525] ( 74.8%) | Loss: 0.7449 | Speed: 44.3 batches/s | ETA: 05:28\n",
      "  Train: [43100/57525] ( 74.9%) | Loss: 0.7447 | Speed: 44.3 batches/s | ETA: 05:25\n",
      "  Train: [43200/57525] ( 75.1%) | Loss: 0.7445 | Speed: 44.3 batches/s | ETA: 05:23\n",
      "  Train: [43300/57525] ( 75.3%) | Loss: 0.7443 | Speed: 44.3 batches/s | ETA: 05:21\n",
      "  Train: [43400/57525] ( 75.4%) | Loss: 0.7442 | Speed: 44.3 batches/s | ETA: 05:19\n",
      "  Train: [43500/57525] ( 75.6%) | Loss: 0.7440 | Speed: 44.3 batches/s | ETA: 05:16\n",
      "  Train: [43600/57525] ( 75.8%) | Loss: 0.7438 | Speed: 44.3 batches/s | ETA: 05:14\n",
      "  Train: [43700/57525] ( 76.0%) | Loss: 0.7437 | Speed: 44.3 batches/s | ETA: 05:12\n",
      "  Train: [43800/57525] ( 76.1%) | Loss: 0.7435 | Speed: 44.3 batches/s | ETA: 05:10\n",
      "  Train: [43900/57525] ( 76.3%) | Loss: 0.7433 | Speed: 44.3 batches/s | ETA: 05:07\n",
      "  Train: [44000/57525] ( 76.5%) | Loss: 0.7431 | Speed: 44.3 batches/s | ETA: 05:05\n",
      "  Train: [44100/57525] ( 76.7%) | Loss: 0.7429 | Speed: 44.3 batches/s | ETA: 05:03\n",
      "  Train: [44200/57525] ( 76.8%) | Loss: 0.7426 | Speed: 44.3 batches/s | ETA: 05:00\n",
      "  Train: [44300/57525] ( 77.0%) | Loss: 0.7425 | Speed: 44.3 batches/s | ETA: 04:58\n",
      "  Train: [44400/57525] ( 77.2%) | Loss: 0.7423 | Speed: 44.3 batches/s | ETA: 04:56\n",
      "  Train: [44500/57525] ( 77.4%) | Loss: 0.7421 | Speed: 44.3 batches/s | ETA: 04:54\n",
      "  Train: [44600/57525] ( 77.5%) | Loss: 0.7419 | Speed: 44.3 batches/s | ETA: 04:51\n",
      "  Train: [44700/57525] ( 77.7%) | Loss: 0.7417 | Speed: 44.3 batches/s | ETA: 04:49\n",
      "  Train: [44800/57525] ( 77.9%) | Loss: 0.7416 | Speed: 44.3 batches/s | ETA: 04:47\n",
      "  Train: [44900/57525] ( 78.1%) | Loss: 0.7414 | Speed: 44.3 batches/s | ETA: 04:45\n",
      "  Train: [45000/57525] ( 78.2%) | Loss: 0.7413 | Speed: 44.3 batches/s | ETA: 04:42\n",
      "  Train: [45100/57525] ( 78.4%) | Loss: 0.7411 | Speed: 44.3 batches/s | ETA: 04:40\n",
      "  Train: [45200/57525] ( 78.6%) | Loss: 0.7409 | Speed: 44.3 batches/s | ETA: 04:38\n",
      "  Train: [45300/57525] ( 78.7%) | Loss: 0.7407 | Speed: 44.3 batches/s | ETA: 04:36\n",
      "  Train: [45400/57525] ( 78.9%) | Loss: 0.7405 | Speed: 44.3 batches/s | ETA: 04:33\n",
      "  Train: [45500/57525] ( 79.1%) | Loss: 0.7403 | Speed: 44.3 batches/s | ETA: 04:31\n",
      "  Train: [45600/57525] ( 79.3%) | Loss: 0.7402 | Speed: 44.3 batches/s | ETA: 04:29\n",
      "  Train: [45700/57525] ( 79.4%) | Loss: 0.7400 | Speed: 44.3 batches/s | ETA: 04:26\n",
      "  Train: [45800/57525] ( 79.6%) | Loss: 0.7399 | Speed: 44.3 batches/s | ETA: 04:24\n",
      "  Train: [45900/57525] ( 79.8%) | Loss: 0.7397 | Speed: 44.3 batches/s | ETA: 04:22\n",
      "  Train: [46000/57525] ( 80.0%) | Loss: 0.7395 | Speed: 44.3 batches/s | ETA: 04:20\n",
      "  Train: [46100/57525] ( 80.1%) | Loss: 0.7393 | Speed: 44.3 batches/s | ETA: 04:17\n",
      "  Train: [46200/57525] ( 80.3%) | Loss: 0.7391 | Speed: 44.3 batches/s | ETA: 04:15\n",
      "  Train: [46300/57525] ( 80.5%) | Loss: 0.7390 | Speed: 44.3 batches/s | ETA: 04:13\n",
      "  Train: [46400/57525] ( 80.7%) | Loss: 0.7388 | Speed: 44.3 batches/s | ETA: 04:11\n",
      "  Train: [46500/57525] ( 80.8%) | Loss: 0.7386 | Speed: 44.3 batches/s | ETA: 04:08\n",
      "  Train: [46600/57525] ( 81.0%) | Loss: 0.7384 | Speed: 44.3 batches/s | ETA: 04:06\n",
      "  Train: [46700/57525] ( 81.2%) | Loss: 0.7383 | Speed: 44.3 batches/s | ETA: 04:04\n",
      "  Train: [46800/57525] ( 81.4%) | Loss: 0.7381 | Speed: 44.3 batches/s | ETA: 04:02\n",
      "  Train: [46900/57525] ( 81.5%) | Loss: 0.7379 | Speed: 44.3 batches/s | ETA: 03:59\n",
      "  Train: [47000/57525] ( 81.7%) | Loss: 0.7378 | Speed: 44.3 batches/s | ETA: 03:57\n",
      "  Train: [47100/57525] ( 81.9%) | Loss: 0.7376 | Speed: 44.3 batches/s | ETA: 03:55\n",
      "  Train: [47200/57525] ( 82.1%) | Loss: 0.7374 | Speed: 44.3 batches/s | ETA: 03:52\n",
      "  Train: [47300/57525] ( 82.2%) | Loss: 0.7373 | Speed: 44.3 batches/s | ETA: 03:50\n",
      "  Train: [47400/57525] ( 82.4%) | Loss: 0.7371 | Speed: 44.3 batches/s | ETA: 03:48\n",
      "  Train: [47500/57525] ( 82.6%) | Loss: 0.7369 | Speed: 44.3 batches/s | ETA: 03:46\n",
      "  Train: [47600/57525] ( 82.7%) | Loss: 0.7367 | Speed: 44.3 batches/s | ETA: 03:43\n",
      "  Train: [47700/57525] ( 82.9%) | Loss: 0.7366 | Speed: 44.3 batches/s | ETA: 03:41\n",
      "  Train: [47800/57525] ( 83.1%) | Loss: 0.7364 | Speed: 44.3 batches/s | ETA: 03:39\n",
      "  Train: [47900/57525] ( 83.3%) | Loss: 0.7363 | Speed: 44.3 batches/s | ETA: 03:37\n",
      "  Train: [48000/57525] ( 83.4%) | Loss: 0.7361 | Speed: 44.3 batches/s | ETA: 03:34\n",
      "  Train: [48100/57525] ( 83.6%) | Loss: 0.7359 | Speed: 44.3 batches/s | ETA: 03:32\n",
      "  Train: [48200/57525] ( 83.8%) | Loss: 0.7357 | Speed: 44.3 batches/s | ETA: 03:30\n",
      "  Train: [48300/57525] ( 84.0%) | Loss: 0.7355 | Speed: 44.3 batches/s | ETA: 03:28\n",
      "  Train: [48400/57525] ( 84.1%) | Loss: 0.7355 | Speed: 44.3 batches/s | ETA: 03:25\n",
      "  Train: [48500/57525] ( 84.3%) | Loss: 0.7353 | Speed: 44.3 batches/s | ETA: 03:23\n",
      "  Train: [48600/57525] ( 84.5%) | Loss: 0.7351 | Speed: 44.3 batches/s | ETA: 03:21\n",
      "  Train: [48700/57525] ( 84.7%) | Loss: 0.7350 | Speed: 44.3 batches/s | ETA: 03:19\n",
      "  Train: [48800/57525] ( 84.8%) | Loss: 0.7348 | Speed: 44.3 batches/s | ETA: 03:16\n",
      "  Train: [48900/57525] ( 85.0%) | Loss: 0.7347 | Speed: 44.3 batches/s | ETA: 03:14\n",
      "  Train: [49000/57525] ( 85.2%) | Loss: 0.7345 | Speed: 44.3 batches/s | ETA: 03:12\n",
      "  Train: [49100/57525] ( 85.4%) | Loss: 0.7344 | Speed: 44.3 batches/s | ETA: 03:09\n",
      "  Train: [49200/57525] ( 85.5%) | Loss: 0.7343 | Speed: 44.3 batches/s | ETA: 03:07\n",
      "  Train: [49300/57525] ( 85.7%) | Loss: 0.7342 | Speed: 44.3 batches/s | ETA: 03:05\n",
      "  Train: [49400/57525] ( 85.9%) | Loss: 0.7341 | Speed: 44.3 batches/s | ETA: 03:03\n",
      "  Train: [49500/57525] ( 86.0%) | Loss: 0.7339 | Speed: 44.3 batches/s | ETA: 03:00\n",
      "  Train: [49600/57525] ( 86.2%) | Loss: 0.7337 | Speed: 44.3 batches/s | ETA: 02:58\n",
      "  Train: [49700/57525] ( 86.4%) | Loss: 0.7336 | Speed: 44.3 batches/s | ETA: 02:56\n",
      "  Train: [49800/57525] ( 86.6%) | Loss: 0.7335 | Speed: 44.3 batches/s | ETA: 02:54\n",
      "  Train: [49900/57525] ( 86.7%) | Loss: 0.7333 | Speed: 44.3 batches/s | ETA: 02:51\n",
      "  Train: [50000/57525] ( 86.9%) | Loss: 0.7331 | Speed: 44.4 batches/s | ETA: 02:49\n",
      "  Train: [50100/57525] ( 87.1%) | Loss: 0.7330 | Speed: 44.4 batches/s | ETA: 02:47\n",
      "  Train: [50200/57525] ( 87.3%) | Loss: 0.7328 | Speed: 44.4 batches/s | ETA: 02:45\n",
      "  Train: [50300/57525] ( 87.4%) | Loss: 0.7326 | Speed: 44.4 batches/s | ETA: 02:42\n",
      "  Train: [50400/57525] ( 87.6%) | Loss: 0.7325 | Speed: 44.4 batches/s | ETA: 02:40\n",
      "  Train: [50500/57525] ( 87.8%) | Loss: 0.7323 | Speed: 44.4 batches/s | ETA: 02:38\n",
      "  Train: [50600/57525] ( 88.0%) | Loss: 0.7322 | Speed: 44.4 batches/s | ETA: 02:36\n",
      "  Train: [50700/57525] ( 88.1%) | Loss: 0.7320 | Speed: 44.4 batches/s | ETA: 02:33\n",
      "  Train: [50800/57525] ( 88.3%) | Loss: 0.7319 | Speed: 44.4 batches/s | ETA: 02:31\n",
      "  Train: [50900/57525] ( 88.5%) | Loss: 0.7317 | Speed: 44.4 batches/s | ETA: 02:29\n",
      "  Train: [51000/57525] ( 88.7%) | Loss: 0.7316 | Speed: 44.4 batches/s | ETA: 02:27\n",
      "  Train: [51100/57525] ( 88.8%) | Loss: 0.7315 | Speed: 44.4 batches/s | ETA: 02:24\n",
      "  Train: [51200/57525] ( 89.0%) | Loss: 0.7313 | Speed: 44.4 batches/s | ETA: 02:22\n",
      "  Train: [51300/57525] ( 89.2%) | Loss: 0.7311 | Speed: 44.4 batches/s | ETA: 02:20\n",
      "  Train: [51400/57525] ( 89.4%) | Loss: 0.7310 | Speed: 44.4 batches/s | ETA: 02:18\n",
      "  Train: [51500/57525] ( 89.5%) | Loss: 0.7309 | Speed: 44.4 batches/s | ETA: 02:15\n",
      "  Train: [51600/57525] ( 89.7%) | Loss: 0.7307 | Speed: 44.4 batches/s | ETA: 02:13\n",
      "  Train: [51700/57525] ( 89.9%) | Loss: 0.7306 | Speed: 44.4 batches/s | ETA: 02:11\n",
      "  Train: [51800/57525] ( 90.0%) | Loss: 0.7304 | Speed: 44.4 batches/s | ETA: 02:09\n",
      "  Train: [51900/57525] ( 90.2%) | Loss: 0.7303 | Speed: 44.4 batches/s | ETA: 02:06\n",
      "  Train: [52000/57525] ( 90.4%) | Loss: 0.7302 | Speed: 44.4 batches/s | ETA: 02:04\n",
      "  Train: [52100/57525] ( 90.6%) | Loss: 0.7300 | Speed: 44.4 batches/s | ETA: 02:02\n",
      "  Train: [52200/57525] ( 90.7%) | Loss: 0.7298 | Speed: 44.4 batches/s | ETA: 02:00\n",
      "  Train: [52300/57525] ( 90.9%) | Loss: 0.7297 | Speed: 44.4 batches/s | ETA: 01:57\n",
      "  Train: [52400/57525] ( 91.1%) | Loss: 0.7295 | Speed: 44.4 batches/s | ETA: 01:55\n",
      "  Train: [52500/57525] ( 91.3%) | Loss: 0.7294 | Speed: 44.4 batches/s | ETA: 01:53\n",
      "  Train: [52600/57525] ( 91.4%) | Loss: 0.7292 | Speed: 44.4 batches/s | ETA: 01:50\n",
      "  Train: [52700/57525] ( 91.6%) | Loss: 0.7291 | Speed: 44.4 batches/s | ETA: 01:48\n",
      "  Train: [52800/57525] ( 91.8%) | Loss: 0.7289 | Speed: 44.4 batches/s | ETA: 01:46\n",
      "  Train: [52900/57525] ( 92.0%) | Loss: 0.7287 | Speed: 44.4 batches/s | ETA: 01:44\n",
      "  Train: [53000/57525] ( 92.1%) | Loss: 0.7285 | Speed: 44.4 batches/s | ETA: 01:41\n",
      "  Train: [53100/57525] ( 92.3%) | Loss: 0.7284 | Speed: 44.4 batches/s | ETA: 01:39\n",
      "  Train: [53200/57525] ( 92.5%) | Loss: 0.7283 | Speed: 44.4 batches/s | ETA: 01:37\n",
      "  Train: [53300/57525] ( 92.7%) | Loss: 0.7281 | Speed: 44.4 batches/s | ETA: 01:35\n",
      "  Train: [53400/57525] ( 92.8%) | Loss: 0.7280 | Speed: 44.4 batches/s | ETA: 01:32\n",
      "  Train: [53500/57525] ( 93.0%) | Loss: 0.7278 | Speed: 44.4 batches/s | ETA: 01:30\n",
      "  Train: [53600/57525] ( 93.2%) | Loss: 0.7277 | Speed: 44.4 batches/s | ETA: 01:28\n",
      "  Train: [53700/57525] ( 93.4%) | Loss: 0.7275 | Speed: 44.4 batches/s | ETA: 01:26\n",
      "  Train: [53800/57525] ( 93.5%) | Loss: 0.7274 | Speed: 44.4 batches/s | ETA: 01:23\n",
      "  Train: [53900/57525] ( 93.7%) | Loss: 0.7272 | Speed: 44.4 batches/s | ETA: 01:21\n",
      "  Train: [54000/57525] ( 93.9%) | Loss: 0.7270 | Speed: 44.4 batches/s | ETA: 01:19\n",
      "  Train: [54100/57525] ( 94.0%) | Loss: 0.7269 | Speed: 44.4 batches/s | ETA: 01:17\n",
      "  Train: [54200/57525] ( 94.2%) | Loss: 0.7267 | Speed: 44.4 batches/s | ETA: 01:14\n",
      "  Train: [54300/57525] ( 94.4%) | Loss: 0.7266 | Speed: 44.4 batches/s | ETA: 01:12\n",
      "  Train: [54400/57525] ( 94.6%) | Loss: 0.7265 | Speed: 44.4 batches/s | ETA: 01:10\n",
      "  Train: [54500/57525] ( 94.7%) | Loss: 0.7264 | Speed: 44.4 batches/s | ETA: 01:08\n",
      "  Train: [54600/57525] ( 94.9%) | Loss: 0.7263 | Speed: 44.4 batches/s | ETA: 01:05\n",
      "  Train: [54700/57525] ( 95.1%) | Loss: 0.7262 | Speed: 44.4 batches/s | ETA: 01:03\n",
      "  Train: [54800/57525] ( 95.3%) | Loss: 0.7260 | Speed: 44.4 batches/s | ETA: 01:01\n",
      "  Train: [54900/57525] ( 95.4%) | Loss: 0.7259 | Speed: 44.4 batches/s | ETA: 00:59\n",
      "  Train: [55000/57525] ( 95.6%) | Loss: 0.7258 | Speed: 44.4 batches/s | ETA: 00:56\n",
      "  Train: [55100/57525] ( 95.8%) | Loss: 0.7256 | Speed: 44.4 batches/s | ETA: 00:54\n",
      "  Train: [55200/57525] ( 96.0%) | Loss: 0.7255 | Speed: 44.4 batches/s | ETA: 00:52\n",
      "  Train: [55300/57525] ( 96.1%) | Loss: 0.7253 | Speed: 44.4 batches/s | ETA: 00:50\n",
      "  Train: [55400/57525] ( 96.3%) | Loss: 0.7252 | Speed: 44.4 batches/s | ETA: 00:47\n",
      "  Train: [55500/57525] ( 96.5%) | Loss: 0.7250 | Speed: 44.4 batches/s | ETA: 00:45\n",
      "  Train: [55600/57525] ( 96.7%) | Loss: 0.7249 | Speed: 44.4 batches/s | ETA: 00:43\n",
      "  Train: [55700/57525] ( 96.8%) | Loss: 0.7248 | Speed: 44.4 batches/s | ETA: 00:41\n",
      "  Train: [55800/57525] ( 97.0%) | Loss: 0.7247 | Speed: 44.4 batches/s | ETA: 00:38\n",
      "  Train: [55900/57525] ( 97.2%) | Loss: 0.7246 | Speed: 44.4 batches/s | ETA: 00:36\n",
      "  Train: [56000/57525] ( 97.3%) | Loss: 0.7244 | Speed: 44.4 batches/s | ETA: 00:34\n",
      "  Train: [56100/57525] ( 97.5%) | Loss: 0.7243 | Speed: 44.4 batches/s | ETA: 00:32\n",
      "  Train: [56200/57525] ( 97.7%) | Loss: 0.7241 | Speed: 44.4 batches/s | ETA: 00:29\n",
      "  Train: [56300/57525] ( 97.9%) | Loss: 0.7240 | Speed: 44.4 batches/s | ETA: 00:27\n",
      "  Train: [56400/57525] ( 98.0%) | Loss: 0.7238 | Speed: 44.4 batches/s | ETA: 00:25\n",
      "  Train: [56500/57525] ( 98.2%) | Loss: 0.7237 | Speed: 44.4 batches/s | ETA: 00:23\n",
      "  Train: [56600/57525] ( 98.4%) | Loss: 0.7236 | Speed: 44.4 batches/s | ETA: 00:20\n",
      "  Train: [56700/57525] ( 98.6%) | Loss: 0.7235 | Speed: 44.4 batches/s | ETA: 00:18\n",
      "  Train: [56800/57525] ( 98.7%) | Loss: 0.7234 | Speed: 44.4 batches/s | ETA: 00:16\n",
      "  Train: [56900/57525] ( 98.9%) | Loss: 0.7232 | Speed: 44.4 batches/s | ETA: 00:14\n",
      "  Train: [57000/57525] ( 99.1%) | Loss: 0.7231 | Speed: 44.4 batches/s | ETA: 00:11\n",
      "  Train: [57100/57525] ( 99.3%) | Loss: 0.7230 | Speed: 44.4 batches/s | ETA: 00:09\n",
      "  Train: [57200/57525] ( 99.4%) | Loss: 0.7228 | Speed: 44.4 batches/s | ETA: 00:07\n",
      "  Train: [57300/57525] ( 99.6%) | Loss: 0.7227 | Speed: 44.4 batches/s | ETA: 00:05\n",
      "  Train: [57400/57525] ( 99.8%) | Loss: 0.7225 | Speed: 44.4 batches/s | ETA: 00:02\n",
      "  Train: [57500/57525] (100.0%) | Loss: 0.7224 | Speed: 44.4 batches/s | ETA: 00:00\n",
      "  Running validation...\n",
      "    Val: [  50/7191] (  0.7%)\n",
      "    Val: [ 100/7191] (  1.4%)\n",
      "    Val: [ 150/7191] (  2.1%)\n",
      "    Val: [ 200/7191] (  2.8%)\n",
      "    Val: [ 250/7191] (  3.5%)\n",
      "    Val: [ 300/7191] (  4.2%)\n",
      "    Val: [ 350/7191] (  4.9%)\n",
      "    Val: [ 400/7191] (  5.6%)\n",
      "    Val: [ 450/7191] (  6.3%)\n",
      "    Val: [ 500/7191] (  7.0%)\n",
      "    Val: [ 550/7191] (  7.6%)\n",
      "    Val: [ 600/7191] (  8.3%)\n",
      "    Val: [ 650/7191] (  9.0%)\n",
      "    Val: [ 700/7191] (  9.7%)\n",
      "    Val: [ 750/7191] ( 10.4%)\n",
      "    Val: [ 800/7191] ( 11.1%)\n",
      "    Val: [ 850/7191] ( 11.8%)\n",
      "    Val: [ 900/7191] ( 12.5%)\n",
      "    Val: [ 950/7191] ( 13.2%)\n",
      "    Val: [1000/7191] ( 13.9%)\n",
      "    Val: [1050/7191] ( 14.6%)\n",
      "    Val: [1100/7191] ( 15.3%)\n",
      "    Val: [1150/7191] ( 16.0%)\n",
      "    Val: [1200/7191] ( 16.7%)\n",
      "    Val: [1250/7191] ( 17.4%)\n",
      "    Val: [1300/7191] ( 18.1%)\n",
      "    Val: [1350/7191] ( 18.8%)\n",
      "    Val: [1400/7191] ( 19.5%)\n",
      "    Val: [1450/7191] ( 20.2%)\n",
      "    Val: [1500/7191] ( 20.9%)\n",
      "    Val: [1550/7191] ( 21.6%)\n",
      "    Val: [1600/7191] ( 22.3%)\n",
      "    Val: [1650/7191] ( 22.9%)\n",
      "    Val: [1700/7191] ( 23.6%)\n",
      "    Val: [1750/7191] ( 24.3%)\n",
      "    Val: [1800/7191] ( 25.0%)\n",
      "    Val: [1850/7191] ( 25.7%)\n",
      "    Val: [1900/7191] ( 26.4%)\n",
      "    Val: [1950/7191] ( 27.1%)\n",
      "    Val: [2000/7191] ( 27.8%)\n",
      "    Val: [2050/7191] ( 28.5%)\n",
      "    Val: [2100/7191] ( 29.2%)\n",
      "    Val: [2150/7191] ( 29.9%)\n",
      "    Val: [2200/7191] ( 30.6%)\n",
      "    Val: [2250/7191] ( 31.3%)\n",
      "    Val: [2300/7191] ( 32.0%)\n",
      "    Val: [2350/7191] ( 32.7%)\n",
      "    Val: [2400/7191] ( 33.4%)\n",
      "    Val: [2450/7191] ( 34.1%)\n",
      "    Val: [2500/7191] ( 34.8%)\n",
      "    Val: [2550/7191] ( 35.5%)\n",
      "    Val: [2600/7191] ( 36.2%)\n",
      "    Val: [2650/7191] ( 36.9%)\n",
      "    Val: [2700/7191] ( 37.5%)\n",
      "    Val: [2750/7191] ( 38.2%)\n",
      "    Val: [2800/7191] ( 38.9%)\n",
      "    Val: [2850/7191] ( 39.6%)\n",
      "    Val: [2900/7191] ( 40.3%)\n",
      "    Val: [2950/7191] ( 41.0%)\n",
      "    Val: [3000/7191] ( 41.7%)\n",
      "    Val: [3050/7191] ( 42.4%)\n",
      "    Val: [3100/7191] ( 43.1%)\n",
      "    Val: [3150/7191] ( 43.8%)\n",
      "    Val: [3200/7191] ( 44.5%)\n",
      "    Val: [3250/7191] ( 45.2%)\n",
      "    Val: [3300/7191] ( 45.9%)\n",
      "    Val: [3350/7191] ( 46.6%)\n",
      "    Val: [3400/7191] ( 47.3%)\n",
      "    Val: [3450/7191] ( 48.0%)\n",
      "    Val: [3500/7191] ( 48.7%)\n",
      "    Val: [3550/7191] ( 49.4%)\n",
      "    Val: [3600/7191] ( 50.1%)\n",
      "    Val: [3650/7191] ( 50.8%)\n",
      "    Val: [3700/7191] ( 51.5%)\n",
      "    Val: [3750/7191] ( 52.1%)\n",
      "    Val: [3800/7191] ( 52.8%)\n",
      "    Val: [3850/7191] ( 53.5%)\n",
      "    Val: [3900/7191] ( 54.2%)\n",
      "    Val: [3950/7191] ( 54.9%)\n",
      "    Val: [4000/7191] ( 55.6%)\n",
      "    Val: [4050/7191] ( 56.3%)\n",
      "    Val: [4100/7191] ( 57.0%)\n",
      "    Val: [4150/7191] ( 57.7%)\n",
      "    Val: [4200/7191] ( 58.4%)\n",
      "    Val: [4250/7191] ( 59.1%)\n",
      "    Val: [4300/7191] ( 59.8%)\n",
      "    Val: [4350/7191] ( 60.5%)\n",
      "    Val: [4400/7191] ( 61.2%)\n",
      "    Val: [4450/7191] ( 61.9%)\n",
      "    Val: [4500/7191] ( 62.6%)\n",
      "    Val: [4550/7191] ( 63.3%)\n",
      "    Val: [4600/7191] ( 64.0%)\n",
      "    Val: [4650/7191] ( 64.7%)\n",
      "    Val: [4700/7191] ( 65.4%)\n",
      "    Val: [4750/7191] ( 66.1%)\n",
      "    Val: [4800/7191] ( 66.8%)\n",
      "    Val: [4850/7191] ( 67.4%)\n",
      "    Val: [4900/7191] ( 68.1%)\n",
      "    Val: [4950/7191] ( 68.8%)\n",
      "    Val: [5000/7191] ( 69.5%)\n",
      "    Val: [5050/7191] ( 70.2%)\n",
      "    Val: [5100/7191] ( 70.9%)\n",
      "    Val: [5150/7191] ( 71.6%)\n",
      "    Val: [5200/7191] ( 72.3%)\n",
      "    Val: [5250/7191] ( 73.0%)\n",
      "    Val: [5300/7191] ( 73.7%)\n",
      "    Val: [5350/7191] ( 74.4%)\n",
      "    Val: [5400/7191] ( 75.1%)\n",
      "    Val: [5450/7191] ( 75.8%)\n",
      "    Val: [5500/7191] ( 76.5%)\n",
      "    Val: [5550/7191] ( 77.2%)\n",
      "    Val: [5600/7191] ( 77.9%)\n",
      "    Val: [5650/7191] ( 78.6%)\n",
      "    Val: [5700/7191] ( 79.3%)\n",
      "    Val: [5750/7191] ( 80.0%)\n",
      "    Val: [5800/7191] ( 80.7%)\n",
      "    Val: [5850/7191] ( 81.4%)\n",
      "    Val: [5900/7191] ( 82.0%)\n",
      "    Val: [5950/7191] ( 82.7%)\n",
      "    Val: [6000/7191] ( 83.4%)\n",
      "    Val: [6050/7191] ( 84.1%)\n",
      "    Val: [6100/7191] ( 84.8%)\n",
      "    Val: [6150/7191] ( 85.5%)\n",
      "    Val: [6200/7191] ( 86.2%)\n",
      "    Val: [6250/7191] ( 86.9%)\n",
      "    Val: [6300/7191] ( 87.6%)\n",
      "    Val: [6350/7191] ( 88.3%)\n",
      "    Val: [6400/7191] ( 89.0%)\n",
      "    Val: [6450/7191] ( 89.7%)\n",
      "    Val: [6500/7191] ( 90.4%)\n",
      "    Val: [6550/7191] ( 91.1%)\n",
      "    Val: [6600/7191] ( 91.8%)\n",
      "    Val: [6650/7191] ( 92.5%)\n",
      "    Val: [6700/7191] ( 93.2%)\n",
      "    Val: [6750/7191] ( 93.9%)\n",
      "    Val: [6800/7191] ( 94.6%)\n",
      "    Val: [6850/7191] ( 95.3%)\n",
      "    Val: [6900/7191] ( 96.0%)\n",
      "    Val: [6950/7191] ( 96.6%)\n",
      "    Val: [7000/7191] ( 97.3%)\n",
      "    Val: [7050/7191] ( 98.0%)\n",
      "    Val: [7100/7191] ( 98.7%)\n",
      "    Val: [7150/7191] ( 99.4%)\n",
      "\n",
      "  Epoch 01 Summary:\n",
      "    Train MSE (norm): 0.7224 | Val MSE (norm): 0.6233\n",
      "    Time: Train=21.6min, Val=0.9min, Total=22.5min\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 02/5\n",
      "============================================================\n",
      "  Train: [  100/57525] (  0.2%) | Loss: 0.6440 | Speed: 30.9 batches/s | ETA: 30:56\n",
      "  Train: [  200/57525] (  0.3%) | Loss: 0.6351 | Speed: 36.3 batches/s | ETA: 26:17\n",
      "  Train: [  300/57525] (  0.5%) | Loss: 0.6387 | Speed: 38.8 batches/s | ETA: 24:33\n",
      "  Train: [  400/57525] (  0.7%) | Loss: 0.6420 | Speed: 40.1 batches/s | ETA: 23:43\n",
      "  Train: [  500/57525] (  0.9%) | Loss: 0.6418 | Speed: 41.0 batches/s | ETA: 23:10\n",
      "  Train: [  600/57525] (  1.0%) | Loss: 0.6411 | Speed: 41.4 batches/s | ETA: 22:55\n",
      "  Train: [  700/57525] (  1.2%) | Loss: 0.6415 | Speed: 41.9 batches/s | ETA: 22:36\n",
      "  Train: [  800/57525] (  1.4%) | Loss: 0.6417 | Speed: 42.3 batches/s | ETA: 22:21\n",
      "  Train: [  900/57525] (  1.6%) | Loss: 0.6420 | Speed: 42.6 batches/s | ETA: 22:10\n",
      "  Train: [ 1000/57525] (  1.7%) | Loss: 0.6409 | Speed: 42.8 batches/s | ETA: 22:00\n",
      "  Train: [ 1100/57525] (  1.9%) | Loss: 0.6389 | Speed: 43.0 batches/s | ETA: 21:52\n",
      "  Train: [ 1200/57525] (  2.1%) | Loss: 0.6398 | Speed: 43.1 batches/s | ETA: 21:47\n",
      "  Train: [ 1300/57525] (  2.3%) | Loss: 0.6395 | Speed: 43.2 batches/s | ETA: 21:42\n",
      "  Train: [ 1400/57525] (  2.4%) | Loss: 0.6405 | Speed: 43.3 batches/s | ETA: 21:35\n",
      "  Train: [ 1500/57525] (  2.6%) | Loss: 0.6402 | Speed: 43.4 batches/s | ETA: 21:29\n",
      "  Train: [ 1600/57525] (  2.8%) | Loss: 0.6399 | Speed: 43.5 batches/s | ETA: 21:24\n",
      "  Train: [ 1700/57525] (  3.0%) | Loss: 0.6392 | Speed: 43.6 batches/s | ETA: 21:19\n",
      "  Train: [ 1800/57525] (  3.1%) | Loss: 0.6389 | Speed: 43.7 batches/s | ETA: 21:15\n",
      "  Train: [ 1900/57525] (  3.3%) | Loss: 0.6397 | Speed: 43.7 batches/s | ETA: 21:11\n",
      "  Train: [ 2000/57525] (  3.5%) | Loss: 0.6404 | Speed: 43.8 batches/s | ETA: 21:07\n",
      "  Train: [ 2100/57525] (  3.7%) | Loss: 0.6409 | Speed: 43.8 batches/s | ETA: 21:04\n",
      "  Train: [ 2200/57525] (  3.8%) | Loss: 0.6401 | Speed: 43.8 batches/s | ETA: 21:01\n",
      "  Train: [ 2300/57525] (  4.0%) | Loss: 0.6399 | Speed: 43.9 batches/s | ETA: 20:58\n",
      "  Train: [ 2400/57525] (  4.2%) | Loss: 0.6395 | Speed: 43.9 batches/s | ETA: 20:54\n",
      "  Train: [ 2500/57525] (  4.3%) | Loss: 0.6390 | Speed: 44.0 batches/s | ETA: 20:51\n",
      "  Train: [ 2600/57525] (  4.5%) | Loss: 0.6395 | Speed: 44.0 batches/s | ETA: 20:48\n",
      "  Train: [ 2700/57525] (  4.7%) | Loss: 0.6397 | Speed: 44.0 batches/s | ETA: 20:46\n",
      "  Train: [ 2800/57525] (  4.9%) | Loss: 0.6404 | Speed: 44.0 batches/s | ETA: 20:43\n",
      "  Train: [ 2900/57525] (  5.0%) | Loss: 0.6411 | Speed: 44.1 batches/s | ETA: 20:39\n",
      "  Train: [ 3000/57525] (  5.2%) | Loss: 0.6405 | Speed: 44.1 batches/s | ETA: 20:36\n",
      "  Train: [ 3100/57525] (  5.4%) | Loss: 0.6401 | Speed: 44.1 batches/s | ETA: 20:34\n",
      "  Train: [ 3200/57525] (  5.6%) | Loss: 0.6405 | Speed: 44.1 batches/s | ETA: 20:32\n",
      "  Train: [ 3300/57525] (  5.7%) | Loss: 0.6406 | Speed: 44.1 batches/s | ETA: 20:29\n",
      "  Train: [ 3400/57525] (  5.9%) | Loss: 0.6410 | Speed: 44.1 batches/s | ETA: 20:27\n",
      "  Train: [ 3500/57525] (  6.1%) | Loss: 0.6411 | Speed: 44.1 batches/s | ETA: 20:24\n",
      "  Train: [ 3600/57525] (  6.3%) | Loss: 0.6414 | Speed: 44.2 batches/s | ETA: 20:21\n",
      "  Train: [ 3700/57525] (  6.4%) | Loss: 0.6413 | Speed: 44.2 batches/s | ETA: 20:18\n",
      "  Train: [ 3800/57525] (  6.6%) | Loss: 0.6413 | Speed: 44.2 batches/s | ETA: 20:15\n",
      "  Train: [ 3900/57525] (  6.8%) | Loss: 0.6414 | Speed: 44.2 batches/s | ETA: 20:12\n",
      "  Train: [ 4000/57525] (  7.0%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 20:09\n",
      "  Train: [ 4100/57525] (  7.1%) | Loss: 0.6419 | Speed: 44.3 batches/s | ETA: 20:06\n",
      "  Train: [ 4200/57525] (  7.3%) | Loss: 0.6424 | Speed: 44.3 batches/s | ETA: 20:03\n",
      "  Train: [ 4300/57525] (  7.5%) | Loss: 0.6427 | Speed: 44.3 batches/s | ETA: 20:00\n",
      "  Train: [ 4400/57525] (  7.6%) | Loss: 0.6425 | Speed: 44.3 batches/s | ETA: 19:58\n",
      "  Train: [ 4500/57525] (  7.8%) | Loss: 0.6426 | Speed: 44.4 batches/s | ETA: 19:55\n",
      "  Train: [ 4600/57525] (  8.0%) | Loss: 0.6427 | Speed: 44.4 batches/s | ETA: 19:52\n",
      "  Train: [ 4700/57525] (  8.2%) | Loss: 0.6431 | Speed: 44.4 batches/s | ETA: 19:50\n",
      "  Train: [ 4800/57525] (  8.3%) | Loss: 0.6426 | Speed: 44.4 batches/s | ETA: 19:47\n",
      "  Train: [ 4900/57525] (  8.5%) | Loss: 0.6426 | Speed: 44.4 batches/s | ETA: 19:44\n",
      "  Train: [ 5000/57525] (  8.7%) | Loss: 0.6431 | Speed: 44.4 batches/s | ETA: 19:41\n",
      "  Train: [ 5100/57525] (  8.9%) | Loss: 0.6428 | Speed: 44.5 batches/s | ETA: 19:39\n",
      "  Train: [ 5200/57525] (  9.0%) | Loss: 0.6429 | Speed: 44.5 batches/s | ETA: 19:36\n",
      "  Train: [ 5300/57525] (  9.2%) | Loss: 0.6430 | Speed: 44.5 batches/s | ETA: 19:34\n",
      "  Train: [ 5400/57525] (  9.4%) | Loss: 0.6430 | Speed: 44.5 batches/s | ETA: 19:31\n",
      "  Train: [ 5500/57525] (  9.6%) | Loss: 0.6432 | Speed: 44.5 batches/s | ETA: 19:28\n",
      "  Train: [ 5600/57525] (  9.7%) | Loss: 0.6435 | Speed: 44.5 batches/s | ETA: 19:26\n",
      "  Train: [ 5700/57525] (  9.9%) | Loss: 0.6440 | Speed: 44.5 batches/s | ETA: 19:23\n",
      "  Train: [ 5800/57525] ( 10.1%) | Loss: 0.6435 | Speed: 44.5 batches/s | ETA: 19:21\n",
      "  Train: [ 5900/57525] ( 10.3%) | Loss: 0.6435 | Speed: 44.5 batches/s | ETA: 19:19\n",
      "  Train: [ 6000/57525] ( 10.4%) | Loss: 0.6435 | Speed: 44.5 batches/s | ETA: 19:16\n",
      "  Train: [ 6100/57525] ( 10.6%) | Loss: 0.6431 | Speed: 44.6 batches/s | ETA: 19:14\n",
      "  Train: [ 6200/57525] ( 10.8%) | Loss: 0.6432 | Speed: 44.6 batches/s | ETA: 19:11\n",
      "  Train: [ 6300/57525] ( 11.0%) | Loss: 0.6433 | Speed: 44.6 batches/s | ETA: 19:09\n",
      "  Train: [ 6400/57525] ( 11.1%) | Loss: 0.6438 | Speed: 44.6 batches/s | ETA: 19:06\n",
      "  Train: [ 6500/57525] ( 11.3%) | Loss: 0.6439 | Speed: 44.6 batches/s | ETA: 19:04\n",
      "  Train: [ 6600/57525] ( 11.5%) | Loss: 0.6441 | Speed: 44.6 batches/s | ETA: 19:01\n",
      "  Train: [ 6700/57525] ( 11.6%) | Loss: 0.6441 | Speed: 44.6 batches/s | ETA: 18:59\n",
      "  Train: [ 6800/57525] ( 11.8%) | Loss: 0.6437 | Speed: 44.6 batches/s | ETA: 18:57\n",
      "  Train: [ 6900/57525] ( 12.0%) | Loss: 0.6437 | Speed: 44.6 batches/s | ETA: 18:55\n",
      "  Train: [ 7000/57525] ( 12.2%) | Loss: 0.6436 | Speed: 44.6 batches/s | ETA: 18:53\n",
      "  Train: [ 7100/57525] ( 12.3%) | Loss: 0.6435 | Speed: 44.6 batches/s | ETA: 18:51\n",
      "  Train: [ 7200/57525] ( 12.5%) | Loss: 0.6435 | Speed: 44.6 batches/s | ETA: 18:49\n",
      "  Train: [ 7300/57525] ( 12.7%) | Loss: 0.6435 | Speed: 44.6 batches/s | ETA: 18:47\n",
      "  Train: [ 7400/57525] ( 12.9%) | Loss: 0.6434 | Speed: 44.6 batches/s | ETA: 18:44\n",
      "  Train: [ 7500/57525] ( 13.0%) | Loss: 0.6435 | Speed: 44.6 batches/s | ETA: 18:42\n",
      "  Train: [ 7600/57525] ( 13.2%) | Loss: 0.6434 | Speed: 44.6 batches/s | ETA: 18:40\n",
      "  Train: [ 7700/57525] ( 13.4%) | Loss: 0.6435 | Speed: 44.6 batches/s | ETA: 18:38\n",
      "  Train: [ 7800/57525] ( 13.6%) | Loss: 0.6434 | Speed: 44.5 batches/s | ETA: 18:36\n",
      "  Train: [ 7900/57525] ( 13.7%) | Loss: 0.6432 | Speed: 44.5 batches/s | ETA: 18:35\n",
      "  Train: [ 8000/57525] ( 13.9%) | Loss: 0.6432 | Speed: 44.5 batches/s | ETA: 18:33\n",
      "  Train: [ 8100/57525] ( 14.1%) | Loss: 0.6430 | Speed: 44.5 batches/s | ETA: 18:31\n",
      "  Train: [ 8200/57525] ( 14.3%) | Loss: 0.6431 | Speed: 44.4 batches/s | ETA: 18:30\n",
      "  Train: [ 8300/57525] ( 14.4%) | Loss: 0.6431 | Speed: 44.4 batches/s | ETA: 18:28\n",
      "  Train: [ 8400/57525] ( 14.6%) | Loss: 0.6432 | Speed: 44.4 batches/s | ETA: 18:26\n",
      "  Train: [ 8500/57525] ( 14.8%) | Loss: 0.6430 | Speed: 44.4 batches/s | ETA: 18:24\n",
      "  Train: [ 8600/57525] ( 15.0%) | Loss: 0.6429 | Speed: 44.4 batches/s | ETA: 18:22\n",
      "  Train: [ 8700/57525] ( 15.1%) | Loss: 0.6428 | Speed: 44.4 batches/s | ETA: 18:19\n",
      "  Train: [ 8800/57525] ( 15.3%) | Loss: 0.6426 | Speed: 44.4 batches/s | ETA: 18:17\n",
      "  Train: [ 8900/57525] ( 15.5%) | Loss: 0.6429 | Speed: 44.4 batches/s | ETA: 18:15\n",
      "  Train: [ 9000/57525] ( 15.6%) | Loss: 0.6429 | Speed: 44.4 batches/s | ETA: 18:12\n",
      "  Train: [ 9100/57525] ( 15.8%) | Loss: 0.6430 | Speed: 44.4 batches/s | ETA: 18:10\n",
      "  Train: [ 9200/57525] ( 16.0%) | Loss: 0.6430 | Speed: 44.4 batches/s | ETA: 18:08\n",
      "  Train: [ 9300/57525] ( 16.2%) | Loss: 0.6428 | Speed: 44.4 batches/s | ETA: 18:06\n",
      "  Train: [ 9400/57525] ( 16.3%) | Loss: 0.6428 | Speed: 44.4 batches/s | ETA: 18:04\n",
      "  Train: [ 9500/57525] ( 16.5%) | Loss: 0.6429 | Speed: 44.4 batches/s | ETA: 18:01\n",
      "  Train: [ 9600/57525] ( 16.7%) | Loss: 0.6430 | Speed: 44.4 batches/s | ETA: 17:59\n",
      "  Train: [ 9700/57525] ( 16.9%) | Loss: 0.6427 | Speed: 44.4 batches/s | ETA: 17:57\n",
      "  Train: [ 9800/57525] ( 17.0%) | Loss: 0.6425 | Speed: 44.4 batches/s | ETA: 17:55\n",
      "  Train: [ 9900/57525] ( 17.2%) | Loss: 0.6424 | Speed: 44.4 batches/s | ETA: 17:53\n",
      "  Train: [10000/57525] ( 17.4%) | Loss: 0.6425 | Speed: 44.4 batches/s | ETA: 17:51\n",
      "  Train: [10100/57525] ( 17.6%) | Loss: 0.6425 | Speed: 44.4 batches/s | ETA: 17:49\n",
      "  Train: [10200/57525] ( 17.7%) | Loss: 0.6426 | Speed: 44.4 batches/s | ETA: 17:46\n",
      "  Train: [10300/57525] ( 17.9%) | Loss: 0.6423 | Speed: 44.4 batches/s | ETA: 17:44\n",
      "  Train: [10400/57525] ( 18.1%) | Loss: 0.6422 | Speed: 44.4 batches/s | ETA: 17:41\n",
      "  Train: [10500/57525] ( 18.3%) | Loss: 0.6420 | Speed: 44.4 batches/s | ETA: 17:39\n",
      "  Train: [10600/57525] ( 18.4%) | Loss: 0.6420 | Speed: 44.4 batches/s | ETA: 17:37\n",
      "  Train: [10700/57525] ( 18.6%) | Loss: 0.6420 | Speed: 44.4 batches/s | ETA: 17:34\n",
      "  Train: [10800/57525] ( 18.8%) | Loss: 0.6418 | Speed: 44.4 batches/s | ETA: 17:32\n",
      "  Train: [10900/57525] ( 18.9%) | Loss: 0.6417 | Speed: 44.4 batches/s | ETA: 17:30\n",
      "  Train: [11000/57525] ( 19.1%) | Loss: 0.6415 | Speed: 44.4 batches/s | ETA: 17:28\n",
      "  Train: [11100/57525] ( 19.3%) | Loss: 0.6416 | Speed: 44.4 batches/s | ETA: 17:25\n",
      "  Train: [11200/57525] ( 19.5%) | Loss: 0.6415 | Speed: 44.4 batches/s | ETA: 17:23\n",
      "  Train: [11300/57525] ( 19.6%) | Loss: 0.6416 | Speed: 44.4 batches/s | ETA: 17:21\n",
      "  Train: [11400/57525] ( 19.8%) | Loss: 0.6415 | Speed: 44.4 batches/s | ETA: 17:19\n",
      "  Train: [11500/57525] ( 20.0%) | Loss: 0.6416 | Speed: 44.4 batches/s | ETA: 17:17\n",
      "  Train: [11600/57525] ( 20.2%) | Loss: 0.6415 | Speed: 44.4 batches/s | ETA: 17:15\n",
      "  Train: [11700/57525] ( 20.3%) | Loss: 0.6414 | Speed: 44.4 batches/s | ETA: 17:12\n",
      "  Train: [11800/57525] ( 20.5%) | Loss: 0.6412 | Speed: 44.3 batches/s | ETA: 17:11\n",
      "  Train: [11900/57525] ( 20.7%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 17:08\n",
      "  Train: [12000/57525] ( 20.9%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 17:06\n",
      "  Train: [12100/57525] ( 21.0%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 17:04\n",
      "  Train: [12200/57525] ( 21.2%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 17:02\n",
      "  Train: [12300/57525] ( 21.4%) | Loss: 0.6412 | Speed: 44.3 batches/s | ETA: 16:59\n",
      "  Train: [12400/57525] ( 21.6%) | Loss: 0.6411 | Speed: 44.3 batches/s | ETA: 16:57\n",
      "  Train: [12500/57525] ( 21.7%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:55\n",
      "  Train: [12600/57525] ( 21.9%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:53\n",
      "  Train: [12700/57525] ( 22.1%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:50\n",
      "  Train: [12800/57525] ( 22.3%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:48\n",
      "  Train: [12900/57525] ( 22.4%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:46\n",
      "  Train: [13000/57525] ( 22.6%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:44\n",
      "  Train: [13100/57525] ( 22.8%) | Loss: 0.6409 | Speed: 44.3 batches/s | ETA: 16:42\n",
      "  Train: [13200/57525] ( 22.9%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:40\n",
      "  Train: [13300/57525] ( 23.1%) | Loss: 0.6409 | Speed: 44.3 batches/s | ETA: 16:37\n",
      "  Train: [13400/57525] ( 23.3%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:35\n",
      "  Train: [13500/57525] ( 23.5%) | Loss: 0.6410 | Speed: 44.3 batches/s | ETA: 16:33\n",
      "  Train: [13600/57525] ( 23.6%) | Loss: 0.6408 | Speed: 44.3 batches/s | ETA: 16:31\n",
      "  Train: [13700/57525] ( 23.8%) | Loss: 0.6408 | Speed: 44.3 batches/s | ETA: 16:29\n",
      "  Train: [13800/57525] ( 24.0%) | Loss: 0.6406 | Speed: 44.3 batches/s | ETA: 16:26\n",
      "  Train: [13900/57525] ( 24.2%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:24\n",
      "  Train: [14000/57525] ( 24.3%) | Loss: 0.6405 | Speed: 44.3 batches/s | ETA: 16:22\n",
      "  Train: [14100/57525] ( 24.5%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:20\n",
      "  Train: [14200/57525] ( 24.7%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:17\n",
      "  Train: [14300/57525] ( 24.9%) | Loss: 0.6405 | Speed: 44.3 batches/s | ETA: 16:15\n",
      "  Train: [14400/57525] ( 25.0%) | Loss: 0.6406 | Speed: 44.3 batches/s | ETA: 16:13\n",
      "  Train: [14500/57525] ( 25.2%) | Loss: 0.6405 | Speed: 44.3 batches/s | ETA: 16:11\n",
      "  Train: [14600/57525] ( 25.4%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:08\n",
      "  Train: [14700/57525] ( 25.6%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:06\n",
      "  Train: [14800/57525] ( 25.7%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 16:04\n",
      "  Train: [14900/57525] ( 25.9%) | Loss: 0.6403 | Speed: 44.3 batches/s | ETA: 16:02\n",
      "  Train: [15000/57525] ( 26.1%) | Loss: 0.6404 | Speed: 44.3 batches/s | ETA: 15:59\n",
      "  Train: [15100/57525] ( 26.2%) | Loss: 0.6402 | Speed: 44.3 batches/s | ETA: 15:57\n",
      "  Train: [15200/57525] ( 26.4%) | Loss: 0.6401 | Speed: 44.3 batches/s | ETA: 15:55\n",
      "  Train: [15300/57525] ( 26.6%) | Loss: 0.6401 | Speed: 44.3 batches/s | ETA: 15:52\n",
      "  Train: [15400/57525] ( 26.8%) | Loss: 0.6400 | Speed: 44.3 batches/s | ETA: 15:50\n",
      "  Train: [15500/57525] ( 26.9%) | Loss: 0.6400 | Speed: 44.3 batches/s | ETA: 15:48\n",
      "  Train: [15600/57525] ( 27.1%) | Loss: 0.6400 | Speed: 44.3 batches/s | ETA: 15:46\n",
      "  Train: [15700/57525] ( 27.3%) | Loss: 0.6397 | Speed: 44.3 batches/s | ETA: 15:43\n",
      "  Train: [15800/57525] ( 27.5%) | Loss: 0.6397 | Speed: 44.3 batches/s | ETA: 15:41\n",
      "  Train: [15900/57525] ( 27.6%) | Loss: 0.6396 | Speed: 44.3 batches/s | ETA: 15:39\n",
      "  Train: [16000/57525] ( 27.8%) | Loss: 0.6395 | Speed: 44.3 batches/s | ETA: 15:37\n",
      "  Train: [16100/57525] ( 28.0%) | Loss: 0.6394 | Speed: 44.3 batches/s | ETA: 15:34\n",
      "  Train: [16200/57525] ( 28.2%) | Loss: 0.6393 | Speed: 44.3 batches/s | ETA: 15:32\n",
      "  Train: [16300/57525] ( 28.3%) | Loss: 0.6393 | Speed: 44.3 batches/s | ETA: 15:30\n",
      "  Train: [16400/57525] ( 28.5%) | Loss: 0.6393 | Speed: 44.3 batches/s | ETA: 15:28\n",
      "  Train: [16500/57525] ( 28.7%) | Loss: 0.6395 | Speed: 44.3 batches/s | ETA: 15:25\n",
      "  Train: [16600/57525] ( 28.9%) | Loss: 0.6396 | Speed: 44.3 batches/s | ETA: 15:23\n",
      "  Train: [16700/57525] ( 29.0%) | Loss: 0.6396 | Speed: 44.3 batches/s | ETA: 15:21\n",
      "  Train: [16800/57525] ( 29.2%) | Loss: 0.6396 | Speed: 44.3 batches/s | ETA: 15:18\n",
      "  Train: [16900/57525] ( 29.4%) | Loss: 0.6395 | Speed: 44.3 batches/s | ETA: 15:16\n",
      "  Train: [17000/57525] ( 29.6%) | Loss: 0.6395 | Speed: 44.3 batches/s | ETA: 15:14\n",
      "  Train: [17100/57525] ( 29.7%) | Loss: 0.6394 | Speed: 44.3 batches/s | ETA: 15:11\n",
      "  Train: [17200/57525] ( 29.9%) | Loss: 0.6393 | Speed: 44.3 batches/s | ETA: 15:09\n",
      "  Train: [17300/57525] ( 30.1%) | Loss: 0.6392 | Speed: 44.3 batches/s | ETA: 15:07\n",
      "  Train: [17400/57525] ( 30.2%) | Loss: 0.6392 | Speed: 44.3 batches/s | ETA: 15:05\n",
      "  Train: [17500/57525] ( 30.4%) | Loss: 0.6392 | Speed: 44.3 batches/s | ETA: 15:02\n",
      "  Train: [17600/57525] ( 30.6%) | Loss: 0.6392 | Speed: 44.3 batches/s | ETA: 15:00\n",
      "  Train: [17700/57525] ( 30.8%) | Loss: 0.6390 | Speed: 44.3 batches/s | ETA: 14:58\n",
      "  Train: [17800/57525] ( 30.9%) | Loss: 0.6389 | Speed: 44.3 batches/s | ETA: 14:55\n",
      "  Train: [17900/57525] ( 31.1%) | Loss: 0.6390 | Speed: 44.3 batches/s | ETA: 14:53\n",
      "  Train: [18000/57525] ( 31.3%) | Loss: 0.6390 | Speed: 44.3 batches/s | ETA: 14:51\n",
      "  Train: [18100/57525] ( 31.5%) | Loss: 0.6390 | Speed: 44.3 batches/s | ETA: 14:49\n",
      "  Train: [18200/57525] ( 31.6%) | Loss: 0.6389 | Speed: 44.3 batches/s | ETA: 14:46\n",
      "  Train: [18300/57525] ( 31.8%) | Loss: 0.6389 | Speed: 44.3 batches/s | ETA: 14:44\n",
      "  Train: [18400/57525] ( 32.0%) | Loss: 0.6388 | Speed: 44.4 batches/s | ETA: 14:42\n",
      "  Train: [18500/57525] ( 32.2%) | Loss: 0.6386 | Speed: 44.4 batches/s | ETA: 14:39\n",
      "  Train: [18600/57525] ( 32.3%) | Loss: 0.6386 | Speed: 44.4 batches/s | ETA: 14:37\n",
      "  Train: [18700/57525] ( 32.5%) | Loss: 0.6385 | Speed: 44.4 batches/s | ETA: 14:35\n",
      "  Train: [18800/57525] ( 32.7%) | Loss: 0.6385 | Speed: 44.4 batches/s | ETA: 14:32\n",
      "  Train: [18900/57525] ( 32.9%) | Loss: 0.6385 | Speed: 44.4 batches/s | ETA: 14:30\n",
      "  Train: [19000/57525] ( 33.0%) | Loss: 0.6385 | Speed: 44.4 batches/s | ETA: 14:28\n",
      "  Train: [19100/57525] ( 33.2%) | Loss: 0.6384 | Speed: 44.4 batches/s | ETA: 14:26\n",
      "  Train: [19200/57525] ( 33.4%) | Loss: 0.6383 | Speed: 44.4 batches/s | ETA: 14:23\n",
      "  Train: [19300/57525] ( 33.6%) | Loss: 0.6383 | Speed: 44.4 batches/s | ETA: 14:21\n",
      "  Train: [19400/57525] ( 33.7%) | Loss: 0.6381 | Speed: 44.4 batches/s | ETA: 14:19\n",
      "  Train: [19500/57525] ( 33.9%) | Loss: 0.6381 | Speed: 44.4 batches/s | ETA: 14:17\n",
      "  Train: [19600/57525] ( 34.1%) | Loss: 0.6381 | Speed: 44.4 batches/s | ETA: 14:14\n",
      "  Train: [19700/57525] ( 34.2%) | Loss: 0.6380 | Speed: 44.4 batches/s | ETA: 14:12\n",
      "  Train: [19800/57525] ( 34.4%) | Loss: 0.6380 | Speed: 44.4 batches/s | ETA: 14:10\n",
      "  Train: [19900/57525] ( 34.6%) | Loss: 0.6379 | Speed: 44.4 batches/s | ETA: 14:08\n",
      "  Train: [20000/57525] ( 34.8%) | Loss: 0.6379 | Speed: 44.4 batches/s | ETA: 14:05\n",
      "  Train: [20100/57525] ( 34.9%) | Loss: 0.6379 | Speed: 44.4 batches/s | ETA: 14:03\n",
      "  Train: [20200/57525] ( 35.1%) | Loss: 0.6379 | Speed: 44.4 batches/s | ETA: 14:01\n",
      "  Train: [20300/57525] ( 35.3%) | Loss: 0.6380 | Speed: 44.4 batches/s | ETA: 13:58\n",
      "  Train: [20400/57525] ( 35.5%) | Loss: 0.6380 | Speed: 44.4 batches/s | ETA: 13:56\n",
      "  Train: [20500/57525] ( 35.6%) | Loss: 0.6378 | Speed: 44.4 batches/s | ETA: 13:54\n",
      "  Train: [20600/57525] ( 35.8%) | Loss: 0.6378 | Speed: 44.4 batches/s | ETA: 13:51\n",
      "  Train: [20700/57525] ( 36.0%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:49\n",
      "  Train: [20800/57525] ( 36.2%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:47\n",
      "  Train: [20900/57525] ( 36.3%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:45\n",
      "  Train: [21000/57525] ( 36.5%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:42\n",
      "  Train: [21100/57525] ( 36.7%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:40\n",
      "  Train: [21200/57525] ( 36.9%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:38\n",
      "  Train: [21300/57525] ( 37.0%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:36\n",
      "  Train: [21400/57525] ( 37.2%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:33\n",
      "  Train: [21500/57525] ( 37.4%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:31\n",
      "  Train: [21600/57525] ( 37.5%) | Loss: 0.6377 | Speed: 44.4 batches/s | ETA: 13:29\n",
      "  Train: [21700/57525] ( 37.7%) | Loss: 0.6375 | Speed: 44.4 batches/s | ETA: 13:26\n",
      "  Train: [21800/57525] ( 37.9%) | Loss: 0.6375 | Speed: 44.4 batches/s | ETA: 13:24\n",
      "  Train: [21900/57525] ( 38.1%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:22\n",
      "  Train: [22000/57525] ( 38.2%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:20\n",
      "  Train: [22100/57525] ( 38.4%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:17\n",
      "  Train: [22200/57525] ( 38.6%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:15\n",
      "  Train: [22300/57525] ( 38.8%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:13\n",
      "  Train: [22400/57525] ( 38.9%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:11\n",
      "  Train: [22500/57525] ( 39.1%) | Loss: 0.6376 | Speed: 44.4 batches/s | ETA: 13:08\n",
      "  Train: [22600/57525] ( 39.3%) | Loss: 0.6374 | Speed: 44.4 batches/s | ETA: 13:06\n",
      "  Train: [22700/57525] ( 39.5%) | Loss: 0.6374 | Speed: 44.4 batches/s | ETA: 13:04\n",
      "  Train: [22800/57525] ( 39.6%) | Loss: 0.6374 | Speed: 44.4 batches/s | ETA: 13:02\n",
      "  Train: [22900/57525] ( 39.8%) | Loss: 0.6373 | Speed: 44.4 batches/s | ETA: 12:59\n",
      "  Train: [23000/57525] ( 40.0%) | Loss: 0.6372 | Speed: 44.4 batches/s | ETA: 12:57\n",
      "  Train: [23100/57525] ( 40.2%) | Loss: 0.6370 | Speed: 44.4 batches/s | ETA: 12:55\n",
      "  Train: [23200/57525] ( 40.3%) | Loss: 0.6370 | Speed: 44.4 batches/s | ETA: 12:53\n",
      "  Train: [23300/57525] ( 40.5%) | Loss: 0.6370 | Speed: 44.4 batches/s | ETA: 12:50\n",
      "  Train: [23400/57525] ( 40.7%) | Loss: 0.6369 | Speed: 44.4 batches/s | ETA: 12:48\n",
      "  Train: [23500/57525] ( 40.9%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:46\n",
      "  Train: [23600/57525] ( 41.0%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:43\n",
      "  Train: [23700/57525] ( 41.2%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:41\n",
      "  Train: [23800/57525] ( 41.4%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:39\n",
      "  Train: [23900/57525] ( 41.5%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:37\n",
      "  Train: [24000/57525] ( 41.7%) | Loss: 0.6368 | Speed: 44.4 batches/s | ETA: 12:34\n",
      "  Train: [24100/57525] ( 41.9%) | Loss: 0.6367 | Speed: 44.4 batches/s | ETA: 12:32\n",
      "  Train: [24200/57525] ( 42.1%) | Loss: 0.6367 | Speed: 44.4 batches/s | ETA: 12:30\n",
      "  Train: [24300/57525] ( 42.2%) | Loss: 0.6366 | Speed: 44.4 batches/s | ETA: 12:27\n",
      "  Train: [24400/57525] ( 42.4%) | Loss: 0.6366 | Speed: 44.4 batches/s | ETA: 12:25\n",
      "  Train: [24500/57525] ( 42.6%) | Loss: 0.6366 | Speed: 44.4 batches/s | ETA: 12:23\n",
      "  Train: [24600/57525] ( 42.8%) | Loss: 0.6366 | Speed: 44.4 batches/s | ETA: 12:21\n",
      "  Train: [24700/57525] ( 42.9%) | Loss: 0.6366 | Speed: 44.4 batches/s | ETA: 12:18\n",
      "  Train: [24800/57525] ( 43.1%) | Loss: 0.6365 | Speed: 44.4 batches/s | ETA: 12:16\n",
      "  Train: [24900/57525] ( 43.3%) | Loss: 0.6365 | Speed: 44.4 batches/s | ETA: 12:14\n",
      "  Train: [25000/57525] ( 43.5%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:12\n",
      "  Train: [25100/57525] ( 43.6%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:09\n",
      "  Train: [25200/57525] ( 43.8%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:07\n",
      "  Train: [25300/57525] ( 44.0%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:05\n",
      "  Train: [25400/57525] ( 44.2%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:02\n",
      "  Train: [25500/57525] ( 44.3%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 12:00\n",
      "  Train: [25600/57525] ( 44.5%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 11:58\n",
      "  Train: [25700/57525] ( 44.7%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 11:56\n",
      "  Train: [25800/57525] ( 44.9%) | Loss: 0.6364 | Speed: 44.4 batches/s | ETA: 11:53\n",
      "  Train: [25900/57525] ( 45.0%) | Loss: 0.6363 | Speed: 44.4 batches/s | ETA: 11:51\n",
      "  Train: [26000/57525] ( 45.2%) | Loss: 0.6362 | Speed: 44.4 batches/s | ETA: 11:49\n",
      "  Train: [26100/57525] ( 45.4%) | Loss: 0.6362 | Speed: 44.4 batches/s | ETA: 11:47\n",
      "  Train: [26200/57525] ( 45.5%) | Loss: 0.6362 | Speed: 44.4 batches/s | ETA: 11:44\n",
      "  Train: [26300/57525] ( 45.7%) | Loss: 0.6362 | Speed: 44.4 batches/s | ETA: 11:42\n",
      "  Train: [26400/57525] ( 45.9%) | Loss: 0.6361 | Speed: 44.4 batches/s | ETA: 11:40\n",
      "  Train: [26500/57525] ( 46.1%) | Loss: 0.6361 | Speed: 44.4 batches/s | ETA: 11:38\n",
      "  Train: [26600/57525] ( 46.2%) | Loss: 0.6361 | Speed: 44.4 batches/s | ETA: 11:35\n",
      "  Train: [26700/57525] ( 46.4%) | Loss: 0.6360 | Speed: 44.4 batches/s | ETA: 11:33\n",
      "  Train: [26800/57525] ( 46.6%) | Loss: 0.6359 | Speed: 44.4 batches/s | ETA: 11:31\n",
      "  Train: [26900/57525] ( 46.8%) | Loss: 0.6358 | Speed: 44.4 batches/s | ETA: 11:29\n",
      "  Train: [27000/57525] ( 46.9%) | Loss: 0.6358 | Speed: 44.4 batches/s | ETA: 11:26\n",
      "  Train: [27100/57525] ( 47.1%) | Loss: 0.6358 | Speed: 44.4 batches/s | ETA: 11:24\n",
      "  Train: [27200/57525] ( 47.3%) | Loss: 0.6357 | Speed: 44.4 batches/s | ETA: 11:22\n",
      "  Train: [27300/57525] ( 47.5%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 11:19\n",
      "  Train: [27400/57525] ( 47.6%) | Loss: 0.6358 | Speed: 44.5 batches/s | ETA: 11:17\n",
      "  Train: [27500/57525] ( 47.8%) | Loss: 0.6358 | Speed: 44.5 batches/s | ETA: 11:15\n",
      "  Train: [27600/57525] ( 48.0%) | Loss: 0.6357 | Speed: 44.4 batches/s | ETA: 11:13\n",
      "  Train: [27700/57525] ( 48.2%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 11:10\n",
      "  Train: [27800/57525] ( 48.3%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 11:08\n",
      "  Train: [27900/57525] ( 48.5%) | Loss: 0.6357 | Speed: 44.4 batches/s | ETA: 11:06\n",
      "  Train: [28000/57525] ( 48.7%) | Loss: 0.6357 | Speed: 44.4 batches/s | ETA: 11:04\n",
      "  Train: [28100/57525] ( 48.8%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 11:01\n",
      "  Train: [28200/57525] ( 49.0%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:59\n",
      "  Train: [28300/57525] ( 49.2%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:57\n",
      "  Train: [28400/57525] ( 49.4%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:55\n",
      "  Train: [28500/57525] ( 49.5%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:52\n",
      "  Train: [28600/57525] ( 49.7%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:50\n",
      "  Train: [28700/57525] ( 49.9%) | Loss: 0.6358 | Speed: 44.5 batches/s | ETA: 10:48\n",
      "  Train: [28800/57525] ( 50.1%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:46\n",
      "  Train: [28900/57525] ( 50.2%) | Loss: 0.6357 | Speed: 44.5 batches/s | ETA: 10:43\n",
      "  Train: [29000/57525] ( 50.4%) | Loss: 0.6356 | Speed: 44.5 batches/s | ETA: 10:41\n",
      "  Train: [29100/57525] ( 50.6%) | Loss: 0.6356 | Speed: 44.5 batches/s | ETA: 10:39\n",
      "  Train: [29200/57525] ( 50.8%) | Loss: 0.6356 | Speed: 44.5 batches/s | ETA: 10:37\n",
      "  Train: [29300/57525] ( 50.9%) | Loss: 0.6355 | Speed: 44.5 batches/s | ETA: 10:34\n",
      "  Train: [29400/57525] ( 51.1%) | Loss: 0.6355 | Speed: 44.5 batches/s | ETA: 10:32\n",
      "  Train: [29500/57525] ( 51.3%) | Loss: 0.6354 | Speed: 44.5 batches/s | ETA: 10:30\n",
      "  Train: [29600/57525] ( 51.5%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:27\n",
      "  Train: [29700/57525] ( 51.6%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:25\n",
      "  Train: [29800/57525] ( 51.8%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:23\n",
      "  Train: [29900/57525] ( 52.0%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:21\n",
      "  Train: [30000/57525] ( 52.2%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:18\n",
      "  Train: [30100/57525] ( 52.3%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:16\n",
      "  Train: [30200/57525] ( 52.5%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:14\n",
      "  Train: [30300/57525] ( 52.7%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:12\n",
      "  Train: [30400/57525] ( 52.8%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:09\n",
      "  Train: [30500/57525] ( 53.0%) | Loss: 0.6353 | Speed: 44.5 batches/s | ETA: 10:07\n",
      "  Train: [30600/57525] ( 53.2%) | Loss: 0.6352 | Speed: 44.5 batches/s | ETA: 10:05\n",
      "  Train: [30700/57525] ( 53.4%) | Loss: 0.6351 | Speed: 44.5 batches/s | ETA: 10:03\n",
      "  Train: [30800/57525] ( 53.5%) | Loss: 0.6350 | Speed: 44.5 batches/s | ETA: 10:00\n",
      "  Train: [30900/57525] ( 53.7%) | Loss: 0.6351 | Speed: 44.5 batches/s | ETA: 09:58\n",
      "  Train: [31000/57525] ( 53.9%) | Loss: 0.6350 | Speed: 44.5 batches/s | ETA: 09:56\n",
      "  Train: [31100/57525] ( 54.1%) | Loss: 0.6350 | Speed: 44.5 batches/s | ETA: 09:54\n",
      "  Train: [31200/57525] ( 54.2%) | Loss: 0.6350 | Speed: 44.5 batches/s | ETA: 09:51\n",
      "  Train: [31300/57525] ( 54.4%) | Loss: 0.6349 | Speed: 44.5 batches/s | ETA: 09:49\n",
      "  Train: [31400/57525] ( 54.6%) | Loss: 0.6348 | Speed: 44.5 batches/s | ETA: 09:47\n",
      "  Train: [31500/57525] ( 54.8%) | Loss: 0.6348 | Speed: 44.5 batches/s | ETA: 09:44\n",
      "  Train: [31600/57525] ( 54.9%) | Loss: 0.6348 | Speed: 44.5 batches/s | ETA: 09:42\n",
      "  Train: [31700/57525] ( 55.1%) | Loss: 0.6347 | Speed: 44.5 batches/s | ETA: 09:40\n",
      "  Train: [31800/57525] ( 55.3%) | Loss: 0.6347 | Speed: 44.5 batches/s | ETA: 09:38\n",
      "  Train: [31900/57525] ( 55.5%) | Loss: 0.6347 | Speed: 44.5 batches/s | ETA: 09:35\n",
      "  Train: [32000/57525] ( 55.6%) | Loss: 0.6346 | Speed: 44.5 batches/s | ETA: 09:33\n",
      "  Train: [32100/57525] ( 55.8%) | Loss: 0.6345 | Speed: 44.5 batches/s | ETA: 09:31\n",
      "  Train: [32200/57525] ( 56.0%) | Loss: 0.6345 | Speed: 44.5 batches/s | ETA: 09:29\n",
      "  Train: [32300/57525] ( 56.1%) | Loss: 0.6345 | Speed: 44.5 batches/s | ETA: 09:26\n",
      "  Train: [32400/57525] ( 56.3%) | Loss: 0.6344 | Speed: 44.5 batches/s | ETA: 09:24\n",
      "  Train: [32500/57525] ( 56.5%) | Loss: 0.6344 | Speed: 44.5 batches/s | ETA: 09:22\n",
      "  Train: [32600/57525] ( 56.7%) | Loss: 0.6343 | Speed: 44.5 batches/s | ETA: 09:20\n",
      "  Train: [32700/57525] ( 56.8%) | Loss: 0.6342 | Speed: 44.5 batches/s | ETA: 09:17\n",
      "  Train: [32800/57525] ( 57.0%) | Loss: 0.6342 | Speed: 44.5 batches/s | ETA: 09:15\n",
      "  Train: [32900/57525] ( 57.2%) | Loss: 0.6342 | Speed: 44.5 batches/s | ETA: 09:13\n",
      "  Train: [33000/57525] ( 57.4%) | Loss: 0.6342 | Speed: 44.5 batches/s | ETA: 09:11\n",
      "  Train: [33100/57525] ( 57.5%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 09:08\n",
      "  Train: [33200/57525] ( 57.7%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 09:06\n",
      "  Train: [33300/57525] ( 57.9%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 09:04\n",
      "  Train: [33400/57525] ( 58.1%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 09:02\n",
      "  Train: [33500/57525] ( 58.2%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 08:59\n",
      "  Train: [33600/57525] ( 58.4%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 08:57\n",
      "  Train: [33700/57525] ( 58.6%) | Loss: 0.6341 | Speed: 44.5 batches/s | ETA: 08:55\n",
      "  Train: [33800/57525] ( 58.8%) | Loss: 0.6340 | Speed: 44.5 batches/s | ETA: 08:53\n",
      "  Train: [33900/57525] ( 58.9%) | Loss: 0.6340 | Speed: 44.5 batches/s | ETA: 08:50\n",
      "  Train: [34000/57525] ( 59.1%) | Loss: 0.6339 | Speed: 44.5 batches/s | ETA: 08:48\n",
      "  Train: [34100/57525] ( 59.3%) | Loss: 0.6339 | Speed: 44.5 batches/s | ETA: 08:46\n",
      "  Train: [34200/57525] ( 59.5%) | Loss: 0.6338 | Speed: 44.5 batches/s | ETA: 08:44\n",
      "  Train: [34300/57525] ( 59.6%) | Loss: 0.6338 | Speed: 44.5 batches/s | ETA: 08:41\n",
      "  Train: [34400/57525] ( 59.8%) | Loss: 0.6338 | Speed: 44.5 batches/s | ETA: 08:39\n",
      "  Train: [34500/57525] ( 60.0%) | Loss: 0.6337 | Speed: 44.5 batches/s | ETA: 08:37\n",
      "  Train: [34600/57525] ( 60.1%) | Loss: 0.6337 | Speed: 44.5 batches/s | ETA: 08:35\n",
      "  Train: [34700/57525] ( 60.3%) | Loss: 0.6337 | Speed: 44.5 batches/s | ETA: 08:32\n",
      "  Train: [34800/57525] ( 60.5%) | Loss: 0.6336 | Speed: 44.5 batches/s | ETA: 08:30\n",
      "  Train: [34900/57525] ( 60.7%) | Loss: 0.6336 | Speed: 44.5 batches/s | ETA: 08:28\n",
      "  Train: [35000/57525] ( 60.8%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:26\n",
      "  Train: [35100/57525] ( 61.0%) | Loss: 0.6336 | Speed: 44.5 batches/s | ETA: 08:23\n",
      "  Train: [35200/57525] ( 61.2%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:21\n",
      "  Train: [35300/57525] ( 61.4%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 08:19\n",
      "  Train: [35400/57525] ( 61.5%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:17\n",
      "  Train: [35500/57525] ( 61.7%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 08:14\n",
      "  Train: [35600/57525] ( 61.9%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 08:12\n",
      "  Train: [35700/57525] ( 62.1%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 08:10\n",
      "  Train: [35800/57525] ( 62.2%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:08\n",
      "  Train: [35900/57525] ( 62.4%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:05\n",
      "  Train: [36000/57525] ( 62.6%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:03\n",
      "  Train: [36100/57525] ( 62.8%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 08:01\n",
      "  Train: [36200/57525] ( 62.9%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 07:59\n",
      "  Train: [36300/57525] ( 63.1%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 07:56\n",
      "  Train: [36400/57525] ( 63.3%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 07:54\n",
      "  Train: [36500/57525] ( 63.5%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 07:52\n",
      "  Train: [36600/57525] ( 63.6%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 07:50\n",
      "  Train: [36700/57525] ( 63.8%) | Loss: 0.6335 | Speed: 44.5 batches/s | ETA: 07:47\n",
      "  Train: [36800/57525] ( 64.0%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 07:45\n",
      "  Train: [36900/57525] ( 64.1%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 07:43\n",
      "  Train: [37000/57525] ( 64.3%) | Loss: 0.6334 | Speed: 44.5 batches/s | ETA: 07:41\n",
      "  Train: [37100/57525] ( 64.5%) | Loss: 0.6333 | Speed: 44.5 batches/s | ETA: 07:38\n",
      "  Train: [37200/57525] ( 64.7%) | Loss: 0.6333 | Speed: 44.5 batches/s | ETA: 07:36\n",
      "  Train: [37300/57525] ( 64.8%) | Loss: 0.6332 | Speed: 44.5 batches/s | ETA: 07:34\n",
      "  Train: [37400/57525] ( 65.0%) | Loss: 0.6332 | Speed: 44.5 batches/s | ETA: 07:32\n",
      "  Train: [37500/57525] ( 65.2%) | Loss: 0.6332 | Speed: 44.5 batches/s | ETA: 07:29\n",
      "  Train: [37600/57525] ( 65.4%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:27\n",
      "  Train: [37700/57525] ( 65.5%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:25\n",
      "  Train: [37800/57525] ( 65.7%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:23\n",
      "  Train: [37900/57525] ( 65.9%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:20\n",
      "  Train: [38000/57525] ( 66.1%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:18\n",
      "  Train: [38100/57525] ( 66.2%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:16\n",
      "  Train: [38200/57525] ( 66.4%) | Loss: 0.6331 | Speed: 44.5 batches/s | ETA: 07:14\n",
      "  Train: [38300/57525] ( 66.6%) | Loss: 0.6330 | Speed: 44.5 batches/s | ETA: 07:11\n",
      "  Train: [38400/57525] ( 66.8%) | Loss: 0.6330 | Speed: 44.5 batches/s | ETA: 07:09\n",
      "  Train: [38500/57525] ( 66.9%) | Loss: 0.6330 | Speed: 44.5 batches/s | ETA: 07:07\n",
      "  Train: [38600/57525] ( 67.1%) | Loss: 0.6329 | Speed: 44.5 batches/s | ETA: 07:05\n",
      "  Train: [38700/57525] ( 67.3%) | Loss: 0.6329 | Speed: 44.5 batches/s | ETA: 07:02\n",
      "  Train: [38800/57525] ( 67.4%) | Loss: 0.6329 | Speed: 44.5 batches/s | ETA: 07:00\n",
      "  Train: [38900/57525] ( 67.6%) | Loss: 0.6328 | Speed: 44.5 batches/s | ETA: 06:58\n",
      "  Train: [39000/57525] ( 67.8%) | Loss: 0.6328 | Speed: 44.5 batches/s | ETA: 06:56\n",
      "  Train: [39100/57525] ( 68.0%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:53\n",
      "  Train: [39200/57525] ( 68.1%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:51\n",
      "  Train: [39300/57525] ( 68.3%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:49\n",
      "  Train: [39400/57525] ( 68.5%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:47\n",
      "  Train: [39500/57525] ( 68.7%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:44\n",
      "  Train: [39600/57525] ( 68.8%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:42\n",
      "  Train: [39700/57525] ( 69.0%) | Loss: 0.6327 | Speed: 44.5 batches/s | ETA: 06:40\n",
      "  Train: [39800/57525] ( 69.2%) | Loss: 0.6326 | Speed: 44.5 batches/s | ETA: 06:38\n",
      "  Train: [39900/57525] ( 69.4%) | Loss: 0.6326 | Speed: 44.5 batches/s | ETA: 06:35\n",
      "  Train: [40000/57525] ( 69.5%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:33\n",
      "  Train: [40100/57525] ( 69.7%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:31\n",
      "  Train: [40200/57525] ( 69.9%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:29\n",
      "  Train: [40300/57525] ( 70.1%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:26\n",
      "  Train: [40400/57525] ( 70.2%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:24\n",
      "  Train: [40500/57525] ( 70.4%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:22\n",
      "  Train: [40600/57525] ( 70.6%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:20\n",
      "  Train: [40700/57525] ( 70.8%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:17\n",
      "  Train: [40800/57525] ( 70.9%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:15\n",
      "  Train: [40900/57525] ( 71.1%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:13\n",
      "  Train: [41000/57525] ( 71.3%) | Loss: 0.6325 | Speed: 44.5 batches/s | ETA: 06:11\n",
      "  Train: [41100/57525] ( 71.4%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:08\n",
      "  Train: [41200/57525] ( 71.6%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:06\n",
      "  Train: [41300/57525] ( 71.8%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:04\n",
      "  Train: [41400/57525] ( 72.0%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 06:02\n",
      "  Train: [41500/57525] ( 72.1%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 05:59\n",
      "  Train: [41600/57525] ( 72.3%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 05:57\n",
      "  Train: [41700/57525] ( 72.5%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 05:55\n",
      "  Train: [41800/57525] ( 72.7%) | Loss: 0.6324 | Speed: 44.5 batches/s | ETA: 05:53\n",
      "  Train: [41900/57525] ( 72.8%) | Loss: 0.6323 | Speed: 44.5 batches/s | ETA: 05:50\n",
      "  Train: [42000/57525] ( 73.0%) | Loss: 0.6323 | Speed: 44.5 batches/s | ETA: 05:48\n",
      "  Train: [42100/57525] ( 73.2%) | Loss: 0.6322 | Speed: 44.5 batches/s | ETA: 05:46\n",
      "  Train: [42200/57525] ( 73.4%) | Loss: 0.6322 | Speed: 44.5 batches/s | ETA: 05:44\n",
      "  Train: [42300/57525] ( 73.5%) | Loss: 0.6321 | Speed: 44.5 batches/s | ETA: 05:41\n",
      "  Train: [42400/57525] ( 73.7%) | Loss: 0.6320 | Speed: 44.5 batches/s | ETA: 05:39\n",
      "  Train: [42500/57525] ( 73.9%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:37\n",
      "  Train: [42600/57525] ( 74.1%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:35\n",
      "  Train: [42700/57525] ( 74.2%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:32\n",
      "  Train: [42800/57525] ( 74.4%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:30\n",
      "  Train: [42900/57525] ( 74.6%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:28\n",
      "  Train: [43000/57525] ( 74.8%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:26\n",
      "  Train: [43100/57525] ( 74.9%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:23\n",
      "  Train: [43200/57525] ( 75.1%) | Loss: 0.6319 | Speed: 44.5 batches/s | ETA: 05:21\n",
      "  Train: [43300/57525] ( 75.3%) | Loss: 0.6318 | Speed: 44.5 batches/s | ETA: 05:19\n",
      "  Train: [43400/57525] ( 75.4%) | Loss: 0.6318 | Speed: 44.5 batches/s | ETA: 05:17\n",
      "  Train: [43500/57525] ( 75.6%) | Loss: 0.6318 | Speed: 44.5 batches/s | ETA: 05:14\n",
      "  Train: [43600/57525] ( 75.8%) | Loss: 0.6318 | Speed: 44.5 batches/s | ETA: 05:12\n",
      "  Train: [43700/57525] ( 76.0%) | Loss: 0.6317 | Speed: 44.5 batches/s | ETA: 05:10\n",
      "  Train: [43800/57525] ( 76.1%) | Loss: 0.6316 | Speed: 44.5 batches/s | ETA: 05:08\n",
      "  Train: [43900/57525] ( 76.3%) | Loss: 0.6317 | Speed: 44.5 batches/s | ETA: 05:05\n",
      "  Train: [44000/57525] ( 76.5%) | Loss: 0.6316 | Speed: 44.5 batches/s | ETA: 05:03\n",
      "  Train: [44100/57525] ( 76.7%) | Loss: 0.6316 | Speed: 44.5 batches/s | ETA: 05:01\n",
      "  Train: [44200/57525] ( 76.8%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:59\n",
      "  Train: [44300/57525] ( 77.0%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:56\n",
      "  Train: [44400/57525] ( 77.2%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:54\n",
      "  Train: [44500/57525] ( 77.4%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:52\n",
      "  Train: [44600/57525] ( 77.5%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:50\n",
      "  Train: [44700/57525] ( 77.7%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:47\n",
      "  Train: [44800/57525] ( 77.9%) | Loss: 0.6315 | Speed: 44.5 batches/s | ETA: 04:45\n",
      "  Train: [44900/57525] ( 78.1%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:43\n",
      "  Train: [45000/57525] ( 78.2%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:41\n",
      "  Train: [45100/57525] ( 78.4%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:39\n",
      "  Train: [45200/57525] ( 78.6%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:36\n",
      "  Train: [45300/57525] ( 78.7%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:34\n",
      "  Train: [45400/57525] ( 78.9%) | Loss: 0.6314 | Speed: 44.5 batches/s | ETA: 04:32\n",
      "  Train: [45500/57525] ( 79.1%) | Loss: 0.6313 | Speed: 44.5 batches/s | ETA: 04:30\n",
      "  Train: [45600/57525] ( 79.3%) | Loss: 0.6312 | Speed: 44.5 batches/s | ETA: 04:27\n",
      "  Train: [45700/57525] ( 79.4%) | Loss: 0.6312 | Speed: 44.5 batches/s | ETA: 04:25\n",
      "  Train: [45800/57525] ( 79.6%) | Loss: 0.6312 | Speed: 44.5 batches/s | ETA: 04:23\n",
      "  Train: [45900/57525] ( 79.8%) | Loss: 0.6311 | Speed: 44.5 batches/s | ETA: 04:21\n",
      "  Train: [46000/57525] ( 80.0%) | Loss: 0.6311 | Speed: 44.5 batches/s | ETA: 04:18\n",
      "  Train: [46100/57525] ( 80.1%) | Loss: 0.6311 | Speed: 44.5 batches/s | ETA: 04:16\n",
      "  Train: [46200/57525] ( 80.3%) | Loss: 0.6310 | Speed: 44.5 batches/s | ETA: 04:14\n",
      "  Train: [46300/57525] ( 80.5%) | Loss: 0.6310 | Speed: 44.5 batches/s | ETA: 04:12\n",
      "  Train: [46400/57525] ( 80.7%) | Loss: 0.6310 | Speed: 44.5 batches/s | ETA: 04:09\n",
      "  Train: [46500/57525] ( 80.8%) | Loss: 0.6309 | Speed: 44.5 batches/s | ETA: 04:07\n",
      "  Train: [46600/57525] ( 81.0%) | Loss: 0.6309 | Speed: 44.5 batches/s | ETA: 04:05\n",
      "  Train: [46700/57525] ( 81.2%) | Loss: 0.6309 | Speed: 44.5 batches/s | ETA: 04:03\n",
      "  Train: [46800/57525] ( 81.4%) | Loss: 0.6309 | Speed: 44.5 batches/s | ETA: 04:00\n",
      "  Train: [46900/57525] ( 81.5%) | Loss: 0.6308 | Speed: 44.5 batches/s | ETA: 03:58\n",
      "  Train: [47000/57525] ( 81.7%) | Loss: 0.6308 | Speed: 44.5 batches/s | ETA: 03:56\n",
      "  Train: [47100/57525] ( 81.9%) | Loss: 0.6308 | Speed: 44.5 batches/s | ETA: 03:54\n",
      "  Train: [47200/57525] ( 82.1%) | Loss: 0.6307 | Speed: 44.5 batches/s | ETA: 03:51\n",
      "  Train: [47300/57525] ( 82.2%) | Loss: 0.6307 | Speed: 44.5 batches/s | ETA: 03:49\n",
      "  Train: [47400/57525] ( 82.4%) | Loss: 0.6307 | Speed: 44.5 batches/s | ETA: 03:47\n",
      "  Train: [47500/57525] ( 82.6%) | Loss: 0.6307 | Speed: 44.5 batches/s | ETA: 03:45\n",
      "  Train: [47600/57525] ( 82.7%) | Loss: 0.6307 | Speed: 44.5 batches/s | ETA: 03:42\n",
      "  Train: [47700/57525] ( 82.9%) | Loss: 0.6306 | Speed: 44.5 batches/s | ETA: 03:40\n",
      "  Train: [47800/57525] ( 83.1%) | Loss: 0.6306 | Speed: 44.5 batches/s | ETA: 03:38\n",
      "  Train: [47900/57525] ( 83.3%) | Loss: 0.6306 | Speed: 44.5 batches/s | ETA: 03:36\n",
      "  Train: [48000/57525] ( 83.4%) | Loss: 0.6306 | Speed: 44.5 batches/s | ETA: 03:34\n",
      "  Train: [48100/57525] ( 83.6%) | Loss: 0.6306 | Speed: 44.5 batches/s | ETA: 03:31\n",
      "  Train: [48200/57525] ( 83.8%) | Loss: 0.6305 | Speed: 44.5 batches/s | ETA: 03:29\n",
      "  Train: [48300/57525] ( 84.0%) | Loss: 0.6305 | Speed: 44.5 batches/s | ETA: 03:27\n",
      "  Train: [48400/57525] ( 84.1%) | Loss: 0.6305 | Speed: 44.5 batches/s | ETA: 03:25\n",
      "  Train: [48500/57525] ( 84.3%) | Loss: 0.6304 | Speed: 44.5 batches/s | ETA: 03:22\n",
      "  Train: [48600/57525] ( 84.5%) | Loss: 0.6304 | Speed: 44.5 batches/s | ETA: 03:20\n",
      "  Train: [48700/57525] ( 84.7%) | Loss: 0.6304 | Speed: 44.5 batches/s | ETA: 03:18\n",
      "  Train: [48800/57525] ( 84.8%) | Loss: 0.6303 | Speed: 44.5 batches/s | ETA: 03:16\n",
      "  Train: [48900/57525] ( 85.0%) | Loss: 0.6303 | Speed: 44.5 batches/s | ETA: 03:13\n",
      "  Train: [49000/57525] ( 85.2%) | Loss: 0.6303 | Speed: 44.5 batches/s | ETA: 03:11\n",
      "  Train: [49100/57525] ( 85.4%) | Loss: 0.6303 | Speed: 44.5 batches/s | ETA: 03:09\n",
      "  Train: [49200/57525] ( 85.5%) | Loss: 0.6303 | Speed: 44.5 batches/s | ETA: 03:07\n",
      "  Train: [49300/57525] ( 85.7%) | Loss: 0.6302 | Speed: 44.5 batches/s | ETA: 03:04\n",
      "  Train: [49400/57525] ( 85.9%) | Loss: 0.6301 | Speed: 44.5 batches/s | ETA: 03:02\n",
      "  Train: [49500/57525] ( 86.0%) | Loss: 0.6301 | Speed: 44.5 batches/s | ETA: 03:00\n",
      "  Train: [49600/57525] ( 86.2%) | Loss: 0.6301 | Speed: 44.5 batches/s | ETA: 02:58\n",
      "  Train: [49700/57525] ( 86.4%) | Loss: 0.6302 | Speed: 44.5 batches/s | ETA: 02:55\n",
      "  Train: [49800/57525] ( 86.6%) | Loss: 0.6301 | Speed: 44.5 batches/s | ETA: 02:53\n",
      "  Train: [49900/57525] ( 86.7%) | Loss: 0.6300 | Speed: 44.5 batches/s | ETA: 02:51\n",
      "  Train: [50000/57525] ( 86.9%) | Loss: 0.6300 | Speed: 44.5 batches/s | ETA: 02:49\n",
      "  Train: [50100/57525] ( 87.1%) | Loss: 0.6300 | Speed: 44.5 batches/s | ETA: 02:46\n",
      "  Train: [50200/57525] ( 87.3%) | Loss: 0.6300 | Speed: 44.5 batches/s | ETA: 02:44\n",
      "  Train: [50300/57525] ( 87.4%) | Loss: 0.6300 | Speed: 44.5 batches/s | ETA: 02:42\n",
      "  Train: [50400/57525] ( 87.6%) | Loss: 0.6299 | Speed: 44.5 batches/s | ETA: 02:40\n",
      "  Train: [50500/57525] ( 87.8%) | Loss: 0.6299 | Speed: 44.5 batches/s | ETA: 02:37\n",
      "  Train: [50600/57525] ( 88.0%) | Loss: 0.6299 | Speed: 44.5 batches/s | ETA: 02:35\n",
      "  Train: [50700/57525] ( 88.1%) | Loss: 0.6298 | Speed: 44.5 batches/s | ETA: 02:33\n",
      "  Train: [50800/57525] ( 88.3%) | Loss: 0.6298 | Speed: 44.5 batches/s | ETA: 02:31\n",
      "  Train: [50900/57525] ( 88.5%) | Loss: 0.6298 | Speed: 44.5 batches/s | ETA: 02:28\n",
      "  Train: [51000/57525] ( 88.7%) | Loss: 0.6297 | Speed: 44.5 batches/s | ETA: 02:26\n",
      "  Train: [51100/57525] ( 88.8%) | Loss: 0.6297 | Speed: 44.5 batches/s | ETA: 02:24\n",
      "  Train: [51200/57525] ( 89.0%) | Loss: 0.6296 | Speed: 44.5 batches/s | ETA: 02:22\n",
      "  Train: [51300/57525] ( 89.2%) | Loss: 0.6296 | Speed: 44.5 batches/s | ETA: 02:19\n",
      "  Train: [51400/57525] ( 89.4%) | Loss: 0.6296 | Speed: 44.5 batches/s | ETA: 02:17\n",
      "  Train: [51500/57525] ( 89.5%) | Loss: 0.6296 | Speed: 44.5 batches/s | ETA: 02:15\n",
      "  Train: [51600/57525] ( 89.7%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:13\n",
      "  Train: [51700/57525] ( 89.9%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:10\n",
      "  Train: [51800/57525] ( 90.0%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:08\n",
      "  Train: [51900/57525] ( 90.2%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:06\n",
      "  Train: [52000/57525] ( 90.4%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:04\n",
      "  Train: [52100/57525] ( 90.6%) | Loss: 0.6295 | Speed: 44.5 batches/s | ETA: 02:01\n",
      "  Train: [52200/57525] ( 90.7%) | Loss: 0.6294 | Speed: 44.5 batches/s | ETA: 01:59\n",
      "  Train: [52300/57525] ( 90.9%) | Loss: 0.6294 | Speed: 44.5 batches/s | ETA: 01:57\n",
      "  Train: [52400/57525] ( 91.1%) | Loss: 0.6294 | Speed: 44.5 batches/s | ETA: 01:55\n",
      "  Train: [52500/57525] ( 91.3%) | Loss: 0.6294 | Speed: 44.5 batches/s | ETA: 01:52\n",
      "  Train: [52600/57525] ( 91.4%) | Loss: 0.6293 | Speed: 44.5 batches/s | ETA: 01:50\n",
      "  Train: [52700/57525] ( 91.6%) | Loss: 0.6293 | Speed: 44.5 batches/s | ETA: 01:48\n",
      "  Train: [52800/57525] ( 91.8%) | Loss: 0.6293 | Speed: 44.5 batches/s | ETA: 01:46\n",
      "  Train: [52900/57525] ( 92.0%) | Loss: 0.6293 | Speed: 44.5 batches/s | ETA: 01:44\n",
      "  Train: [53000/57525] ( 92.1%) | Loss: 0.6292 | Speed: 44.5 batches/s | ETA: 01:41\n",
      "  Train: [53100/57525] ( 92.3%) | Loss: 0.6292 | Speed: 44.5 batches/s | ETA: 01:39\n",
      "  Train: [53200/57525] ( 92.5%) | Loss: 0.6292 | Speed: 44.5 batches/s | ETA: 01:37\n",
      "  Train: [53300/57525] ( 92.7%) | Loss: 0.6291 | Speed: 44.5 batches/s | ETA: 01:35\n",
      "  Train: [53400/57525] ( 92.8%) | Loss: 0.6291 | Speed: 44.5 batches/s | ETA: 01:32\n",
      "  Train: [53500/57525] ( 93.0%) | Loss: 0.6290 | Speed: 44.5 batches/s | ETA: 01:30\n",
      "  Train: [53600/57525] ( 93.2%) | Loss: 0.6290 | Speed: 44.5 batches/s | ETA: 01:28\n",
      "  Train: [53700/57525] ( 93.4%) | Loss: 0.6289 | Speed: 44.5 batches/s | ETA: 01:26\n",
      "  Train: [53800/57525] ( 93.5%) | Loss: 0.6289 | Speed: 44.5 batches/s | ETA: 01:23\n",
      "  Train: [53900/57525] ( 93.7%) | Loss: 0.6288 | Speed: 44.5 batches/s | ETA: 01:21\n",
      "  Train: [54000/57525] ( 93.9%) | Loss: 0.6288 | Speed: 44.5 batches/s | ETA: 01:19\n",
      "  Train: [54100/57525] ( 94.0%) | Loss: 0.6288 | Speed: 44.5 batches/s | ETA: 01:17\n",
      "  Train: [54200/57525] ( 94.2%) | Loss: 0.6288 | Speed: 44.5 batches/s | ETA: 01:14\n",
      "  Train: [54300/57525] ( 94.4%) | Loss: 0.6287 | Speed: 44.5 batches/s | ETA: 01:12\n",
      "  Train: [54400/57525] ( 94.6%) | Loss: 0.6287 | Speed: 44.5 batches/s | ETA: 01:10\n",
      "  Train: [54500/57525] ( 94.7%) | Loss: 0.6287 | Speed: 44.5 batches/s | ETA: 01:08\n",
      "  Train: [54600/57525] ( 94.9%) | Loss: 0.6287 | Speed: 44.5 batches/s | ETA: 01:05\n",
      "  Train: [54700/57525] ( 95.1%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 01:03\n",
      "  Train: [54800/57525] ( 95.3%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 01:01\n",
      "  Train: [54900/57525] ( 95.4%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 00:59\n",
      "  Train: [55000/57525] ( 95.6%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 00:56\n",
      "  Train: [55100/57525] ( 95.8%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 00:54\n",
      "  Train: [55200/57525] ( 96.0%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 00:52\n",
      "  Train: [55300/57525] ( 96.1%) | Loss: 0.6287 | Speed: 44.4 batches/s | ETA: 00:50\n",
      "  Train: [55400/57525] ( 96.3%) | Loss: 0.6286 | Speed: 44.4 batches/s | ETA: 00:47\n",
      "  Train: [55500/57525] ( 96.5%) | Loss: 0.6286 | Speed: 44.4 batches/s | ETA: 00:45\n",
      "  Train: [55600/57525] ( 96.7%) | Loss: 0.6285 | Speed: 44.4 batches/s | ETA: 00:43\n",
      "  Train: [55700/57525] ( 96.8%) | Loss: 0.6285 | Speed: 44.4 batches/s | ETA: 00:41\n",
      "  Train: [55800/57525] ( 97.0%) | Loss: 0.6285 | Speed: 44.4 batches/s | ETA: 00:38\n",
      "  Train: [55900/57525] ( 97.2%) | Loss: 0.6285 | Speed: 44.4 batches/s | ETA: 00:36\n",
      "  Train: [56000/57525] ( 97.3%) | Loss: 0.6285 | Speed: 44.4 batches/s | ETA: 00:34\n",
      "  Train: [56100/57525] ( 97.5%) | Loss: 0.6284 | Speed: 44.4 batches/s | ETA: 00:32\n",
      "  Train: [56200/57525] ( 97.7%) | Loss: 0.6284 | Speed: 44.4 batches/s | ETA: 00:29\n",
      "  Train: [56300/57525] ( 97.9%) | Loss: 0.6284 | Speed: 44.4 batches/s | ETA: 00:27\n",
      "  Train: [56400/57525] ( 98.0%) | Loss: 0.6283 | Speed: 44.4 batches/s | ETA: 00:25\n",
      "  Train: [56500/57525] ( 98.2%) | Loss: 0.6283 | Speed: 44.4 batches/s | ETA: 00:23\n",
      "  Train: [56600/57525] ( 98.4%) | Loss: 0.6282 | Speed: 44.4 batches/s | ETA: 00:20\n",
      "  Train: [56700/57525] ( 98.6%) | Loss: 0.6282 | Speed: 44.4 batches/s | ETA: 00:18\n",
      "  Train: [56800/57525] ( 98.7%) | Loss: 0.6282 | Speed: 44.4 batches/s | ETA: 00:16\n",
      "  Train: [56900/57525] ( 98.9%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:14\n",
      "  Train: [57000/57525] ( 99.1%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:11\n",
      "  Train: [57100/57525] ( 99.3%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:09\n",
      "  Train: [57200/57525] ( 99.4%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:07\n",
      "  Train: [57300/57525] ( 99.6%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:05\n",
      "  Train: [57400/57525] ( 99.8%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:02\n",
      "  Train: [57500/57525] (100.0%) | Loss: 0.6281 | Speed: 44.4 batches/s | ETA: 00:00\n",
      "  Running validation...\n",
      "    Val: [  50/7191] (  0.7%)\n",
      "    Val: [ 100/7191] (  1.4%)\n",
      "    Val: [ 150/7191] (  2.1%)\n",
      "    Val: [ 200/7191] (  2.8%)\n",
      "    Val: [ 250/7191] (  3.5%)\n",
      "    Val: [ 300/7191] (  4.2%)\n",
      "    Val: [ 350/7191] (  4.9%)\n",
      "    Val: [ 400/7191] (  5.6%)\n",
      "    Val: [ 450/7191] (  6.3%)\n",
      "    Val: [ 500/7191] (  7.0%)\n",
      "    Val: [ 550/7191] (  7.6%)\n",
      "    Val: [ 600/7191] (  8.3%)\n",
      "    Val: [ 650/7191] (  9.0%)\n",
      "    Val: [ 700/7191] (  9.7%)\n",
      "    Val: [ 750/7191] ( 10.4%)\n",
      "    Val: [ 800/7191] ( 11.1%)\n",
      "    Val: [ 850/7191] ( 11.8%)\n",
      "    Val: [ 900/7191] ( 12.5%)\n",
      "    Val: [ 950/7191] ( 13.2%)\n",
      "    Val: [1000/7191] ( 13.9%)\n",
      "    Val: [1050/7191] ( 14.6%)\n",
      "    Val: [1100/7191] ( 15.3%)\n",
      "    Val: [1150/7191] ( 16.0%)\n",
      "    Val: [1200/7191] ( 16.7%)\n",
      "    Val: [1250/7191] ( 17.4%)\n",
      "    Val: [1300/7191] ( 18.1%)\n",
      "    Val: [1350/7191] ( 18.8%)\n",
      "    Val: [1400/7191] ( 19.5%)\n",
      "    Val: [1450/7191] ( 20.2%)\n",
      "    Val: [1500/7191] ( 20.9%)\n",
      "    Val: [1550/7191] ( 21.6%)\n",
      "    Val: [1600/7191] ( 22.3%)\n",
      "    Val: [1650/7191] ( 22.9%)\n",
      "    Val: [1700/7191] ( 23.6%)\n",
      "    Val: [1750/7191] ( 24.3%)\n",
      "    Val: [1800/7191] ( 25.0%)\n",
      "    Val: [1850/7191] ( 25.7%)\n",
      "    Val: [1900/7191] ( 26.4%)\n",
      "    Val: [1950/7191] ( 27.1%)\n",
      "    Val: [2000/7191] ( 27.8%)\n",
      "    Val: [2050/7191] ( 28.5%)\n",
      "    Val: [2100/7191] ( 29.2%)\n",
      "    Val: [2150/7191] ( 29.9%)\n",
      "    Val: [2200/7191] ( 30.6%)\n",
      "    Val: [2250/7191] ( 31.3%)\n",
      "    Val: [2300/7191] ( 32.0%)\n",
      "    Val: [2350/7191] ( 32.7%)\n",
      "    Val: [2400/7191] ( 33.4%)\n",
      "    Val: [2450/7191] ( 34.1%)\n",
      "    Val: [2500/7191] ( 34.8%)\n",
      "    Val: [2550/7191] ( 35.5%)\n",
      "    Val: [2600/7191] ( 36.2%)\n",
      "    Val: [2650/7191] ( 36.9%)\n",
      "    Val: [2700/7191] ( 37.5%)\n",
      "    Val: [2750/7191] ( 38.2%)\n",
      "    Val: [2800/7191] ( 38.9%)\n",
      "    Val: [2850/7191] ( 39.6%)\n",
      "    Val: [2900/7191] ( 40.3%)\n",
      "    Val: [2950/7191] ( 41.0%)\n",
      "    Val: [3000/7191] ( 41.7%)\n",
      "    Val: [3050/7191] ( 42.4%)\n",
      "    Val: [3100/7191] ( 43.1%)\n",
      "    Val: [3150/7191] ( 43.8%)\n",
      "    Val: [3200/7191] ( 44.5%)\n",
      "    Val: [3250/7191] ( 45.2%)\n",
      "    Val: [3300/7191] ( 45.9%)\n",
      "    Val: [3350/7191] ( 46.6%)\n",
      "    Val: [3400/7191] ( 47.3%)\n",
      "    Val: [3450/7191] ( 48.0%)\n",
      "    Val: [3500/7191] ( 48.7%)\n",
      "    Val: [3550/7191] ( 49.4%)\n",
      "    Val: [3600/7191] ( 50.1%)\n",
      "    Val: [3650/7191] ( 50.8%)\n",
      "    Val: [3700/7191] ( 51.5%)\n",
      "    Val: [3750/7191] ( 52.1%)\n",
      "    Val: [3800/7191] ( 52.8%)\n",
      "    Val: [3850/7191] ( 53.5%)\n",
      "    Val: [3900/7191] ( 54.2%)\n",
      "    Val: [3950/7191] ( 54.9%)\n",
      "    Val: [4000/7191] ( 55.6%)\n",
      "    Val: [4050/7191] ( 56.3%)\n",
      "    Val: [4100/7191] ( 57.0%)\n",
      "    Val: [4150/7191] ( 57.7%)\n",
      "    Val: [4200/7191] ( 58.4%)\n",
      "    Val: [4250/7191] ( 59.1%)\n",
      "    Val: [4300/7191] ( 59.8%)\n",
      "    Val: [4350/7191] ( 60.5%)\n",
      "    Val: [4400/7191] ( 61.2%)\n",
      "    Val: [4450/7191] ( 61.9%)\n",
      "    Val: [4500/7191] ( 62.6%)\n",
      "    Val: [4550/7191] ( 63.3%)\n",
      "    Val: [4600/7191] ( 64.0%)\n",
      "    Val: [4650/7191] ( 64.7%)\n",
      "    Val: [4700/7191] ( 65.4%)\n",
      "    Val: [4750/7191] ( 66.1%)\n",
      "    Val: [4800/7191] ( 66.8%)\n",
      "    Val: [4850/7191] ( 67.4%)\n",
      "    Val: [4900/7191] ( 68.1%)\n",
      "    Val: [4950/7191] ( 68.8%)\n",
      "    Val: [5000/7191] ( 69.5%)\n",
      "    Val: [5050/7191] ( 70.2%)\n",
      "    Val: [5100/7191] ( 70.9%)\n",
      "    Val: [5150/7191] ( 71.6%)\n",
      "    Val: [5200/7191] ( 72.3%)\n",
      "    Val: [5250/7191] ( 73.0%)\n",
      "    Val: [5300/7191] ( 73.7%)\n",
      "    Val: [5350/7191] ( 74.4%)\n",
      "    Val: [5400/7191] ( 75.1%)\n",
      "    Val: [5450/7191] ( 75.8%)\n",
      "    Val: [5500/7191] ( 76.5%)\n",
      "    Val: [5550/7191] ( 77.2%)\n",
      "    Val: [5600/7191] ( 77.9%)\n",
      "    Val: [5650/7191] ( 78.6%)\n",
      "    Val: [5700/7191] ( 79.3%)\n",
      "    Val: [5750/7191] ( 80.0%)\n",
      "    Val: [5800/7191] ( 80.7%)\n",
      "    Val: [5850/7191] ( 81.4%)\n",
      "    Val: [5900/7191] ( 82.0%)\n",
      "    Val: [5950/7191] ( 82.7%)\n",
      "    Val: [6000/7191] ( 83.4%)\n",
      "    Val: [6050/7191] ( 84.1%)\n",
      "    Val: [6100/7191] ( 84.8%)\n",
      "    Val: [6150/7191] ( 85.5%)\n",
      "    Val: [6200/7191] ( 86.2%)\n",
      "    Val: [6250/7191] ( 86.9%)\n",
      "    Val: [6300/7191] ( 87.6%)\n",
      "    Val: [6350/7191] ( 88.3%)\n",
      "    Val: [6400/7191] ( 89.0%)\n",
      "    Val: [6450/7191] ( 89.7%)\n",
      "    Val: [6500/7191] ( 90.4%)\n",
      "    Val: [6550/7191] ( 91.1%)\n",
      "    Val: [6600/7191] ( 91.8%)\n",
      "    Val: [6650/7191] ( 92.5%)\n",
      "    Val: [6700/7191] ( 93.2%)\n",
      "    Val: [6750/7191] ( 93.9%)\n",
      "    Val: [6800/7191] ( 94.6%)\n",
      "    Val: [6850/7191] ( 95.3%)\n",
      "    Val: [6900/7191] ( 96.0%)\n",
      "    Val: [6950/7191] ( 96.6%)\n",
      "    Val: [7000/7191] ( 97.3%)\n",
      "    Val: [7050/7191] ( 98.0%)\n",
      "    Val: [7100/7191] ( 98.7%)\n",
      "    Val: [7150/7191] ( 99.4%)\n",
      "\n",
      "  Epoch 02 Summary:\n",
      "    Train MSE (norm): 0.6281 | Val MSE (norm): 0.5917\n",
      "    Time: Train=21.6min, Val=0.9min, Total=22.5min\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 03/5\n",
      "============================================================\n",
      "  Train: [  100/57525] (  0.2%) | Loss: 0.6126 | Speed: 30.9 batches/s | ETA: 30:56\n",
      "  Train: [  200/57525] (  0.3%) | Loss: 0.6053 | Speed: 36.4 batches/s | ETA: 26:16\n",
      "  Train: [  300/57525] (  0.5%) | Loss: 0.6062 | Speed: 38.5 batches/s | ETA: 24:45\n",
      "  Train: [  400/57525] (  0.7%) | Loss: 0.6072 | Speed: 39.8 batches/s | ETA: 23:56\n",
      "  Train: [  500/57525] (  0.9%) | Loss: 0.6085 | Speed: 40.6 batches/s | ETA: 23:25\n",
      "  Train: [  600/57525] (  1.0%) | Loss: 0.6107 | Speed: 41.2 batches/s | ETA: 23:01\n",
      "  Train: [  700/57525] (  1.2%) | Loss: 0.6094 | Speed: 41.7 batches/s | ETA: 22:44\n",
      "  Train: [  800/57525] (  1.4%) | Loss: 0.6077 | Speed: 42.0 batches/s | ETA: 22:30\n",
      "  Train: [  900/57525] (  1.6%) | Loss: 0.6077 | Speed: 42.2 batches/s | ETA: 22:20\n",
      "  Train: [ 1000/57525] (  1.7%) | Loss: 0.6066 | Speed: 42.4 batches/s | ETA: 22:11\n",
      "  Train: [ 1100/57525] (  1.9%) | Loss: 0.6081 | Speed: 42.6 batches/s | ETA: 22:03\n",
      "  Train: [ 1200/57525] (  2.1%) | Loss: 0.6094 | Speed: 42.7 batches/s | ETA: 21:59\n",
      "  Train: [ 1300/57525] (  2.3%) | Loss: 0.6105 | Speed: 42.8 batches/s | ETA: 21:54\n",
      "  Train: [ 1400/57525] (  2.4%) | Loss: 0.6108 | Speed: 42.9 batches/s | ETA: 21:49\n",
      "  Train: [ 1500/57525] (  2.6%) | Loss: 0.6101 | Speed: 43.0 batches/s | ETA: 21:44\n",
      "  Train: [ 1600/57525] (  2.8%) | Loss: 0.6097 | Speed: 43.1 batches/s | ETA: 21:38\n",
      "  Train: [ 1700/57525] (  3.0%) | Loss: 0.6087 | Speed: 43.1 batches/s | ETA: 21:34\n",
      "  Train: [ 1800/57525] (  3.1%) | Loss: 0.6090 | Speed: 43.2 batches/s | ETA: 21:29\n",
      "  Train: [ 1900/57525] (  3.3%) | Loss: 0.6103 | Speed: 43.3 batches/s | ETA: 21:25\n",
      "  Train: [ 2000/57525] (  3.5%) | Loss: 0.6100 | Speed: 43.3 batches/s | ETA: 21:20\n",
      "  Train: [ 2100/57525] (  3.7%) | Loss: 0.6099 | Speed: 43.4 batches/s | ETA: 21:17\n",
      "  Train: [ 2200/57525] (  3.8%) | Loss: 0.6090 | Speed: 43.4 batches/s | ETA: 21:13\n",
      "  Train: [ 2300/57525] (  4.0%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 21:10\n",
      "  Train: [ 2400/57525] (  4.2%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 21:06\n",
      "  Train: [ 2500/57525] (  4.3%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 21:04\n",
      "  Train: [ 2600/57525] (  4.5%) | Loss: 0.6084 | Speed: 43.5 batches/s | ETA: 21:01\n",
      "  Train: [ 2700/57525] (  4.7%) | Loss: 0.6084 | Speed: 43.6 batches/s | ETA: 20:58\n",
      "  Train: [ 2800/57525] (  4.9%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 20:55\n",
      "  Train: [ 2900/57525] (  5.0%) | Loss: 0.6075 | Speed: 43.6 batches/s | ETA: 20:52\n",
      "  Train: [ 3000/57525] (  5.2%) | Loss: 0.6076 | Speed: 43.6 batches/s | ETA: 20:49\n",
      "  Train: [ 3100/57525] (  5.4%) | Loss: 0.6079 | Speed: 43.7 batches/s | ETA: 20:46\n",
      "  Train: [ 3200/57525] (  5.6%) | Loss: 0.6084 | Speed: 43.7 batches/s | ETA: 20:44\n",
      "  Train: [ 3300/57525] (  5.7%) | Loss: 0.6086 | Speed: 43.7 batches/s | ETA: 20:41\n",
      "  Train: [ 3400/57525] (  5.9%) | Loss: 0.6087 | Speed: 43.7 batches/s | ETA: 20:39\n",
      "  Train: [ 3500/57525] (  6.1%) | Loss: 0.6079 | Speed: 43.7 batches/s | ETA: 20:36\n",
      "  Train: [ 3600/57525] (  6.3%) | Loss: 0.6076 | Speed: 43.7 batches/s | ETA: 20:33\n",
      "  Train: [ 3700/57525] (  6.4%) | Loss: 0.6077 | Speed: 43.7 batches/s | ETA: 20:30\n",
      "  Train: [ 3800/57525] (  6.6%) | Loss: 0.6078 | Speed: 43.7 batches/s | ETA: 20:28\n",
      "  Train: [ 3900/57525] (  6.8%) | Loss: 0.6074 | Speed: 43.8 batches/s | ETA: 20:25\n",
      "  Train: [ 4000/57525] (  7.0%) | Loss: 0.6075 | Speed: 43.8 batches/s | ETA: 20:22\n",
      "  Train: [ 4100/57525] (  7.1%) | Loss: 0.6079 | Speed: 43.8 batches/s | ETA: 20:20\n",
      "  Train: [ 4200/57525] (  7.3%) | Loss: 0.6078 | Speed: 43.8 batches/s | ETA: 20:17\n",
      "  Train: [ 4300/57525] (  7.5%) | Loss: 0.6080 | Speed: 43.8 batches/s | ETA: 20:14\n",
      "  Train: [ 4400/57525] (  7.6%) | Loss: 0.6082 | Speed: 43.8 batches/s | ETA: 20:12\n",
      "  Train: [ 4500/57525] (  7.8%) | Loss: 0.6083 | Speed: 43.8 batches/s | ETA: 20:09\n",
      "  Train: [ 4600/57525] (  8.0%) | Loss: 0.6086 | Speed: 43.8 batches/s | ETA: 20:07\n",
      "  Train: [ 4700/57525] (  8.2%) | Loss: 0.6090 | Speed: 43.9 batches/s | ETA: 20:04\n",
      "  Train: [ 4800/57525] (  8.3%) | Loss: 0.6094 | Speed: 43.9 batches/s | ETA: 20:01\n",
      "  Train: [ 4900/57525] (  8.5%) | Loss: 0.6095 | Speed: 43.9 batches/s | ETA: 19:59\n",
      "  Train: [ 5000/57525] (  8.7%) | Loss: 0.6098 | Speed: 43.9 batches/s | ETA: 19:56\n",
      "  Train: [ 5100/57525] (  8.9%) | Loss: 0.6097 | Speed: 43.9 batches/s | ETA: 19:53\n",
      "  Train: [ 5200/57525] (  9.0%) | Loss: 0.6094 | Speed: 43.9 batches/s | ETA: 19:52\n",
      "  Train: [ 5300/57525] (  9.2%) | Loss: 0.6094 | Speed: 43.9 batches/s | ETA: 19:49\n",
      "  Train: [ 5400/57525] (  9.4%) | Loss: 0.6092 | Speed: 43.9 batches/s | ETA: 19:47\n",
      "  Train: [ 5500/57525] (  9.6%) | Loss: 0.6092 | Speed: 43.9 batches/s | ETA: 19:45\n",
      "  Train: [ 5600/57525] (  9.7%) | Loss: 0.6093 | Speed: 43.9 batches/s | ETA: 19:42\n",
      "  Train: [ 5700/57525] (  9.9%) | Loss: 0.6094 | Speed: 43.9 batches/s | ETA: 19:40\n",
      "  Train: [ 5800/57525] ( 10.1%) | Loss: 0.6095 | Speed: 43.9 batches/s | ETA: 19:37\n",
      "  Train: [ 5900/57525] ( 10.3%) | Loss: 0.6098 | Speed: 43.9 batches/s | ETA: 19:35\n",
      "  Train: [ 6000/57525] ( 10.4%) | Loss: 0.6097 | Speed: 43.9 batches/s | ETA: 19:32\n",
      "  Train: [ 6100/57525] ( 10.6%) | Loss: 0.6100 | Speed: 44.0 batches/s | ETA: 19:30\n",
      "  Train: [ 6200/57525] ( 10.8%) | Loss: 0.6105 | Speed: 44.0 batches/s | ETA: 19:27\n",
      "  Train: [ 6300/57525] ( 11.0%) | Loss: 0.6108 | Speed: 44.0 batches/s | ETA: 19:25\n",
      "  Train: [ 6400/57525] ( 11.1%) | Loss: 0.6113 | Speed: 44.0 batches/s | ETA: 19:23\n",
      "  Train: [ 6500/57525] ( 11.3%) | Loss: 0.6111 | Speed: 43.9 batches/s | ETA: 19:21\n",
      "  Train: [ 6600/57525] ( 11.5%) | Loss: 0.6111 | Speed: 43.9 batches/s | ETA: 19:19\n",
      "  Train: [ 6700/57525] ( 11.6%) | Loss: 0.6111 | Speed: 43.9 batches/s | ETA: 19:16\n",
      "  Train: [ 6800/57525] ( 11.8%) | Loss: 0.6112 | Speed: 43.9 batches/s | ETA: 19:14\n",
      "  Train: [ 6900/57525] ( 12.0%) | Loss: 0.6110 | Speed: 43.9 batches/s | ETA: 19:11\n",
      "  Train: [ 7000/57525] ( 12.2%) | Loss: 0.6109 | Speed: 44.0 batches/s | ETA: 19:09\n",
      "  Train: [ 7100/57525] ( 12.3%) | Loss: 0.6108 | Speed: 44.0 batches/s | ETA: 19:07\n",
      "  Train: [ 7200/57525] ( 12.5%) | Loss: 0.6105 | Speed: 44.0 batches/s | ETA: 19:04\n",
      "  Train: [ 7300/57525] ( 12.7%) | Loss: 0.6105 | Speed: 44.0 batches/s | ETA: 19:02\n",
      "  Train: [ 7400/57525] ( 12.9%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 18:59\n",
      "  Train: [ 7500/57525] ( 13.0%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 18:57\n",
      "  Train: [ 7600/57525] ( 13.2%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 18:55\n",
      "  Train: [ 7700/57525] ( 13.4%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 18:52\n",
      "  Train: [ 7800/57525] ( 13.6%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 18:50\n",
      "  Train: [ 7900/57525] ( 13.7%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 18:48\n",
      "  Train: [ 8000/57525] ( 13.9%) | Loss: 0.6106 | Speed: 44.0 batches/s | ETA: 18:46\n",
      "  Train: [ 8100/57525] ( 14.1%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 18:43\n",
      "  Train: [ 8200/57525] ( 14.3%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 18:41\n",
      "  Train: [ 8300/57525] ( 14.4%) | Loss: 0.6102 | Speed: 44.0 batches/s | ETA: 18:39\n",
      "  Train: [ 8400/57525] ( 14.6%) | Loss: 0.6100 | Speed: 44.0 batches/s | ETA: 18:36\n",
      "  Train: [ 8500/57525] ( 14.8%) | Loss: 0.6098 | Speed: 44.0 batches/s | ETA: 18:34\n",
      "  Train: [ 8600/57525] ( 15.0%) | Loss: 0.6098 | Speed: 44.0 batches/s | ETA: 18:32\n",
      "  Train: [ 8700/57525] ( 15.1%) | Loss: 0.6097 | Speed: 44.0 batches/s | ETA: 18:29\n",
      "  Train: [ 8800/57525] ( 15.3%) | Loss: 0.6095 | Speed: 44.0 batches/s | ETA: 18:27\n",
      "  Train: [ 8900/57525] ( 15.5%) | Loss: 0.6095 | Speed: 44.0 batches/s | ETA: 18:24\n",
      "  Train: [ 9000/57525] ( 15.6%) | Loss: 0.6096 | Speed: 44.0 batches/s | ETA: 18:22\n",
      "  Train: [ 9100/57525] ( 15.8%) | Loss: 0.6094 | Speed: 44.0 batches/s | ETA: 18:19\n",
      "  Train: [ 9200/57525] ( 16.0%) | Loss: 0.6093 | Speed: 44.0 batches/s | ETA: 18:17\n",
      "  Train: [ 9300/57525] ( 16.2%) | Loss: 0.6092 | Speed: 44.0 batches/s | ETA: 18:15\n",
      "  Train: [ 9400/57525] ( 16.3%) | Loss: 0.6094 | Speed: 44.0 batches/s | ETA: 18:13\n",
      "  Train: [ 9500/57525] ( 16.5%) | Loss: 0.6094 | Speed: 44.0 batches/s | ETA: 18:11\n",
      "  Train: [ 9600/57525] ( 16.7%) | Loss: 0.6094 | Speed: 44.0 batches/s | ETA: 18:08\n",
      "  Train: [ 9700/57525] ( 16.9%) | Loss: 0.6099 | Speed: 44.0 batches/s | ETA: 18:06\n",
      "  Train: [ 9800/57525] ( 17.0%) | Loss: 0.6100 | Speed: 44.0 batches/s | ETA: 18:04\n",
      "  Train: [ 9900/57525] ( 17.2%) | Loss: 0.6100 | Speed: 44.0 batches/s | ETA: 18:01\n",
      "  Train: [10000/57525] ( 17.4%) | Loss: 0.6102 | Speed: 44.0 batches/s | ETA: 17:59\n",
      "  Train: [10100/57525] ( 17.6%) | Loss: 0.6101 | Speed: 44.0 batches/s | ETA: 17:57\n",
      "  Train: [10200/57525] ( 17.7%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 17:54\n",
      "  Train: [10300/57525] ( 17.9%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 17:52\n",
      "  Train: [10400/57525] ( 18.1%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 17:50\n",
      "  Train: [10500/57525] ( 18.3%) | Loss: 0.6102 | Speed: 44.0 batches/s | ETA: 17:47\n",
      "  Train: [10600/57525] ( 18.4%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 17:45\n",
      "  Train: [10700/57525] ( 18.6%) | Loss: 0.6105 | Speed: 44.0 batches/s | ETA: 17:43\n",
      "  Train: [10800/57525] ( 18.8%) | Loss: 0.6105 | Speed: 44.1 batches/s | ETA: 17:40\n",
      "  Train: [10900/57525] ( 18.9%) | Loss: 0.6105 | Speed: 44.1 batches/s | ETA: 17:38\n",
      "  Train: [11000/57525] ( 19.1%) | Loss: 0.6105 | Speed: 44.1 batches/s | ETA: 17:35\n",
      "  Train: [11100/57525] ( 19.3%) | Loss: 0.6104 | Speed: 44.1 batches/s | ETA: 17:33\n",
      "  Train: [11200/57525] ( 19.5%) | Loss: 0.6105 | Speed: 44.1 batches/s | ETA: 17:31\n",
      "  Train: [11300/57525] ( 19.6%) | Loss: 0.6107 | Speed: 44.1 batches/s | ETA: 17:29\n",
      "  Train: [11400/57525] ( 19.8%) | Loss: 0.6107 | Speed: 44.1 batches/s | ETA: 17:26\n",
      "  Train: [11500/57525] ( 20.0%) | Loss: 0.6107 | Speed: 44.1 batches/s | ETA: 17:24\n",
      "  Train: [11600/57525] ( 20.2%) | Loss: 0.6106 | Speed: 44.1 batches/s | ETA: 17:22\n",
      "  Train: [11700/57525] ( 20.3%) | Loss: 0.6106 | Speed: 44.1 batches/s | ETA: 17:19\n",
      "  Train: [11800/57525] ( 20.5%) | Loss: 0.6107 | Speed: 44.1 batches/s | ETA: 17:17\n",
      "  Train: [11900/57525] ( 20.7%) | Loss: 0.6110 | Speed: 44.1 batches/s | ETA: 17:15\n",
      "  Train: [12000/57525] ( 20.9%) | Loss: 0.6111 | Speed: 44.1 batches/s | ETA: 17:12\n",
      "  Train: [12100/57525] ( 21.0%) | Loss: 0.6110 | Speed: 44.1 batches/s | ETA: 17:10\n",
      "  Train: [12200/57525] ( 21.2%) | Loss: 0.6110 | Speed: 44.1 batches/s | ETA: 17:08\n",
      "  Train: [12300/57525] ( 21.4%) | Loss: 0.6109 | Speed: 44.1 batches/s | ETA: 17:05\n",
      "  Train: [12400/57525] ( 21.6%) | Loss: 0.6111 | Speed: 44.1 batches/s | ETA: 17:03\n",
      "  Train: [12500/57525] ( 21.7%) | Loss: 0.6110 | Speed: 44.1 batches/s | ETA: 17:01\n",
      "  Train: [12600/57525] ( 21.9%) | Loss: 0.6110 | Speed: 44.1 batches/s | ETA: 16:59\n",
      "  Train: [12700/57525] ( 22.1%) | Loss: 0.6109 | Speed: 44.0 batches/s | ETA: 16:57\n",
      "  Train: [12800/57525] ( 22.3%) | Loss: 0.6108 | Speed: 44.0 batches/s | ETA: 16:55\n",
      "  Train: [12900/57525] ( 22.4%) | Loss: 0.6107 | Speed: 44.0 batches/s | ETA: 16:53\n",
      "  Train: [13000/57525] ( 22.6%) | Loss: 0.6107 | Speed: 44.0 batches/s | ETA: 16:51\n",
      "  Train: [13100/57525] ( 22.8%) | Loss: 0.6107 | Speed: 44.0 batches/s | ETA: 16:49\n",
      "  Train: [13200/57525] ( 22.9%) | Loss: 0.6106 | Speed: 44.0 batches/s | ETA: 16:46\n",
      "  Train: [13300/57525] ( 23.1%) | Loss: 0.6105 | Speed: 44.0 batches/s | ETA: 16:44\n",
      "  Train: [13400/57525] ( 23.3%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 16:42\n",
      "  Train: [13500/57525] ( 23.5%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 16:40\n",
      "  Train: [13600/57525] ( 23.6%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 16:38\n",
      "  Train: [13700/57525] ( 23.8%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 16:36\n",
      "  Train: [13800/57525] ( 24.0%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 16:33\n",
      "  Train: [13900/57525] ( 24.2%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 16:31\n",
      "  Train: [14000/57525] ( 24.3%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 16:29\n",
      "  Train: [14100/57525] ( 24.5%) | Loss: 0.6104 | Speed: 44.0 batches/s | ETA: 16:27\n",
      "  Train: [14200/57525] ( 24.7%) | Loss: 0.6102 | Speed: 44.0 batches/s | ETA: 16:25\n",
      "  Train: [14300/57525] ( 24.9%) | Loss: 0.6103 | Speed: 44.0 batches/s | ETA: 16:23\n",
      "  Train: [14400/57525] ( 25.0%) | Loss: 0.6102 | Speed: 44.0 batches/s | ETA: 16:21\n",
      "  Train: [14500/57525] ( 25.2%) | Loss: 0.6101 | Speed: 44.0 batches/s | ETA: 16:18\n",
      "  Train: [14600/57525] ( 25.4%) | Loss: 0.6103 | Speed: 43.9 batches/s | ETA: 16:16\n",
      "  Train: [14700/57525] ( 25.6%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 16:14\n",
      "  Train: [14800/57525] ( 25.7%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 16:12\n",
      "  Train: [14900/57525] ( 25.9%) | Loss: 0.6104 | Speed: 43.9 batches/s | ETA: 16:10\n",
      "  Train: [15000/57525] ( 26.1%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 16:08\n",
      "  Train: [15100/57525] ( 26.2%) | Loss: 0.6104 | Speed: 43.9 batches/s | ETA: 16:06\n",
      "  Train: [15200/57525] ( 26.4%) | Loss: 0.6103 | Speed: 43.9 batches/s | ETA: 16:03\n",
      "  Train: [15300/57525] ( 26.6%) | Loss: 0.6102 | Speed: 43.9 batches/s | ETA: 16:01\n",
      "  Train: [15400/57525] ( 26.8%) | Loss: 0.6103 | Speed: 43.9 batches/s | ETA: 15:59\n",
      "  Train: [15500/57525] ( 26.9%) | Loss: 0.6104 | Speed: 43.9 batches/s | ETA: 15:57\n",
      "  Train: [15600/57525] ( 27.1%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:54\n",
      "  Train: [15700/57525] ( 27.3%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:52\n",
      "  Train: [15800/57525] ( 27.5%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:50\n",
      "  Train: [15900/57525] ( 27.6%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:48\n",
      "  Train: [16000/57525] ( 27.8%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:46\n",
      "  Train: [16100/57525] ( 28.0%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:44\n",
      "  Train: [16200/57525] ( 28.2%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:42\n",
      "  Train: [16300/57525] ( 28.3%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:39\n",
      "  Train: [16400/57525] ( 28.5%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:37\n",
      "  Train: [16500/57525] ( 28.7%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:35\n",
      "  Train: [16600/57525] ( 28.9%) | Loss: 0.6106 | Speed: 43.9 batches/s | ETA: 15:33\n",
      "  Train: [16700/57525] ( 29.0%) | Loss: 0.6105 | Speed: 43.9 batches/s | ETA: 15:30\n",
      "  Train: [16800/57525] ( 29.2%) | Loss: 0.6104 | Speed: 43.9 batches/s | ETA: 15:28\n",
      "  Train: [16900/57525] ( 29.4%) | Loss: 0.6106 | Speed: 43.8 batches/s | ETA: 15:26\n",
      "  Train: [17000/57525] ( 29.6%) | Loss: 0.6106 | Speed: 43.8 batches/s | ETA: 15:24\n",
      "  Train: [17100/57525] ( 29.7%) | Loss: 0.6104 | Speed: 43.8 batches/s | ETA: 15:22\n",
      "  Train: [17200/57525] ( 29.9%) | Loss: 0.6104 | Speed: 43.8 batches/s | ETA: 15:19\n",
      "  Train: [17300/57525] ( 30.1%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:17\n",
      "  Train: [17400/57525] ( 30.2%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:15\n",
      "  Train: [17500/57525] ( 30.4%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:13\n",
      "  Train: [17600/57525] ( 30.6%) | Loss: 0.6104 | Speed: 43.8 batches/s | ETA: 15:11\n",
      "  Train: [17700/57525] ( 30.8%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:09\n",
      "  Train: [17800/57525] ( 30.9%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:06\n",
      "  Train: [17900/57525] ( 31.1%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:04\n",
      "  Train: [18000/57525] ( 31.3%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:02\n",
      "  Train: [18100/57525] ( 31.5%) | Loss: 0.6105 | Speed: 43.8 batches/s | ETA: 15:00\n",
      "  Train: [18200/57525] ( 31.6%) | Loss: 0.6104 | Speed: 43.8 batches/s | ETA: 14:57\n",
      "  Train: [18300/57525] ( 31.8%) | Loss: 0.6103 | Speed: 43.8 batches/s | ETA: 14:55\n",
      "  Train: [18400/57525] ( 32.0%) | Loss: 0.6103 | Speed: 43.8 batches/s | ETA: 14:53\n",
      "  Train: [18500/57525] ( 32.2%) | Loss: 0.6103 | Speed: 43.8 batches/s | ETA: 14:51\n",
      "  Train: [18600/57525] ( 32.3%) | Loss: 0.6102 | Speed: 43.8 batches/s | ETA: 14:49\n",
      "  Train: [18700/57525] ( 32.5%) | Loss: 0.6102 | Speed: 43.8 batches/s | ETA: 14:46\n",
      "  Train: [18800/57525] ( 32.7%) | Loss: 0.6101 | Speed: 43.8 batches/s | ETA: 14:44\n",
      "  Train: [18900/57525] ( 32.9%) | Loss: 0.6101 | Speed: 43.8 batches/s | ETA: 14:42\n",
      "  Train: [19000/57525] ( 33.0%) | Loss: 0.6101 | Speed: 43.8 batches/s | ETA: 14:40\n",
      "  Train: [19100/57525] ( 33.2%) | Loss: 0.6101 | Speed: 43.8 batches/s | ETA: 14:38\n",
      "  Train: [19200/57525] ( 33.4%) | Loss: 0.6101 | Speed: 43.8 batches/s | ETA: 14:35\n",
      "  Train: [19300/57525] ( 33.6%) | Loss: 0.6102 | Speed: 43.8 batches/s | ETA: 14:33\n",
      "  Train: [19400/57525] ( 33.7%) | Loss: 0.6102 | Speed: 43.8 batches/s | ETA: 14:31\n",
      "  Train: [19500/57525] ( 33.9%) | Loss: 0.6102 | Speed: 43.8 batches/s | ETA: 14:29\n",
      "  Train: [19600/57525] ( 34.1%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 14:26\n",
      "  Train: [19700/57525] ( 34.2%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 14:24\n",
      "  Train: [19800/57525] ( 34.4%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 14:22\n",
      "  Train: [19900/57525] ( 34.6%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 14:20\n",
      "  Train: [20000/57525] ( 34.8%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:17\n",
      "  Train: [20100/57525] ( 34.9%) | Loss: 0.6103 | Speed: 43.7 batches/s | ETA: 14:15\n",
      "  Train: [20200/57525] ( 35.1%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:13\n",
      "  Train: [20300/57525] ( 35.3%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:11\n",
      "  Train: [20400/57525] ( 35.5%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:09\n",
      "  Train: [20500/57525] ( 35.6%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:06\n",
      "  Train: [20600/57525] ( 35.8%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 14:04\n",
      "  Train: [20700/57525] ( 36.0%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:02\n",
      "  Train: [20800/57525] ( 36.2%) | Loss: 0.6102 | Speed: 43.7 batches/s | ETA: 14:00\n",
      "  Train: [20900/57525] ( 36.3%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 13:58\n",
      "  Train: [21000/57525] ( 36.5%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:55\n",
      "  Train: [21100/57525] ( 36.7%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:53\n",
      "  Train: [21200/57525] ( 36.9%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:51\n",
      "  Train: [21300/57525] ( 37.0%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:49\n",
      "  Train: [21400/57525] ( 37.2%) | Loss: 0.6098 | Speed: 43.7 batches/s | ETA: 13:46\n",
      "  Train: [21500/57525] ( 37.4%) | Loss: 0.6098 | Speed: 43.7 batches/s | ETA: 13:44\n",
      "  Train: [21600/57525] ( 37.5%) | Loss: 0.6098 | Speed: 43.7 batches/s | ETA: 13:42\n",
      "  Train: [21700/57525] ( 37.7%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:39\n",
      "  Train: [21800/57525] ( 37.9%) | Loss: 0.6097 | Speed: 43.7 batches/s | ETA: 13:37\n",
      "  Train: [21900/57525] ( 38.1%) | Loss: 0.6097 | Speed: 43.7 batches/s | ETA: 13:35\n",
      "  Train: [22000/57525] ( 38.2%) | Loss: 0.6098 | Speed: 43.7 batches/s | ETA: 13:33\n",
      "  Train: [22100/57525] ( 38.4%) | Loss: 0.6097 | Speed: 43.7 batches/s | ETA: 13:31\n",
      "  Train: [22200/57525] ( 38.6%) | Loss: 0.6098 | Speed: 43.7 batches/s | ETA: 13:28\n",
      "  Train: [22300/57525] ( 38.8%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:26\n",
      "  Train: [22400/57525] ( 38.9%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:24\n",
      "  Train: [22500/57525] ( 39.1%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:22\n",
      "  Train: [22600/57525] ( 39.3%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:19\n",
      "  Train: [22700/57525] ( 39.5%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:17\n",
      "  Train: [22800/57525] ( 39.6%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:15\n",
      "  Train: [22900/57525] ( 39.8%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:12\n",
      "  Train: [23000/57525] ( 40.0%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:10\n",
      "  Train: [23100/57525] ( 40.2%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:08\n",
      "  Train: [23200/57525] ( 40.3%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:06\n",
      "  Train: [23300/57525] ( 40.5%) | Loss: 0.6099 | Speed: 43.7 batches/s | ETA: 13:03\n",
      "  Train: [23400/57525] ( 40.7%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 13:01\n",
      "  Train: [23500/57525] ( 40.9%) | Loss: 0.6100 | Speed: 43.7 batches/s | ETA: 12:59\n",
      "  Train: [23600/57525] ( 41.0%) | Loss: 0.6101 | Speed: 43.7 batches/s | ETA: 12:57\n",
      "  Train: [23700/57525] ( 41.2%) | Loss: 0.6100 | Speed: 43.6 batches/s | ETA: 12:54\n",
      "  Train: [23800/57525] ( 41.4%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 12:52\n",
      "  Train: [23900/57525] ( 41.5%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 12:50\n",
      "  Train: [24000/57525] ( 41.7%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 12:48\n",
      "  Train: [24100/57525] ( 41.9%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:45\n",
      "  Train: [24200/57525] ( 42.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:43\n",
      "  Train: [24300/57525] ( 42.2%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 12:41\n",
      "  Train: [24400/57525] ( 42.4%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:39\n",
      "  Train: [24500/57525] ( 42.6%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:36\n",
      "  Train: [24600/57525] ( 42.8%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 12:34\n",
      "  Train: [24700/57525] ( 42.9%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 12:32\n",
      "  Train: [24800/57525] ( 43.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:29\n",
      "  Train: [24900/57525] ( 43.3%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 12:27\n",
      "  Train: [25000/57525] ( 43.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:25\n",
      "  Train: [25100/57525] ( 43.6%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:23\n",
      "  Train: [25200/57525] ( 43.8%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:20\n",
      "  Train: [25300/57525] ( 44.0%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:18\n",
      "  Train: [25400/57525] ( 44.2%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:16\n",
      "  Train: [25500/57525] ( 44.3%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:14\n",
      "  Train: [25600/57525] ( 44.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 12:11\n",
      "  Train: [25700/57525] ( 44.7%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 12:09\n",
      "  Train: [25800/57525] ( 44.9%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 12:07\n",
      "  Train: [25900/57525] ( 45.0%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 12:04\n",
      "  Train: [26000/57525] ( 45.2%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 12:02\n",
      "  Train: [26100/57525] ( 45.4%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 12:00\n",
      "  Train: [26200/57525] ( 45.5%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:58\n",
      "  Train: [26300/57525] ( 45.7%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 11:55\n",
      "  Train: [26400/57525] ( 45.9%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:53\n",
      "  Train: [26500/57525] ( 46.1%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:51\n",
      "  Train: [26600/57525] ( 46.2%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:48\n",
      "  Train: [26700/57525] ( 46.4%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:46\n",
      "  Train: [26800/57525] ( 46.6%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:44\n",
      "  Train: [26900/57525] ( 46.8%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:42\n",
      "  Train: [27000/57525] ( 46.9%) | Loss: 0.6094 | Speed: 43.6 batches/s | ETA: 11:39\n",
      "  Train: [27100/57525] ( 47.1%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 11:37\n",
      "  Train: [27200/57525] ( 47.3%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 11:35\n",
      "  Train: [27300/57525] ( 47.5%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:33\n",
      "  Train: [27400/57525] ( 47.6%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:30\n",
      "  Train: [27500/57525] ( 47.8%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 11:28\n",
      "  Train: [27600/57525] ( 48.0%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:26\n",
      "  Train: [27700/57525] ( 48.2%) | Loss: 0.6095 | Speed: 43.6 batches/s | ETA: 11:23\n",
      "  Train: [27800/57525] ( 48.3%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:21\n",
      "  Train: [27900/57525] ( 48.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 11:19\n",
      "  Train: [28000/57525] ( 48.7%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 11:17\n",
      "  Train: [28100/57525] ( 48.8%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 11:14\n",
      "  Train: [28200/57525] ( 49.0%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 11:12\n",
      "  Train: [28300/57525] ( 49.2%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:10\n",
      "  Train: [28400/57525] ( 49.4%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:07\n",
      "  Train: [28500/57525] ( 49.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 11:05\n",
      "  Train: [28600/57525] ( 49.7%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:03\n",
      "  Train: [28700/57525] ( 49.9%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 11:01\n",
      "  Train: [28800/57525] ( 50.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 10:58\n",
      "  Train: [28900/57525] ( 50.2%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 10:56\n",
      "  Train: [29000/57525] ( 50.4%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 10:54\n",
      "  Train: [29100/57525] ( 50.6%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 10:51\n",
      "  Train: [29200/57525] ( 50.8%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:49\n",
      "  Train: [29300/57525] ( 50.9%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:47\n",
      "  Train: [29400/57525] ( 51.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 10:45\n",
      "  Train: [29500/57525] ( 51.3%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:42\n",
      "  Train: [29600/57525] ( 51.5%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:40\n",
      "  Train: [29700/57525] ( 51.6%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:38\n",
      "  Train: [29800/57525] ( 51.8%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:35\n",
      "  Train: [29900/57525] ( 52.0%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:33\n",
      "  Train: [30000/57525] ( 52.2%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:31\n",
      "  Train: [30100/57525] ( 52.3%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:29\n",
      "  Train: [30200/57525] ( 52.5%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:26\n",
      "  Train: [30300/57525] ( 52.7%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:24\n",
      "  Train: [30400/57525] ( 52.8%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:22\n",
      "  Train: [30500/57525] ( 53.0%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:20\n",
      "  Train: [30600/57525] ( 53.2%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:17\n",
      "  Train: [30700/57525] ( 53.4%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:15\n",
      "  Train: [30800/57525] ( 53.5%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 10:13\n",
      "  Train: [30900/57525] ( 53.7%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:10\n",
      "  Train: [31000/57525] ( 53.9%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:08\n",
      "  Train: [31100/57525] ( 54.1%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:06\n",
      "  Train: [31200/57525] ( 54.2%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:04\n",
      "  Train: [31300/57525] ( 54.4%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 10:01\n",
      "  Train: [31400/57525] ( 54.6%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:59\n",
      "  Train: [31500/57525] ( 54.8%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:57\n",
      "  Train: [31600/57525] ( 54.9%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:54\n",
      "  Train: [31700/57525] ( 55.1%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:52\n",
      "  Train: [31800/57525] ( 55.3%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:50\n",
      "  Train: [31900/57525] ( 55.5%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:48\n",
      "  Train: [32000/57525] ( 55.6%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 09:45\n",
      "  Train: [32100/57525] ( 55.8%) | Loss: 0.6099 | Speed: 43.6 batches/s | ETA: 09:43\n",
      "  Train: [32200/57525] ( 56.0%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:41\n",
      "  Train: [32300/57525] ( 56.1%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:38\n",
      "  Train: [32400/57525] ( 56.3%) | Loss: 0.6098 | Speed: 43.6 batches/s | ETA: 09:36\n",
      "  Train: [32500/57525] ( 56.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:34\n",
      "  Train: [32600/57525] ( 56.7%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:32\n",
      "  Train: [32700/57525] ( 56.8%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:29\n",
      "  Train: [32800/57525] ( 57.0%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:27\n",
      "  Train: [32900/57525] ( 57.2%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:25\n",
      "  Train: [33000/57525] ( 57.4%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:22\n",
      "  Train: [33100/57525] ( 57.5%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:20\n",
      "  Train: [33200/57525] ( 57.7%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:18\n",
      "  Train: [33300/57525] ( 57.9%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:16\n",
      "  Train: [33400/57525] ( 58.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:13\n",
      "  Train: [33500/57525] ( 58.2%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:11\n",
      "  Train: [33600/57525] ( 58.4%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:09\n",
      "  Train: [33700/57525] ( 58.6%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 09:07\n",
      "  Train: [33800/57525] ( 58.8%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:04\n",
      "  Train: [33900/57525] ( 58.9%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:02\n",
      "  Train: [34000/57525] ( 59.1%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 09:00\n",
      "  Train: [34100/57525] ( 59.3%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 08:57\n",
      "  Train: [34200/57525] ( 59.5%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 08:55\n",
      "  Train: [34300/57525] ( 59.6%) | Loss: 0.6097 | Speed: 43.6 batches/s | ETA: 08:53\n",
      "  Train: [34400/57525] ( 59.8%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:50\n",
      "  Train: [34500/57525] ( 60.0%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:48\n",
      "  Train: [34600/57525] ( 60.1%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:46\n",
      "  Train: [34700/57525] ( 60.3%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:44\n",
      "  Train: [34800/57525] ( 60.5%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:41\n",
      "  Train: [34900/57525] ( 60.7%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:39\n",
      "  Train: [35000/57525] ( 60.8%) | Loss: 0.6096 | Speed: 43.6 batches/s | ETA: 08:37\n",
      "  Train: [35100/57525] ( 61.0%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:34\n",
      "  Train: [35200/57525] ( 61.2%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:32\n",
      "  Train: [35300/57525] ( 61.4%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:30\n",
      "  Train: [35400/57525] ( 61.5%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:28\n",
      "  Train: [35500/57525] ( 61.7%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:25\n",
      "  Train: [35600/57525] ( 61.9%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:23\n",
      "  Train: [35700/57525] ( 62.1%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 08:21\n",
      "  Train: [35800/57525] ( 62.2%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:18\n",
      "  Train: [35900/57525] ( 62.4%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 08:16\n",
      "  Train: [36000/57525] ( 62.6%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 08:14\n",
      "  Train: [36100/57525] ( 62.8%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 08:12\n",
      "  Train: [36200/57525] ( 62.9%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 08:09\n",
      "  Train: [36300/57525] ( 63.1%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:07\n",
      "  Train: [36400/57525] ( 63.3%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:05\n",
      "  Train: [36500/57525] ( 63.5%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:02\n",
      "  Train: [36600/57525] ( 63.6%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 08:00\n",
      "  Train: [36700/57525] ( 63.8%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 07:58\n",
      "  Train: [36800/57525] ( 64.0%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 07:56\n",
      "  Train: [36900/57525] ( 64.1%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 07:53\n",
      "  Train: [37000/57525] ( 64.3%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:51\n",
      "  Train: [37100/57525] ( 64.5%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:49\n",
      "  Train: [37200/57525] ( 64.7%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:46\n",
      "  Train: [37300/57525] ( 64.8%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:44\n",
      "  Train: [37400/57525] ( 65.0%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:42\n",
      "  Train: [37500/57525] ( 65.2%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:40\n",
      "  Train: [37600/57525] ( 65.4%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:37\n",
      "  Train: [37700/57525] ( 65.5%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:35\n",
      "  Train: [37800/57525] ( 65.7%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:33\n",
      "  Train: [37900/57525] ( 65.9%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:30\n",
      "  Train: [38000/57525] ( 66.1%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:28\n",
      "  Train: [38100/57525] ( 66.2%) | Loss: 0.6096 | Speed: 43.5 batches/s | ETA: 07:26\n",
      "  Train: [38200/57525] ( 66.4%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:23\n",
      "  Train: [38300/57525] ( 66.6%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:21\n",
      "  Train: [38400/57525] ( 66.8%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:19\n",
      "  Train: [38500/57525] ( 66.9%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:17\n",
      "  Train: [38600/57525] ( 67.1%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:14\n",
      "  Train: [38700/57525] ( 67.3%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:12\n",
      "  Train: [38800/57525] ( 67.4%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:10\n",
      "  Train: [38900/57525] ( 67.6%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:07\n",
      "  Train: [39000/57525] ( 67.8%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:05\n",
      "  Train: [39100/57525] ( 68.0%) | Loss: 0.6095 | Speed: 43.5 batches/s | ETA: 07:03\n",
      "  Train: [39200/57525] ( 68.1%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 07:01\n",
      "  Train: [39300/57525] ( 68.3%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 06:58\n",
      "  Train: [39400/57525] ( 68.5%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 06:56\n",
      "  Train: [39500/57525] ( 68.7%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 06:54\n",
      "  Train: [39600/57525] ( 68.8%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 06:51\n",
      "  Train: [39700/57525] ( 69.0%) | Loss: 0.6094 | Speed: 43.5 batches/s | ETA: 06:49\n",
      "  Train: [39800/57525] ( 69.2%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 06:47\n",
      "  Train: [39900/57525] ( 69.4%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 06:45\n",
      "  Train: [40000/57525] ( 69.5%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:42\n",
      "  Train: [40100/57525] ( 69.7%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 06:40\n",
      "  Train: [40200/57525] ( 69.9%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:38\n",
      "  Train: [40300/57525] ( 70.1%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:35\n",
      "  Train: [40400/57525] ( 70.2%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:33\n",
      "  Train: [40500/57525] ( 70.4%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:31\n",
      "  Train: [40600/57525] ( 70.6%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:28\n",
      "  Train: [40700/57525] ( 70.8%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:26\n",
      "  Train: [40800/57525] ( 70.9%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:24\n",
      "  Train: [40900/57525] ( 71.1%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:22\n",
      "  Train: [41000/57525] ( 71.3%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:19\n",
      "  Train: [41100/57525] ( 71.4%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:17\n",
      "  Train: [41200/57525] ( 71.6%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:15\n",
      "  Train: [41300/57525] ( 71.8%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:12\n",
      "  Train: [41400/57525] ( 72.0%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:10\n",
      "  Train: [41500/57525] ( 72.1%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:08\n",
      "  Train: [41600/57525] ( 72.3%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 06:06\n",
      "  Train: [41700/57525] ( 72.5%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 06:03\n",
      "  Train: [41800/57525] ( 72.7%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 06:01\n",
      "  Train: [41900/57525] ( 72.8%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:59\n",
      "  Train: [42000/57525] ( 73.0%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:56\n",
      "  Train: [42100/57525] ( 73.2%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:54\n",
      "  Train: [42200/57525] ( 73.4%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:52\n",
      "  Train: [42300/57525] ( 73.5%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 05:49\n",
      "  Train: [42400/57525] ( 73.7%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 05:47\n",
      "  Train: [42500/57525] ( 73.9%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:45\n",
      "  Train: [42600/57525] ( 74.1%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 05:43\n",
      "  Train: [42700/57525] ( 74.2%) | Loss: 0.6093 | Speed: 43.5 batches/s | ETA: 05:40\n",
      "  Train: [42800/57525] ( 74.4%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:38\n",
      "  Train: [42900/57525] ( 74.6%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:36\n",
      "  Train: [43000/57525] ( 74.8%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:33\n",
      "  Train: [43100/57525] ( 74.9%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:31\n",
      "  Train: [43200/57525] ( 75.1%) | Loss: 0.6092 | Speed: 43.5 batches/s | ETA: 05:29\n",
      "  Train: [43300/57525] ( 75.3%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:26\n",
      "  Train: [43400/57525] ( 75.4%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:24\n",
      "  Train: [43500/57525] ( 75.6%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:22\n",
      "  Train: [43600/57525] ( 75.8%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:20\n",
      "  Train: [43700/57525] ( 76.0%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 05:17\n",
      "  Train: [43800/57525] ( 76.1%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 05:15\n",
      "  Train: [43900/57525] ( 76.3%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:13\n",
      "  Train: [44000/57525] ( 76.5%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:10\n",
      "  Train: [44100/57525] ( 76.7%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:08\n",
      "  Train: [44200/57525] ( 76.8%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 05:06\n",
      "  Train: [44300/57525] ( 77.0%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 05:04\n",
      "  Train: [44400/57525] ( 77.2%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 05:01\n",
      "  Train: [44500/57525] ( 77.4%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:59\n",
      "  Train: [44600/57525] ( 77.5%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:57\n",
      "  Train: [44700/57525] ( 77.7%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:54\n",
      "  Train: [44800/57525] ( 77.9%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:52\n",
      "  Train: [44900/57525] ( 78.1%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:50\n",
      "  Train: [45000/57525] ( 78.2%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:47\n",
      "  Train: [45100/57525] ( 78.4%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:45\n",
      "  Train: [45200/57525] ( 78.6%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:43\n",
      "  Train: [45300/57525] ( 78.7%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:41\n",
      "  Train: [45400/57525] ( 78.9%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:38\n",
      "  Train: [45500/57525] ( 79.1%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:36\n",
      "  Train: [45600/57525] ( 79.3%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:34\n",
      "  Train: [45700/57525] ( 79.4%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:31\n",
      "  Train: [45800/57525] ( 79.6%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:29\n",
      "  Train: [45900/57525] ( 79.8%) | Loss: 0.6091 | Speed: 43.5 batches/s | ETA: 04:27\n",
      "  Train: [46000/57525] ( 80.0%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:24\n",
      "  Train: [46100/57525] ( 80.1%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:22\n",
      "  Train: [46200/57525] ( 80.3%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:20\n",
      "  Train: [46300/57525] ( 80.5%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:17\n",
      "  Train: [46400/57525] ( 80.7%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:15\n",
      "  Train: [46500/57525] ( 80.8%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:13\n",
      "  Train: [46600/57525] ( 81.0%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:11\n",
      "  Train: [46700/57525] ( 81.2%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:08\n",
      "  Train: [46800/57525] ( 81.4%) | Loss: 0.6090 | Speed: 43.5 batches/s | ETA: 04:06\n",
      "  Train: [46900/57525] ( 81.5%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:04\n",
      "  Train: [47000/57525] ( 81.7%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 04:01\n",
      "  Train: [47100/57525] ( 81.9%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 03:59\n",
      "  Train: [47200/57525] ( 82.1%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 03:57\n",
      "  Train: [47300/57525] ( 82.2%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:54\n",
      "  Train: [47400/57525] ( 82.4%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:52\n",
      "  Train: [47500/57525] ( 82.6%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 03:50\n",
      "  Train: [47600/57525] ( 82.7%) | Loss: 0.6089 | Speed: 43.5 batches/s | ETA: 03:47\n",
      "  Train: [47700/57525] ( 82.9%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:45\n",
      "  Train: [47800/57525] ( 83.1%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:43\n",
      "  Train: [47900/57525] ( 83.3%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:41\n",
      "  Train: [48000/57525] ( 83.4%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:38\n",
      "  Train: [48100/57525] ( 83.6%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:36\n",
      "  Train: [48200/57525] ( 83.8%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:34\n",
      "  Train: [48300/57525] ( 84.0%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:31\n",
      "  Train: [48400/57525] ( 84.1%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:29\n",
      "  Train: [48500/57525] ( 84.3%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:27\n",
      "  Train: [48600/57525] ( 84.5%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:24\n",
      "  Train: [48700/57525] ( 84.7%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:22\n",
      "  Train: [48800/57525] ( 84.8%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:20\n",
      "  Train: [48900/57525] ( 85.0%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:18\n",
      "  Train: [49000/57525] ( 85.2%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:15\n",
      "  Train: [49100/57525] ( 85.4%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:13\n",
      "  Train: [49200/57525] ( 85.5%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:11\n",
      "  Train: [49300/57525] ( 85.7%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:08\n",
      "  Train: [49400/57525] ( 85.9%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:06\n",
      "  Train: [49500/57525] ( 86.0%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:04\n",
      "  Train: [49600/57525] ( 86.2%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 03:02\n",
      "  Train: [49700/57525] ( 86.4%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:59\n",
      "  Train: [49800/57525] ( 86.6%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:57\n",
      "  Train: [49900/57525] ( 86.7%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:55\n",
      "  Train: [50000/57525] ( 86.9%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:52\n",
      "  Train: [50100/57525] ( 87.1%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:50\n",
      "  Train: [50200/57525] ( 87.3%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:48\n",
      "  Train: [50300/57525] ( 87.4%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:45\n",
      "  Train: [50400/57525] ( 87.6%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:43\n",
      "  Train: [50500/57525] ( 87.8%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:41\n",
      "  Train: [50600/57525] ( 88.0%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:39\n",
      "  Train: [50700/57525] ( 88.1%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:36\n",
      "  Train: [50800/57525] ( 88.3%) | Loss: 0.6088 | Speed: 43.5 batches/s | ETA: 02:34\n",
      "  Train: [50900/57525] ( 88.5%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:32\n",
      "  Train: [51000/57525] ( 88.7%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:29\n",
      "  Train: [51100/57525] ( 88.8%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:27\n",
      "  Train: [51200/57525] ( 89.0%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:25\n",
      "  Train: [51300/57525] ( 89.2%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:22\n",
      "  Train: [51400/57525] ( 89.4%) | Loss: 0.6087 | Speed: 43.5 batches/s | ETA: 02:20\n",
      "  Train: [51500/57525] ( 89.5%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:18\n",
      "  Train: [51600/57525] ( 89.7%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:16\n",
      "  Train: [51700/57525] ( 89.9%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:13\n",
      "  Train: [51800/57525] ( 90.0%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:11\n",
      "  Train: [51900/57525] ( 90.2%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:09\n",
      "  Train: [52000/57525] ( 90.4%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:06\n",
      "  Train: [52100/57525] ( 90.6%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:04\n",
      "  Train: [52200/57525] ( 90.7%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:02\n",
      "  Train: [52300/57525] ( 90.9%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 02:00\n",
      "  Train: [52400/57525] ( 91.1%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:57\n",
      "  Train: [52500/57525] ( 91.3%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:55\n",
      "  Train: [52600/57525] ( 91.4%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:53\n",
      "  Train: [52700/57525] ( 91.6%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:50\n",
      "  Train: [52800/57525] ( 91.8%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:48\n",
      "  Train: [52900/57525] ( 92.0%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:46\n",
      "  Train: [53000/57525] ( 92.1%) | Loss: 0.6086 | Speed: 43.5 batches/s | ETA: 01:43\n",
      "  Train: [53100/57525] ( 92.3%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:41\n",
      "  Train: [53200/57525] ( 92.5%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:39\n",
      "  Train: [53300/57525] ( 92.7%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:37\n",
      "  Train: [53400/57525] ( 92.8%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:34\n",
      "  Train: [53500/57525] ( 93.0%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:32\n",
      "  Train: [53600/57525] ( 93.2%) | Loss: 0.6085 | Speed: 43.5 batches/s | ETA: 01:30\n",
      "  Train: [53700/57525] ( 93.4%) | Loss: 0.6084 | Speed: 43.5 batches/s | ETA: 01:27\n",
      "  Train: [53800/57525] ( 93.5%) | Loss: 0.6084 | Speed: 43.5 batches/s | ETA: 01:25\n",
      "  Train: [53900/57525] ( 93.7%) | Loss: 0.6084 | Speed: 43.5 batches/s | ETA: 01:23\n",
      "  Train: [54000/57525] ( 93.9%) | Loss: 0.6084 | Speed: 43.5 batches/s | ETA: 01:20\n",
      "  Train: [54100/57525] ( 94.0%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:18\n",
      "  Train: [54200/57525] ( 94.2%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:16\n",
      "  Train: [54300/57525] ( 94.4%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:14\n",
      "  Train: [54400/57525] ( 94.6%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:11\n",
      "  Train: [54500/57525] ( 94.7%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:09\n",
      "  Train: [54600/57525] ( 94.9%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:07\n",
      "  Train: [54700/57525] ( 95.1%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:04\n",
      "  Train: [54800/57525] ( 95.3%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:02\n",
      "  Train: [54900/57525] ( 95.4%) | Loss: 0.6083 | Speed: 43.5 batches/s | ETA: 01:00\n",
      "  Train: [55000/57525] ( 95.6%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:58\n",
      "  Train: [55100/57525] ( 95.8%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:55\n",
      "  Train: [55200/57525] ( 96.0%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:53\n",
      "  Train: [55300/57525] ( 96.1%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:51\n",
      "  Train: [55400/57525] ( 96.3%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:48\n",
      "  Train: [55500/57525] ( 96.5%) | Loss: 0.6082 | Speed: 43.5 batches/s | ETA: 00:46\n",
      "  Train: [55600/57525] ( 96.7%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:44\n",
      "  Train: [55700/57525] ( 96.8%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:41\n",
      "  Train: [55800/57525] ( 97.0%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:39\n",
      "  Train: [55900/57525] ( 97.2%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:37\n",
      "  Train: [56000/57525] ( 97.3%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:35\n",
      "  Train: [56100/57525] ( 97.5%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:32\n",
      "  Train: [56200/57525] ( 97.7%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:30\n",
      "  Train: [56300/57525] ( 97.9%) | Loss: 0.6081 | Speed: 43.5 batches/s | ETA: 00:28\n",
      "  Train: [56400/57525] ( 98.0%) | Loss: 0.6081 | Speed: 43.6 batches/s | ETA: 00:25\n",
      "  Train: [56500/57525] ( 98.2%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:23\n",
      "  Train: [56600/57525] ( 98.4%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:21\n",
      "  Train: [56700/57525] ( 98.6%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:18\n",
      "  Train: [56800/57525] ( 98.7%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:16\n",
      "  Train: [56900/57525] ( 98.9%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:14\n",
      "  Train: [57000/57525] ( 99.1%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:12\n",
      "  Train: [57100/57525] ( 99.3%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:09\n",
      "  Train: [57200/57525] ( 99.4%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:07\n",
      "  Train: [57300/57525] ( 99.6%) | Loss: 0.6080 | Speed: 43.6 batches/s | ETA: 00:05\n",
      "  Train: [57400/57525] ( 99.8%) | Loss: 0.6079 | Speed: 43.6 batches/s | ETA: 00:02\n",
      "  Train: [57500/57525] (100.0%) | Loss: 0.6079 | Speed: 43.6 batches/s | ETA: 00:00\n",
      "  Running validation...\n",
      "    Val: [  50/7191] (  0.7%)\n",
      "    Val: [ 100/7191] (  1.4%)\n",
      "    Val: [ 150/7191] (  2.1%)\n",
      "    Val: [ 200/7191] (  2.8%)\n",
      "    Val: [ 250/7191] (  3.5%)\n",
      "    Val: [ 300/7191] (  4.2%)\n",
      "    Val: [ 350/7191] (  4.9%)\n",
      "    Val: [ 400/7191] (  5.6%)\n",
      "    Val: [ 450/7191] (  6.3%)\n",
      "    Val: [ 500/7191] (  7.0%)\n",
      "    Val: [ 550/7191] (  7.6%)\n",
      "    Val: [ 600/7191] (  8.3%)\n",
      "    Val: [ 650/7191] (  9.0%)\n",
      "    Val: [ 700/7191] (  9.7%)\n",
      "    Val: [ 750/7191] ( 10.4%)\n",
      "    Val: [ 800/7191] ( 11.1%)\n",
      "    Val: [ 850/7191] ( 11.8%)\n",
      "    Val: [ 900/7191] ( 12.5%)\n",
      "    Val: [ 950/7191] ( 13.2%)\n",
      "    Val: [1000/7191] ( 13.9%)\n",
      "    Val: [1050/7191] ( 14.6%)\n",
      "    Val: [1100/7191] ( 15.3%)\n",
      "    Val: [1150/7191] ( 16.0%)\n",
      "    Val: [1200/7191] ( 16.7%)\n",
      "    Val: [1250/7191] ( 17.4%)\n",
      "    Val: [1300/7191] ( 18.1%)\n",
      "    Val: [1350/7191] ( 18.8%)\n",
      "    Val: [1400/7191] ( 19.5%)\n",
      "    Val: [1450/7191] ( 20.2%)\n",
      "    Val: [1500/7191] ( 20.9%)\n",
      "    Val: [1550/7191] ( 21.6%)\n",
      "    Val: [1600/7191] ( 22.3%)\n",
      "    Val: [1650/7191] ( 22.9%)\n",
      "    Val: [1700/7191] ( 23.6%)\n",
      "    Val: [1750/7191] ( 24.3%)\n",
      "    Val: [1800/7191] ( 25.0%)\n",
      "    Val: [1850/7191] ( 25.7%)\n",
      "    Val: [1900/7191] ( 26.4%)\n",
      "    Val: [1950/7191] ( 27.1%)\n",
      "    Val: [2000/7191] ( 27.8%)\n",
      "    Val: [2050/7191] ( 28.5%)\n",
      "    Val: [2100/7191] ( 29.2%)\n",
      "    Val: [2150/7191] ( 29.9%)\n",
      "    Val: [2200/7191] ( 30.6%)\n",
      "    Val: [2250/7191] ( 31.3%)\n",
      "    Val: [2300/7191] ( 32.0%)\n",
      "    Val: [2350/7191] ( 32.7%)\n",
      "    Val: [2400/7191] ( 33.4%)\n",
      "    Val: [2450/7191] ( 34.1%)\n",
      "    Val: [2500/7191] ( 34.8%)\n",
      "    Val: [2550/7191] ( 35.5%)\n",
      "    Val: [2600/7191] ( 36.2%)\n",
      "    Val: [2650/7191] ( 36.9%)\n",
      "    Val: [2700/7191] ( 37.5%)\n",
      "    Val: [2750/7191] ( 38.2%)\n",
      "    Val: [2800/7191] ( 38.9%)\n",
      "    Val: [2850/7191] ( 39.6%)\n",
      "    Val: [2900/7191] ( 40.3%)\n",
      "    Val: [2950/7191] ( 41.0%)\n",
      "    Val: [3000/7191] ( 41.7%)\n",
      "    Val: [3050/7191] ( 42.4%)\n",
      "    Val: [3100/7191] ( 43.1%)\n",
      "    Val: [3150/7191] ( 43.8%)\n",
      "    Val: [3200/7191] ( 44.5%)\n",
      "    Val: [3250/7191] ( 45.2%)\n",
      "    Val: [3300/7191] ( 45.9%)\n",
      "    Val: [3350/7191] ( 46.6%)\n",
      "    Val: [3400/7191] ( 47.3%)\n",
      "    Val: [3450/7191] ( 48.0%)\n",
      "    Val: [3500/7191] ( 48.7%)\n",
      "    Val: [3550/7191] ( 49.4%)\n",
      "    Val: [3600/7191] ( 50.1%)\n",
      "    Val: [3650/7191] ( 50.8%)\n",
      "    Val: [3700/7191] ( 51.5%)\n",
      "    Val: [3750/7191] ( 52.1%)\n",
      "    Val: [3800/7191] ( 52.8%)\n",
      "    Val: [3850/7191] ( 53.5%)\n",
      "    Val: [3900/7191] ( 54.2%)\n",
      "    Val: [3950/7191] ( 54.9%)\n",
      "    Val: [4000/7191] ( 55.6%)\n",
      "    Val: [4050/7191] ( 56.3%)\n",
      "    Val: [4100/7191] ( 57.0%)\n",
      "    Val: [4150/7191] ( 57.7%)\n",
      "    Val: [4200/7191] ( 58.4%)\n",
      "    Val: [4250/7191] ( 59.1%)\n",
      "    Val: [4300/7191] ( 59.8%)\n",
      "    Val: [4350/7191] ( 60.5%)\n",
      "    Val: [4400/7191] ( 61.2%)\n",
      "    Val: [4450/7191] ( 61.9%)\n",
      "    Val: [4500/7191] ( 62.6%)\n",
      "    Val: [4550/7191] ( 63.3%)\n",
      "    Val: [4600/7191] ( 64.0%)\n",
      "    Val: [4650/7191] ( 64.7%)\n",
      "    Val: [4700/7191] ( 65.4%)\n",
      "    Val: [4750/7191] ( 66.1%)\n",
      "    Val: [4800/7191] ( 66.8%)\n",
      "    Val: [4850/7191] ( 67.4%)\n",
      "    Val: [4900/7191] ( 68.1%)\n",
      "    Val: [4950/7191] ( 68.8%)\n",
      "    Val: [5000/7191] ( 69.5%)\n",
      "    Val: [5050/7191] ( 70.2%)\n",
      "    Val: [5100/7191] ( 70.9%)\n",
      "    Val: [5150/7191] ( 71.6%)\n",
      "    Val: [5200/7191] ( 72.3%)\n",
      "    Val: [5250/7191] ( 73.0%)\n",
      "    Val: [5300/7191] ( 73.7%)\n",
      "    Val: [5350/7191] ( 74.4%)\n",
      "    Val: [5400/7191] ( 75.1%)\n",
      "    Val: [5450/7191] ( 75.8%)\n",
      "    Val: [5500/7191] ( 76.5%)\n",
      "    Val: [5550/7191] ( 77.2%)\n",
      "    Val: [5600/7191] ( 77.9%)\n",
      "    Val: [5650/7191] ( 78.6%)\n",
      "    Val: [5700/7191] ( 79.3%)\n",
      "    Val: [5750/7191] ( 80.0%)\n",
      "    Val: [5800/7191] ( 80.7%)\n",
      "    Val: [5850/7191] ( 81.4%)\n",
      "    Val: [5900/7191] ( 82.0%)\n",
      "    Val: [5950/7191] ( 82.7%)\n",
      "    Val: [6000/7191] ( 83.4%)\n",
      "    Val: [6050/7191] ( 84.1%)\n",
      "    Val: [6100/7191] ( 84.8%)\n",
      "    Val: [6150/7191] ( 85.5%)\n",
      "    Val: [6200/7191] ( 86.2%)\n",
      "    Val: [6250/7191] ( 86.9%)\n",
      "    Val: [6300/7191] ( 87.6%)\n",
      "    Val: [6350/7191] ( 88.3%)\n",
      "    Val: [6400/7191] ( 89.0%)\n",
      "    Val: [6450/7191] ( 89.7%)\n",
      "    Val: [6500/7191] ( 90.4%)\n",
      "    Val: [6550/7191] ( 91.1%)\n",
      "    Val: [6600/7191] ( 91.8%)\n",
      "    Val: [6650/7191] ( 92.5%)\n",
      "    Val: [6700/7191] ( 93.2%)\n",
      "    Val: [6750/7191] ( 93.9%)\n",
      "    Val: [6800/7191] ( 94.6%)\n",
      "    Val: [6850/7191] ( 95.3%)\n",
      "    Val: [6900/7191] ( 96.0%)\n",
      "    Val: [6950/7191] ( 96.6%)\n",
      "    Val: [7000/7191] ( 97.3%)\n",
      "    Val: [7050/7191] ( 98.0%)\n",
      "    Val: [7100/7191] ( 98.7%)\n",
      "    Val: [7150/7191] ( 99.4%)\n",
      "\n",
      "  Epoch 03 Summary:\n",
      "    Train MSE (norm): 0.6079 | Val MSE (norm): 0.5815\n",
      "    Time: Train=22.0min, Val=0.9min, Total=22.9min\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 04/5\n",
      "============================================================\n",
      "  Train: [  100/57525] (  0.2%) | Loss: 0.6132 | Speed: 32.7 batches/s | ETA: 29:18\n",
      "  Train: [  200/57525] (  0.3%) | Loss: 0.6019 | Speed: 38.0 batches/s | ETA: 25:10\n",
      "  Train: [  300/57525] (  0.5%) | Loss: 0.6025 | Speed: 40.1 batches/s | ETA: 23:47\n",
      "  Train: [  400/57525] (  0.7%) | Loss: 0.5985 | Speed: 41.3 batches/s | ETA: 23:04\n",
      "  Train: [  500/57525] (  0.9%) | Loss: 0.6005 | Speed: 42.0 batches/s | ETA: 22:38\n",
      "  Train: [  600/57525] (  1.0%) | Loss: 0.5994 | Speed: 42.5 batches/s | ETA: 22:18\n",
      "  Train: [  700/57525] (  1.2%) | Loss: 0.5961 | Speed: 43.0 batches/s | ETA: 22:02\n",
      "  Train: [  800/57525] (  1.4%) | Loss: 0.5949 | Speed: 43.2 batches/s | ETA: 21:52\n",
      "  Train: [  900/57525] (  1.6%) | Loss: 0.5943 | Speed: 43.5 batches/s | ETA: 21:42\n",
      "  Train: [ 1000/57525] (  1.7%) | Loss: 0.5956 | Speed: 43.7 batches/s | ETA: 21:34\n",
      "  Train: [ 1100/57525] (  1.9%) | Loss: 0.5965 | Speed: 43.8 batches/s | ETA: 21:28\n",
      "  Train: [ 1200/57525] (  2.1%) | Loss: 0.5966 | Speed: 43.9 batches/s | ETA: 21:21\n",
      "  Train: [ 1300/57525] (  2.3%) | Loss: 0.5960 | Speed: 44.1 batches/s | ETA: 21:15\n",
      "  Train: [ 1400/57525] (  2.4%) | Loss: 0.5966 | Speed: 44.2 batches/s | ETA: 21:09\n",
      "  Train: [ 1500/57525] (  2.6%) | Loss: 0.5985 | Speed: 44.3 batches/s | ETA: 21:04\n",
      "  Train: [ 1600/57525] (  2.8%) | Loss: 0.5984 | Speed: 44.4 batches/s | ETA: 20:59\n",
      "  Train: [ 1700/57525] (  3.0%) | Loss: 0.5974 | Speed: 44.5 batches/s | ETA: 20:54\n",
      "  Train: [ 1800/57525] (  3.1%) | Loss: 0.5971 | Speed: 44.6 batches/s | ETA: 20:49\n",
      "  Train: [ 1900/57525] (  3.3%) | Loss: 0.5973 | Speed: 44.6 batches/s | ETA: 20:46\n",
      "  Train: [ 2000/57525] (  3.5%) | Loss: 0.5976 | Speed: 44.7 batches/s | ETA: 20:42\n",
      "  Train: [ 2100/57525] (  3.7%) | Loss: 0.5974 | Speed: 44.7 batches/s | ETA: 20:39\n",
      "  Train: [ 2200/57525] (  3.8%) | Loss: 0.5973 | Speed: 44.7 batches/s | ETA: 20:37\n",
      "  Train: [ 2300/57525] (  4.0%) | Loss: 0.5970 | Speed: 44.7 batches/s | ETA: 20:34\n",
      "  Train: [ 2400/57525] (  4.2%) | Loss: 0.5967 | Speed: 44.7 batches/s | ETA: 20:32\n",
      "  Train: [ 2500/57525] (  4.3%) | Loss: 0.5967 | Speed: 44.8 batches/s | ETA: 20:29\n",
      "  Train: [ 2600/57525] (  4.5%) | Loss: 0.5966 | Speed: 44.8 batches/s | ETA: 20:27\n",
      "  Train: [ 2700/57525] (  4.7%) | Loss: 0.5971 | Speed: 44.8 batches/s | ETA: 20:24\n",
      "  Train: [ 2800/57525] (  4.9%) | Loss: 0.5974 | Speed: 44.7 batches/s | ETA: 20:23\n",
      "  Train: [ 2900/57525] (  5.0%) | Loss: 0.5979 | Speed: 44.7 batches/s | ETA: 20:21\n",
      "  Train: [ 3000/57525] (  5.2%) | Loss: 0.5979 | Speed: 44.7 batches/s | ETA: 20:18\n",
      "  Train: [ 3100/57525] (  5.4%) | Loss: 0.5980 | Speed: 44.7 batches/s | ETA: 20:17\n",
      "  Train: [ 3200/57525] (  5.6%) | Loss: 0.5980 | Speed: 44.7 batches/s | ETA: 20:14\n",
      "  Train: [ 3300/57525] (  5.7%) | Loss: 0.5979 | Speed: 44.7 batches/s | ETA: 20:11\n",
      "  Train: [ 3400/57525] (  5.9%) | Loss: 0.5981 | Speed: 44.8 batches/s | ETA: 20:08\n",
      "  Train: [ 3500/57525] (  6.1%) | Loss: 0.5985 | Speed: 44.8 batches/s | ETA: 20:06\n",
      "  Train: [ 3600/57525] (  6.3%) | Loss: 0.5983 | Speed: 44.8 batches/s | ETA: 20:03\n",
      "  Train: [ 3700/57525] (  6.4%) | Loss: 0.5982 | Speed: 44.8 batches/s | ETA: 20:01\n",
      "  Train: [ 3800/57525] (  6.6%) | Loss: 0.5977 | Speed: 44.8 batches/s | ETA: 19:59\n",
      "  Train: [ 3900/57525] (  6.8%) | Loss: 0.5976 | Speed: 44.8 batches/s | ETA: 19:56\n",
      "  Train: [ 4000/57525] (  7.0%) | Loss: 0.5975 | Speed: 44.8 batches/s | ETA: 19:53\n",
      "  Train: [ 4100/57525] (  7.1%) | Loss: 0.5974 | Speed: 44.8 batches/s | ETA: 19:51\n",
      "  Train: [ 4200/57525] (  7.3%) | Loss: 0.5975 | Speed: 44.9 batches/s | ETA: 19:48\n",
      "  Train: [ 4300/57525] (  7.5%) | Loss: 0.5975 | Speed: 44.9 batches/s | ETA: 19:45\n",
      "  Train: [ 4400/57525] (  7.6%) | Loss: 0.5979 | Speed: 44.9 batches/s | ETA: 19:42\n",
      "  Train: [ 4500/57525] (  7.8%) | Loss: 0.5976 | Speed: 44.9 batches/s | ETA: 19:40\n",
      "  Train: [ 4600/57525] (  8.0%) | Loss: 0.5975 | Speed: 44.9 batches/s | ETA: 19:39\n",
      "  Train: [ 4700/57525] (  8.2%) | Loss: 0.5974 | Speed: 44.9 batches/s | ETA: 19:36\n",
      "  Train: [ 4800/57525] (  8.3%) | Loss: 0.5975 | Speed: 44.9 batches/s | ETA: 19:33\n",
      "  Train: [ 4900/57525] (  8.5%) | Loss: 0.5976 | Speed: 45.0 batches/s | ETA: 19:30\n",
      "  Train: [ 5000/57525] (  8.7%) | Loss: 0.5975 | Speed: 45.0 batches/s | ETA: 19:27\n",
      "  Train: [ 5100/57525] (  8.9%) | Loss: 0.5975 | Speed: 45.0 batches/s | ETA: 19:25\n",
      "  Train: [ 5200/57525] (  9.0%) | Loss: 0.5977 | Speed: 45.0 batches/s | ETA: 19:22\n",
      "  Train: [ 5300/57525] (  9.2%) | Loss: 0.5979 | Speed: 45.0 batches/s | ETA: 19:20\n",
      "  Train: [ 5400/57525] (  9.4%) | Loss: 0.5981 | Speed: 45.0 batches/s | ETA: 19:17\n",
      "  Train: [ 5500/57525] (  9.6%) | Loss: 0.5980 | Speed: 45.0 batches/s | ETA: 19:15\n",
      "  Train: [ 5600/57525] (  9.7%) | Loss: 0.5980 | Speed: 45.1 batches/s | ETA: 19:12\n",
      "  Train: [ 5700/57525] (  9.9%) | Loss: 0.5981 | Speed: 45.1 batches/s | ETA: 19:10\n",
      "  Train: [ 5800/57525] ( 10.1%) | Loss: 0.5979 | Speed: 45.1 batches/s | ETA: 19:07\n",
      "  Train: [ 5900/57525] ( 10.3%) | Loss: 0.5980 | Speed: 45.1 batches/s | ETA: 19:05\n",
      "  Train: [ 6000/57525] ( 10.4%) | Loss: 0.5979 | Speed: 45.1 batches/s | ETA: 19:03\n",
      "  Train: [ 6100/57525] ( 10.6%) | Loss: 0.5981 | Speed: 45.1 batches/s | ETA: 19:00\n",
      "  Train: [ 6200/57525] ( 10.8%) | Loss: 0.5980 | Speed: 45.1 batches/s | ETA: 18:58\n",
      "  Train: [ 6300/57525] ( 11.0%) | Loss: 0.5978 | Speed: 45.1 batches/s | ETA: 18:56\n",
      "  Train: [ 6400/57525] ( 11.1%) | Loss: 0.5980 | Speed: 45.1 batches/s | ETA: 18:53\n",
      "  Train: [ 6500/57525] ( 11.3%) | Loss: 0.5983 | Speed: 45.1 batches/s | ETA: 18:51\n",
      "  Train: [ 6600/57525] ( 11.5%) | Loss: 0.5984 | Speed: 45.1 batches/s | ETA: 18:48\n",
      "  Train: [ 6700/57525] ( 11.6%) | Loss: 0.5983 | Speed: 45.1 batches/s | ETA: 18:46\n",
      "  Train: [ 6800/57525] ( 11.8%) | Loss: 0.5982 | Speed: 45.1 batches/s | ETA: 18:44\n",
      "  Train: [ 6900/57525] ( 12.0%) | Loss: 0.5984 | Speed: 45.1 batches/s | ETA: 18:41\n",
      "  Train: [ 7000/57525] ( 12.2%) | Loss: 0.5988 | Speed: 45.1 batches/s | ETA: 18:39\n",
      "  Train: [ 7100/57525] ( 12.3%) | Loss: 0.5987 | Speed: 45.1 batches/s | ETA: 18:36\n",
      "  Train: [ 7200/57525] ( 12.5%) | Loss: 0.5988 | Speed: 45.1 batches/s | ETA: 18:34\n",
      "  Train: [ 7300/57525] ( 12.7%) | Loss: 0.5989 | Speed: 45.1 batches/s | ETA: 18:32\n",
      "  Train: [ 7400/57525] ( 12.9%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 18:30\n",
      "  Train: [ 7500/57525] ( 13.0%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 18:28\n",
      "  Train: [ 7600/57525] ( 13.2%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 18:25\n",
      "  Train: [ 7700/57525] ( 13.4%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 18:23\n",
      "  Train: [ 7800/57525] ( 13.6%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 18:21\n",
      "  Train: [ 7900/57525] ( 13.7%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 18:18\n",
      "  Train: [ 8000/57525] ( 13.9%) | Loss: 0.5988 | Speed: 45.2 batches/s | ETA: 18:16\n",
      "  Train: [ 8100/57525] ( 14.1%) | Loss: 0.5987 | Speed: 45.2 batches/s | ETA: 18:13\n",
      "  Train: [ 8200/57525] ( 14.3%) | Loss: 0.5988 | Speed: 45.2 batches/s | ETA: 18:11\n",
      "  Train: [ 8300/57525] ( 14.4%) | Loss: 0.5987 | Speed: 45.2 batches/s | ETA: 18:09\n",
      "  Train: [ 8400/57525] ( 14.6%) | Loss: 0.5987 | Speed: 45.2 batches/s | ETA: 18:07\n",
      "  Train: [ 8500/57525] ( 14.8%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 18:04\n",
      "  Train: [ 8600/57525] ( 15.0%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 18:02\n",
      "  Train: [ 8700/57525] ( 15.1%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 18:00\n",
      "  Train: [ 8800/57525] ( 15.3%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 17:57\n",
      "  Train: [ 8900/57525] ( 15.5%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 17:55\n",
      "  Train: [ 9000/57525] ( 15.6%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 17:53\n",
      "  Train: [ 9100/57525] ( 15.8%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 17:51\n",
      "  Train: [ 9200/57525] ( 16.0%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 17:49\n",
      "  Train: [ 9300/57525] ( 16.2%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 17:46\n",
      "  Train: [ 9400/57525] ( 16.3%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 17:45\n",
      "  Train: [ 9500/57525] ( 16.5%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 17:43\n",
      "  Train: [ 9600/57525] ( 16.7%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 17:41\n",
      "  Train: [ 9700/57525] ( 16.9%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 17:39\n",
      "  Train: [ 9800/57525] ( 17.0%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:37\n",
      "  Train: [ 9900/57525] ( 17.2%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:35\n",
      "  Train: [10000/57525] ( 17.4%) | Loss: 0.5989 | Speed: 45.1 batches/s | ETA: 17:33\n",
      "  Train: [10100/57525] ( 17.6%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:31\n",
      "  Train: [10200/57525] ( 17.7%) | Loss: 0.5988 | Speed: 45.1 batches/s | ETA: 17:30\n",
      "  Train: [10300/57525] ( 17.9%) | Loss: 0.5987 | Speed: 45.1 batches/s | ETA: 17:27\n",
      "  Train: [10400/57525] ( 18.1%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:25\n",
      "  Train: [10500/57525] ( 18.3%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:23\n",
      "  Train: [10600/57525] ( 18.4%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:21\n",
      "  Train: [10700/57525] ( 18.6%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:19\n",
      "  Train: [10800/57525] ( 18.8%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:16\n",
      "  Train: [10900/57525] ( 18.9%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 17:14\n",
      "  Train: [11000/57525] ( 19.1%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 17:12\n",
      "  Train: [11100/57525] ( 19.3%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 17:09\n",
      "  Train: [11200/57525] ( 19.5%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 17:07\n",
      "  Train: [11300/57525] ( 19.6%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 17:04\n",
      "  Train: [11400/57525] ( 19.8%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 17:02\n",
      "  Train: [11500/57525] ( 20.0%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 17:00\n",
      "  Train: [11600/57525] ( 20.2%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 16:57\n",
      "  Train: [11700/57525] ( 20.3%) | Loss: 0.5993 | Speed: 45.1 batches/s | ETA: 16:55\n",
      "  Train: [11800/57525] ( 20.5%) | Loss: 0.5993 | Speed: 45.1 batches/s | ETA: 16:53\n",
      "  Train: [11900/57525] ( 20.7%) | Loss: 0.5994 | Speed: 45.1 batches/s | ETA: 16:50\n",
      "  Train: [12000/57525] ( 20.9%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:48\n",
      "  Train: [12100/57525] ( 21.0%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:46\n",
      "  Train: [12200/57525] ( 21.2%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:43\n",
      "  Train: [12300/57525] ( 21.4%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:41\n",
      "  Train: [12400/57525] ( 21.6%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:39\n",
      "  Train: [12500/57525] ( 21.7%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:37\n",
      "  Train: [12600/57525] ( 21.9%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:35\n",
      "  Train: [12700/57525] ( 22.1%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:32\n",
      "  Train: [12800/57525] ( 22.3%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:30\n",
      "  Train: [12900/57525] ( 22.4%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:28\n",
      "  Train: [13000/57525] ( 22.6%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:26\n",
      "  Train: [13100/57525] ( 22.8%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:24\n",
      "  Train: [13200/57525] ( 22.9%) | Loss: 0.5995 | Speed: 45.1 batches/s | ETA: 16:22\n",
      "  Train: [13300/57525] ( 23.1%) | Loss: 0.5996 | Speed: 45.1 batches/s | ETA: 16:20\n",
      "  Train: [13400/57525] ( 23.3%) | Loss: 0.5994 | Speed: 45.1 batches/s | ETA: 16:18\n",
      "  Train: [13500/57525] ( 23.5%) | Loss: 0.5993 | Speed: 45.1 batches/s | ETA: 16:17\n",
      "  Train: [13600/57525] ( 23.6%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 16:14\n",
      "  Train: [13700/57525] ( 23.8%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 16:12\n",
      "  Train: [13800/57525] ( 24.0%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 16:10\n",
      "  Train: [13900/57525] ( 24.2%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 16:08\n",
      "  Train: [14000/57525] ( 24.3%) | Loss: 0.5993 | Speed: 45.1 batches/s | ETA: 16:06\n",
      "  Train: [14100/57525] ( 24.5%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 16:04\n",
      "  Train: [14200/57525] ( 24.7%) | Loss: 0.5992 | Speed: 45.0 batches/s | ETA: 16:02\n",
      "  Train: [14300/57525] ( 24.9%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:59\n",
      "  Train: [14400/57525] ( 25.0%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:57\n",
      "  Train: [14500/57525] ( 25.2%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:55\n",
      "  Train: [14600/57525] ( 25.4%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:53\n",
      "  Train: [14700/57525] ( 25.6%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:51\n",
      "  Train: [14800/57525] ( 25.7%) | Loss: 0.5992 | Speed: 45.0 batches/s | ETA: 15:49\n",
      "  Train: [14900/57525] ( 25.9%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:47\n",
      "  Train: [15000/57525] ( 26.1%) | Loss: 0.5992 | Speed: 45.0 batches/s | ETA: 15:45\n",
      "  Train: [15100/57525] ( 26.2%) | Loss: 0.5992 | Speed: 45.0 batches/s | ETA: 15:43\n",
      "  Train: [15200/57525] ( 26.4%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:41\n",
      "  Train: [15300/57525] ( 26.6%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:39\n",
      "  Train: [15400/57525] ( 26.8%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:36\n",
      "  Train: [15500/57525] ( 26.9%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:34\n",
      "  Train: [15600/57525] ( 27.1%) | Loss: 0.5994 | Speed: 44.9 batches/s | ETA: 15:32\n",
      "  Train: [15700/57525] ( 27.3%) | Loss: 0.5993 | Speed: 44.9 batches/s | ETA: 15:30\n",
      "  Train: [15800/57525] ( 27.5%) | Loss: 0.5994 | Speed: 44.9 batches/s | ETA: 15:28\n",
      "  Train: [15900/57525] ( 27.6%) | Loss: 0.5994 | Speed: 44.9 batches/s | ETA: 15:26\n",
      "  Train: [16000/57525] ( 27.8%) | Loss: 0.5993 | Speed: 44.9 batches/s | ETA: 15:23\n",
      "  Train: [16100/57525] ( 28.0%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:21\n",
      "  Train: [16200/57525] ( 28.2%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:19\n",
      "  Train: [16300/57525] ( 28.3%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:16\n",
      "  Train: [16400/57525] ( 28.5%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:14\n",
      "  Train: [16500/57525] ( 28.7%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:12\n",
      "  Train: [16600/57525] ( 28.9%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:09\n",
      "  Train: [16700/57525] ( 29.0%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:07\n",
      "  Train: [16800/57525] ( 29.2%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:05\n",
      "  Train: [16900/57525] ( 29.4%) | Loss: 0.5994 | Speed: 45.0 batches/s | ETA: 15:02\n",
      "  Train: [17000/57525] ( 29.6%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 15:00\n",
      "  Train: [17100/57525] ( 29.7%) | Loss: 0.5993 | Speed: 45.0 batches/s | ETA: 14:57\n",
      "  Train: [17200/57525] ( 29.9%) | Loss: 0.5992 | Speed: 45.0 batches/s | ETA: 14:55\n",
      "  Train: [17300/57525] ( 30.1%) | Loss: 0.5991 | Speed: 45.0 batches/s | ETA: 14:53\n",
      "  Train: [17400/57525] ( 30.2%) | Loss: 0.5991 | Speed: 45.0 batches/s | ETA: 14:50\n",
      "  Train: [17500/57525] ( 30.4%) | Loss: 0.5990 | Speed: 45.0 batches/s | ETA: 14:48\n",
      "  Train: [17600/57525] ( 30.6%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:46\n",
      "  Train: [17700/57525] ( 30.8%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:43\n",
      "  Train: [17800/57525] ( 30.9%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 14:41\n",
      "  Train: [17900/57525] ( 31.1%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:39\n",
      "  Train: [18000/57525] ( 31.3%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:36\n",
      "  Train: [18100/57525] ( 31.5%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:34\n",
      "  Train: [18200/57525] ( 31.6%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:32\n",
      "  Train: [18300/57525] ( 31.8%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:29\n",
      "  Train: [18400/57525] ( 32.0%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:27\n",
      "  Train: [18500/57525] ( 32.2%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:25\n",
      "  Train: [18600/57525] ( 32.3%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 14:22\n",
      "  Train: [18700/57525] ( 32.5%) | Loss: 0.5990 | Speed: 45.1 batches/s | ETA: 14:20\n",
      "  Train: [18800/57525] ( 32.7%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:18\n",
      "  Train: [18900/57525] ( 32.9%) | Loss: 0.5991 | Speed: 45.1 batches/s | ETA: 14:15\n",
      "  Train: [19000/57525] ( 33.0%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 14:13\n",
      "  Train: [19100/57525] ( 33.2%) | Loss: 0.5992 | Speed: 45.1 batches/s | ETA: 14:11\n",
      "  Train: [19200/57525] ( 33.4%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 14:08\n",
      "  Train: [19300/57525] ( 33.6%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 14:06\n",
      "  Train: [19400/57525] ( 33.7%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 14:04\n",
      "  Train: [19500/57525] ( 33.9%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 14:01\n",
      "  Train: [19600/57525] ( 34.1%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 13:59\n",
      "  Train: [19700/57525] ( 34.2%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 13:57\n",
      "  Train: [19800/57525] ( 34.4%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 13:54\n",
      "  Train: [19900/57525] ( 34.6%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 13:52\n",
      "  Train: [20000/57525] ( 34.8%) | Loss: 0.5992 | Speed: 45.2 batches/s | ETA: 13:50\n",
      "  Train: [20100/57525] ( 34.9%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 13:48\n",
      "  Train: [20200/57525] ( 35.1%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:45\n",
      "  Train: [20300/57525] ( 35.3%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:43\n",
      "  Train: [20400/57525] ( 35.5%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:41\n",
      "  Train: [20500/57525] ( 35.6%) | Loss: 0.5989 | Speed: 45.2 batches/s | ETA: 13:38\n",
      "  Train: [20600/57525] ( 35.8%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:36\n",
      "  Train: [20700/57525] ( 36.0%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:34\n",
      "  Train: [20800/57525] ( 36.2%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:31\n",
      "  Train: [20900/57525] ( 36.3%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:29\n",
      "  Train: [21000/57525] ( 36.5%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:27\n",
      "  Train: [21100/57525] ( 36.7%) | Loss: 0.5991 | Speed: 45.2 batches/s | ETA: 13:25\n",
      "  Train: [21200/57525] ( 36.9%) | Loss: 0.5990 | Speed: 45.2 batches/s | ETA: 13:22\n",
      "  Train: [21300/57525] ( 37.0%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:20\n",
      "  Train: [21400/57525] ( 37.2%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:18\n",
      "  Train: [21500/57525] ( 37.4%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:16\n",
      "  Train: [21600/57525] ( 37.5%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:13\n",
      "  Train: [21700/57525] ( 37.7%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:11\n",
      "  Train: [21800/57525] ( 37.9%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:09\n",
      "  Train: [21900/57525] ( 38.1%) | Loss: 0.5991 | Speed: 45.3 batches/s | ETA: 13:06\n",
      "  Train: [22000/57525] ( 38.2%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 13:04\n",
      "  Train: [22100/57525] ( 38.4%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 13:02\n",
      "  Train: [22200/57525] ( 38.6%) | Loss: 0.5988 | Speed: 45.3 batches/s | ETA: 13:00\n",
      "  Train: [22300/57525] ( 38.8%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:57\n",
      "  Train: [22400/57525] ( 38.9%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:55\n",
      "  Train: [22500/57525] ( 39.1%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:53\n",
      "  Train: [22600/57525] ( 39.3%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:51\n",
      "  Train: [22700/57525] ( 39.5%) | Loss: 0.5988 | Speed: 45.3 batches/s | ETA: 12:48\n",
      "  Train: [22800/57525] ( 39.6%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:46\n",
      "  Train: [22900/57525] ( 39.8%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:44\n",
      "  Train: [23000/57525] ( 40.0%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:41\n",
      "  Train: [23100/57525] ( 40.2%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:39\n",
      "  Train: [23200/57525] ( 40.3%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:37\n",
      "  Train: [23300/57525] ( 40.5%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:35\n",
      "  Train: [23400/57525] ( 40.7%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:32\n",
      "  Train: [23500/57525] ( 40.9%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:30\n",
      "  Train: [23600/57525] ( 41.0%) | Loss: 0.5991 | Speed: 45.3 batches/s | ETA: 12:28\n",
      "  Train: [23700/57525] ( 41.2%) | Loss: 0.5991 | Speed: 45.3 batches/s | ETA: 12:26\n",
      "  Train: [23800/57525] ( 41.4%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:23\n",
      "  Train: [23900/57525] ( 41.5%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:21\n",
      "  Train: [24000/57525] ( 41.7%) | Loss: 0.5989 | Speed: 45.3 batches/s | ETA: 12:19\n",
      "  Train: [24100/57525] ( 41.9%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:17\n",
      "  Train: [24200/57525] ( 42.1%) | Loss: 0.5990 | Speed: 45.3 batches/s | ETA: 12:14\n",
      "  Train: [24300/57525] ( 42.2%) | Loss: 0.5989 | Speed: 45.4 batches/s | ETA: 12:12\n",
      "  Train: [24400/57525] ( 42.4%) | Loss: 0.5990 | Speed: 45.4 batches/s | ETA: 12:10\n",
      "  Train: [24500/57525] ( 42.6%) | Loss: 0.5991 | Speed: 45.4 batches/s | ETA: 12:08\n",
      "  Train: [24600/57525] ( 42.8%) | Loss: 0.5991 | Speed: 45.4 batches/s | ETA: 12:05\n",
      "  Train: [24700/57525] ( 42.9%) | Loss: 0.5991 | Speed: 45.4 batches/s | ETA: 12:03\n",
      "  Train: [24800/57525] ( 43.1%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 12:01\n",
      "  Train: [24900/57525] ( 43.3%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:59\n",
      "  Train: [25000/57525] ( 43.5%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:56\n",
      "  Train: [25100/57525] ( 43.6%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:54\n",
      "  Train: [25200/57525] ( 43.8%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:52\n",
      "  Train: [25300/57525] ( 44.0%) | Loss: 0.5991 | Speed: 45.4 batches/s | ETA: 11:50\n",
      "  Train: [25400/57525] ( 44.2%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:47\n",
      "  Train: [25500/57525] ( 44.3%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:45\n",
      "  Train: [25600/57525] ( 44.5%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:43\n",
      "  Train: [25700/57525] ( 44.7%) | Loss: 0.5993 | Speed: 45.4 batches/s | ETA: 11:41\n",
      "  Train: [25800/57525] ( 44.9%) | Loss: 0.5993 | Speed: 45.4 batches/s | ETA: 11:38\n",
      "  Train: [25900/57525] ( 45.0%) | Loss: 0.5993 | Speed: 45.4 batches/s | ETA: 11:36\n",
      "  Train: [26000/57525] ( 45.2%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:34\n",
      "  Train: [26100/57525] ( 45.4%) | Loss: 0.5993 | Speed: 45.4 batches/s | ETA: 11:32\n",
      "  Train: [26200/57525] ( 45.5%) | Loss: 0.5992 | Speed: 45.4 batches/s | ETA: 11:29\n",
      "  Train: [26300/57525] ( 45.7%) | Loss: 0.5993 | Speed: 45.4 batches/s | ETA: 11:27\n",
      "  Train: [26400/57525] ( 45.9%) | Loss: 0.5994 | Speed: 45.4 batches/s | ETA: 11:25\n",
      "  Train: [26500/57525] ( 46.1%) | Loss: 0.5994 | Speed: 45.4 batches/s | ETA: 11:23\n",
      "  Train: [26600/57525] ( 46.2%) | Loss: 0.5994 | Speed: 45.4 batches/s | ETA: 11:20\n",
      "  Train: [26700/57525] ( 46.4%) | Loss: 0.5994 | Speed: 45.4 batches/s | ETA: 11:18\n",
      "  Train: [26800/57525] ( 46.6%) | Loss: 0.5995 | Speed: 45.4 batches/s | ETA: 11:16\n",
      "  Train: [26900/57525] ( 46.8%) | Loss: 0.5995 | Speed: 45.4 batches/s | ETA: 11:14\n",
      "  Train: [27000/57525] ( 46.9%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 11:12\n",
      "  Train: [27100/57525] ( 47.1%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 11:09\n",
      "  Train: [27200/57525] ( 47.3%) | Loss: 0.5995 | Speed: 45.4 batches/s | ETA: 11:07\n",
      "  Train: [27300/57525] ( 47.5%) | Loss: 0.5995 | Speed: 45.4 batches/s | ETA: 11:05\n",
      "  Train: [27400/57525] ( 47.6%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 11:03\n",
      "  Train: [27500/57525] ( 47.8%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 11:00\n",
      "  Train: [27600/57525] ( 48.0%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:58\n",
      "  Train: [27700/57525] ( 48.2%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:56\n",
      "  Train: [27800/57525] ( 48.3%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:54\n",
      "  Train: [27900/57525] ( 48.5%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:51\n",
      "  Train: [28000/57525] ( 48.7%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:49\n",
      "  Train: [28100/57525] ( 48.8%) | Loss: 0.5996 | Speed: 45.4 batches/s | ETA: 10:47\n",
      "  Train: [28200/57525] ( 49.0%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:45\n",
      "  Train: [28300/57525] ( 49.2%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:42\n",
      "  Train: [28400/57525] ( 49.4%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:40\n",
      "  Train: [28500/57525] ( 49.5%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:38\n",
      "  Train: [28600/57525] ( 49.7%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:36\n",
      "  Train: [28700/57525] ( 49.9%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:34\n",
      "  Train: [28800/57525] ( 50.1%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 10:31\n",
      "  Train: [28900/57525] ( 50.2%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:29\n",
      "  Train: [29000/57525] ( 50.4%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:27\n",
      "  Train: [29100/57525] ( 50.6%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:25\n",
      "  Train: [29200/57525] ( 50.8%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:22\n",
      "  Train: [29300/57525] ( 50.9%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:20\n",
      "  Train: [29400/57525] ( 51.1%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:18\n",
      "  Train: [29500/57525] ( 51.3%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:16\n",
      "  Train: [29600/57525] ( 51.5%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 10:14\n",
      "  Train: [29700/57525] ( 51.6%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 10:11\n",
      "  Train: [29800/57525] ( 51.8%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 10:09\n",
      "  Train: [29900/57525] ( 52.0%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:07\n",
      "  Train: [30000/57525] ( 52.2%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 10:05\n",
      "  Train: [30100/57525] ( 52.3%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 10:02\n",
      "  Train: [30200/57525] ( 52.5%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 10:00\n",
      "  Train: [30300/57525] ( 52.7%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:58\n",
      "  Train: [30400/57525] ( 52.8%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:56\n",
      "  Train: [30500/57525] ( 53.0%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:53\n",
      "  Train: [30600/57525] ( 53.2%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:51\n",
      "  Train: [30700/57525] ( 53.4%) | Loss: 0.5993 | Speed: 45.5 batches/s | ETA: 09:49\n",
      "  Train: [30800/57525] ( 53.5%) | Loss: 0.5993 | Speed: 45.5 batches/s | ETA: 09:47\n",
      "  Train: [30900/57525] ( 53.7%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:45\n",
      "  Train: [31000/57525] ( 53.9%) | Loss: 0.5994 | Speed: 45.5 batches/s | ETA: 09:42\n",
      "  Train: [31100/57525] ( 54.1%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:40\n",
      "  Train: [31200/57525] ( 54.2%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 09:38\n",
      "  Train: [31300/57525] ( 54.4%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:36\n",
      "  Train: [31400/57525] ( 54.6%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:34\n",
      "  Train: [31500/57525] ( 54.8%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 09:31\n",
      "  Train: [31600/57525] ( 54.9%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:29\n",
      "  Train: [31700/57525] ( 55.1%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:27\n",
      "  Train: [31800/57525] ( 55.3%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:25\n",
      "  Train: [31900/57525] ( 55.5%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:22\n",
      "  Train: [32000/57525] ( 55.6%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:20\n",
      "  Train: [32100/57525] ( 55.8%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:18\n",
      "  Train: [32200/57525] ( 56.0%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:16\n",
      "  Train: [32300/57525] ( 56.1%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:14\n",
      "  Train: [32400/57525] ( 56.3%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:11\n",
      "  Train: [32500/57525] ( 56.5%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:09\n",
      "  Train: [32600/57525] ( 56.7%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 09:07\n",
      "  Train: [32700/57525] ( 56.8%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 09:05\n",
      "  Train: [32800/57525] ( 57.0%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 09:02\n",
      "  Train: [32900/57525] ( 57.2%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 09:00\n",
      "  Train: [33000/57525] ( 57.4%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 08:58\n",
      "  Train: [33100/57525] ( 57.5%) | Loss: 0.5995 | Speed: 45.5 batches/s | ETA: 08:56\n",
      "  Train: [33200/57525] ( 57.7%) | Loss: 0.5996 | Speed: 45.5 batches/s | ETA: 08:54\n",
      "  Train: [33300/57525] ( 57.9%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:51\n",
      "  Train: [33400/57525] ( 58.1%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:49\n",
      "  Train: [33500/57525] ( 58.2%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:47\n",
      "  Train: [33600/57525] ( 58.4%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:45\n",
      "  Train: [33700/57525] ( 58.6%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:42\n",
      "  Train: [33800/57525] ( 58.8%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:40\n",
      "  Train: [33900/57525] ( 58.9%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:38\n",
      "  Train: [34000/57525] ( 59.1%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:36\n",
      "  Train: [34100/57525] ( 59.3%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:34\n",
      "  Train: [34200/57525] ( 59.5%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:31\n",
      "  Train: [34300/57525] ( 59.6%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:29\n",
      "  Train: [34400/57525] ( 59.8%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:27\n",
      "  Train: [34500/57525] ( 60.0%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:25\n",
      "  Train: [34600/57525] ( 60.1%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:23\n",
      "  Train: [34700/57525] ( 60.3%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:20\n",
      "  Train: [34800/57525] ( 60.5%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:18\n",
      "  Train: [34900/57525] ( 60.7%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:16\n",
      "  Train: [35000/57525] ( 60.8%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:14\n",
      "  Train: [35100/57525] ( 61.0%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:11\n",
      "  Train: [35200/57525] ( 61.2%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:09\n",
      "  Train: [35300/57525] ( 61.4%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:07\n",
      "  Train: [35400/57525] ( 61.5%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:05\n",
      "  Train: [35500/57525] ( 61.7%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 08:03\n",
      "  Train: [35600/57525] ( 61.9%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 08:00\n",
      "  Train: [35700/57525] ( 62.1%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:58\n",
      "  Train: [35800/57525] ( 62.2%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:56\n",
      "  Train: [35900/57525] ( 62.4%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:54\n",
      "  Train: [36000/57525] ( 62.6%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:52\n",
      "  Train: [36100/57525] ( 62.8%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:49\n",
      "  Train: [36200/57525] ( 62.9%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:47\n",
      "  Train: [36300/57525] ( 63.1%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:45\n",
      "  Train: [36400/57525] ( 63.3%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:43\n",
      "  Train: [36500/57525] ( 63.5%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:41\n",
      "  Train: [36600/57525] ( 63.6%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:38\n",
      "  Train: [36700/57525] ( 63.8%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:36\n",
      "  Train: [36800/57525] ( 64.0%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:34\n",
      "  Train: [36900/57525] ( 64.1%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:32\n",
      "  Train: [37000/57525] ( 64.3%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:30\n",
      "  Train: [37100/57525] ( 64.5%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:27\n",
      "  Train: [37200/57525] ( 64.7%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:25\n",
      "  Train: [37300/57525] ( 64.8%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:23\n",
      "  Train: [37400/57525] ( 65.0%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:21\n",
      "  Train: [37500/57525] ( 65.2%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:18\n",
      "  Train: [37600/57525] ( 65.4%) | Loss: 0.5997 | Speed: 45.6 batches/s | ETA: 07:16\n",
      "  Train: [37700/57525] ( 65.5%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:14\n",
      "  Train: [37800/57525] ( 65.7%) | Loss: 0.5996 | Speed: 45.6 batches/s | ETA: 07:12\n",
      "  Train: [37900/57525] ( 65.9%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 07:10\n",
      "  Train: [38000/57525] ( 66.1%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 07:07\n",
      "  Train: [38100/57525] ( 66.2%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 07:05\n",
      "  Train: [38200/57525] ( 66.4%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 07:03\n",
      "  Train: [38300/57525] ( 66.6%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 07:01\n",
      "  Train: [38400/57525] ( 66.8%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 06:59\n",
      "  Train: [38500/57525] ( 66.9%) | Loss: 0.5993 | Speed: 45.6 batches/s | ETA: 06:56\n",
      "  Train: [38600/57525] ( 67.1%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 06:54\n",
      "  Train: [38700/57525] ( 67.3%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 06:52\n",
      "  Train: [38800/57525] ( 67.4%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 06:50\n",
      "  Train: [38900/57525] ( 67.6%) | Loss: 0.5994 | Speed: 45.6 batches/s | ETA: 06:48\n",
      "  Train: [39000/57525] ( 67.8%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:45\n",
      "  Train: [39100/57525] ( 68.0%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:43\n",
      "  Train: [39200/57525] ( 68.1%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:41\n",
      "  Train: [39300/57525] ( 68.3%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:39\n",
      "  Train: [39400/57525] ( 68.5%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:37\n",
      "  Train: [39500/57525] ( 68.7%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:34\n",
      "  Train: [39600/57525] ( 68.8%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:32\n",
      "  Train: [39700/57525] ( 69.0%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:30\n",
      "  Train: [39800/57525] ( 69.2%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:28\n",
      "  Train: [39900/57525] ( 69.4%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:26\n",
      "  Train: [40000/57525] ( 69.5%) | Loss: 0.5995 | Speed: 45.6 batches/s | ETA: 06:23\n",
      "  Train: [40100/57525] ( 69.7%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:21\n",
      "  Train: [40200/57525] ( 69.9%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:19\n",
      "  Train: [40300/57525] ( 70.1%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:17\n",
      "  Train: [40400/57525] ( 70.2%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:15\n",
      "  Train: [40500/57525] ( 70.4%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:12\n",
      "  Train: [40600/57525] ( 70.6%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 06:10\n",
      "  Train: [40700/57525] ( 70.8%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 06:08\n",
      "  Train: [40800/57525] ( 70.9%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 06:06\n",
      "  Train: [40900/57525] ( 71.1%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 06:04\n",
      "  Train: [41000/57525] ( 71.3%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 06:01\n",
      "  Train: [41100/57525] ( 71.4%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:59\n",
      "  Train: [41200/57525] ( 71.6%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:57\n",
      "  Train: [41300/57525] ( 71.8%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:55\n",
      "  Train: [41400/57525] ( 72.0%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:53\n",
      "  Train: [41500/57525] ( 72.1%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:50\n",
      "  Train: [41600/57525] ( 72.3%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:48\n",
      "  Train: [41700/57525] ( 72.5%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 05:46\n",
      "  Train: [41800/57525] ( 72.7%) | Loss: 0.5994 | Speed: 45.7 batches/s | ETA: 05:44\n",
      "  Train: [41900/57525] ( 72.8%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:42\n",
      "  Train: [42000/57525] ( 73.0%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:40\n",
      "  Train: [42100/57525] ( 73.2%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:37\n",
      "  Train: [42200/57525] ( 73.4%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:35\n",
      "  Train: [42300/57525] ( 73.5%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:33\n",
      "  Train: [42400/57525] ( 73.7%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:31\n",
      "  Train: [42500/57525] ( 73.9%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:29\n",
      "  Train: [42600/57525] ( 74.1%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:26\n",
      "  Train: [42700/57525] ( 74.2%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:24\n",
      "  Train: [42800/57525] ( 74.4%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:22\n",
      "  Train: [42900/57525] ( 74.6%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:20\n",
      "  Train: [43000/57525] ( 74.8%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:18\n",
      "  Train: [43100/57525] ( 74.9%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:15\n",
      "  Train: [43200/57525] ( 75.1%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:13\n",
      "  Train: [43300/57525] ( 75.3%) | Loss: 0.5993 | Speed: 45.7 batches/s | ETA: 05:11\n",
      "  Train: [43400/57525] ( 75.4%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:09\n",
      "  Train: [43500/57525] ( 75.6%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:07\n",
      "  Train: [43600/57525] ( 75.8%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:04\n",
      "  Train: [43700/57525] ( 76.0%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:02\n",
      "  Train: [43800/57525] ( 76.1%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 05:00\n",
      "  Train: [43900/57525] ( 76.3%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:58\n",
      "  Train: [44000/57525] ( 76.5%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:56\n",
      "  Train: [44100/57525] ( 76.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:53\n",
      "  Train: [44200/57525] ( 76.8%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:51\n",
      "  Train: [44300/57525] ( 77.0%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:49\n",
      "  Train: [44400/57525] ( 77.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:47\n",
      "  Train: [44500/57525] ( 77.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:45\n",
      "  Train: [44600/57525] ( 77.5%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:43\n",
      "  Train: [44700/57525] ( 77.7%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:40\n",
      "  Train: [44800/57525] ( 77.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:38\n",
      "  Train: [44900/57525] ( 78.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:36\n",
      "  Train: [45000/57525] ( 78.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:34\n",
      "  Train: [45100/57525] ( 78.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:32\n",
      "  Train: [45200/57525] ( 78.6%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:29\n",
      "  Train: [45300/57525] ( 78.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:27\n",
      "  Train: [45400/57525] ( 78.9%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:25\n",
      "  Train: [45500/57525] ( 79.1%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:23\n",
      "  Train: [45600/57525] ( 79.3%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:21\n",
      "  Train: [45700/57525] ( 79.4%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:18\n",
      "  Train: [45800/57525] ( 79.6%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:16\n",
      "  Train: [45900/57525] ( 79.8%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 04:14\n",
      "  Train: [46000/57525] ( 80.0%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:12\n",
      "  Train: [46100/57525] ( 80.1%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:10\n",
      "  Train: [46200/57525] ( 80.3%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:07\n",
      "  Train: [46300/57525] ( 80.5%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:05\n",
      "  Train: [46400/57525] ( 80.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:03\n",
      "  Train: [46500/57525] ( 80.8%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 04:01\n",
      "  Train: [46600/57525] ( 81.0%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 03:59\n",
      "  Train: [46700/57525] ( 81.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:57\n",
      "  Train: [46800/57525] ( 81.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:54\n",
      "  Train: [46900/57525] ( 81.5%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:52\n",
      "  Train: [47000/57525] ( 81.7%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:50\n",
      "  Train: [47100/57525] ( 81.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:48\n",
      "  Train: [47200/57525] ( 82.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:46\n",
      "  Train: [47300/57525] ( 82.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:43\n",
      "  Train: [47400/57525] ( 82.4%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 03:41\n",
      "  Train: [47500/57525] ( 82.6%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 03:39\n",
      "  Train: [47600/57525] ( 82.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 03:37\n",
      "  Train: [47700/57525] ( 82.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:35\n",
      "  Train: [47800/57525] ( 83.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:32\n",
      "  Train: [47900/57525] ( 83.3%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:30\n",
      "  Train: [48000/57525] ( 83.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:28\n",
      "  Train: [48100/57525] ( 83.6%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:26\n",
      "  Train: [48200/57525] ( 83.8%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:24\n",
      "  Train: [48300/57525] ( 84.0%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:21\n",
      "  Train: [48400/57525] ( 84.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:19\n",
      "  Train: [48500/57525] ( 84.3%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:17\n",
      "  Train: [48600/57525] ( 84.5%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:15\n",
      "  Train: [48700/57525] ( 84.7%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:13\n",
      "  Train: [48800/57525] ( 84.8%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:11\n",
      "  Train: [48900/57525] ( 85.0%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:08\n",
      "  Train: [49000/57525] ( 85.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:06\n",
      "  Train: [49100/57525] ( 85.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:04\n",
      "  Train: [49200/57525] ( 85.5%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 03:02\n",
      "  Train: [49300/57525] ( 85.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 03:00\n",
      "  Train: [49400/57525] ( 85.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:57\n",
      "  Train: [49500/57525] ( 86.0%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:55\n",
      "  Train: [49600/57525] ( 86.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:53\n",
      "  Train: [49700/57525] ( 86.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:51\n",
      "  Train: [49800/57525] ( 86.6%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:49\n",
      "  Train: [49900/57525] ( 86.7%) | Loss: 0.5992 | Speed: 45.7 batches/s | ETA: 02:46\n",
      "  Train: [50000/57525] ( 86.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:44\n",
      "  Train: [50100/57525] ( 87.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:42\n",
      "  Train: [50200/57525] ( 87.3%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:40\n",
      "  Train: [50300/57525] ( 87.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:38\n",
      "  Train: [50400/57525] ( 87.6%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:36\n",
      "  Train: [50500/57525] ( 87.8%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:33\n",
      "  Train: [50600/57525] ( 88.0%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:31\n",
      "  Train: [50700/57525] ( 88.1%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:29\n",
      "  Train: [50800/57525] ( 88.3%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:27\n",
      "  Train: [50900/57525] ( 88.5%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:25\n",
      "  Train: [51000/57525] ( 88.7%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:22\n",
      "  Train: [51100/57525] ( 88.8%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:20\n",
      "  Train: [51200/57525] ( 89.0%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:18\n",
      "  Train: [51300/57525] ( 89.2%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:16\n",
      "  Train: [51400/57525] ( 89.4%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 02:14\n",
      "  Train: [51500/57525] ( 89.5%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:11\n",
      "  Train: [51600/57525] ( 89.7%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:09\n",
      "  Train: [51700/57525] ( 89.9%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:07\n",
      "  Train: [51800/57525] ( 90.0%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:05\n",
      "  Train: [51900/57525] ( 90.2%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:03\n",
      "  Train: [52000/57525] ( 90.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 02:01\n",
      "  Train: [52100/57525] ( 90.6%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 01:58\n",
      "  Train: [52200/57525] ( 90.7%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 01:56\n",
      "  Train: [52300/57525] ( 90.9%) | Loss: 0.5990 | Speed: 45.7 batches/s | ETA: 01:54\n",
      "  Train: [52400/57525] ( 91.1%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 01:52\n",
      "  Train: [52500/57525] ( 91.3%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 01:50\n",
      "  Train: [52600/57525] ( 91.4%) | Loss: 0.5991 | Speed: 45.7 batches/s | ETA: 01:47\n",
      "  Train: [52700/57525] ( 91.6%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:45\n",
      "  Train: [52800/57525] ( 91.8%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:43\n",
      "  Train: [52900/57525] ( 92.0%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:41\n",
      "  Train: [53000/57525] ( 92.1%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:39\n",
      "  Train: [53100/57525] ( 92.3%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:36\n",
      "  Train: [53200/57525] ( 92.5%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:34\n",
      "  Train: [53300/57525] ( 92.7%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:32\n",
      "  Train: [53400/57525] ( 92.8%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:30\n",
      "  Train: [53500/57525] ( 93.0%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 01:28\n",
      "  Train: [53600/57525] ( 93.2%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:25\n",
      "  Train: [53700/57525] ( 93.4%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 01:23\n",
      "  Train: [53800/57525] ( 93.5%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:21\n",
      "  Train: [53900/57525] ( 93.7%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:19\n",
      "  Train: [54000/57525] ( 93.9%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:17\n",
      "  Train: [54100/57525] ( 94.0%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:15\n",
      "  Train: [54200/57525] ( 94.2%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:12\n",
      "  Train: [54300/57525] ( 94.4%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:10\n",
      "  Train: [54400/57525] ( 94.6%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:08\n",
      "  Train: [54500/57525] ( 94.7%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:06\n",
      "  Train: [54600/57525] ( 94.9%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:04\n",
      "  Train: [54700/57525] ( 95.1%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 01:01\n",
      "  Train: [54800/57525] ( 95.3%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:59\n",
      "  Train: [54900/57525] ( 95.4%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:57\n",
      "  Train: [55000/57525] ( 95.6%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:55\n",
      "  Train: [55100/57525] ( 95.8%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:53\n",
      "  Train: [55200/57525] ( 96.0%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:50\n",
      "  Train: [55300/57525] ( 96.1%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:48\n",
      "  Train: [55400/57525] ( 96.3%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:46\n",
      "  Train: [55500/57525] ( 96.5%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:44\n",
      "  Train: [55600/57525] ( 96.7%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:42\n",
      "  Train: [55700/57525] ( 96.8%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:40\n",
      "  Train: [55800/57525] ( 97.0%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:37\n",
      "  Train: [55900/57525] ( 97.2%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:35\n",
      "  Train: [56000/57525] ( 97.3%) | Loss: 0.5991 | Speed: 45.6 batches/s | ETA: 00:33\n",
      "  Train: [56100/57525] ( 97.5%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:31\n",
      "  Train: [56200/57525] ( 97.7%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:29\n",
      "  Train: [56300/57525] ( 97.9%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:26\n",
      "  Train: [56400/57525] ( 98.0%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:24\n",
      "  Train: [56500/57525] ( 98.2%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:22\n",
      "  Train: [56600/57525] ( 98.4%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:20\n",
      "  Train: [56700/57525] ( 98.6%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:18\n",
      "  Train: [56800/57525] ( 98.7%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:15\n",
      "  Train: [56900/57525] ( 98.9%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:13\n",
      "  Train: [57000/57525] ( 99.1%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:11\n",
      "  Train: [57100/57525] ( 99.3%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:09\n",
      "  Train: [57200/57525] ( 99.4%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:07\n",
      "  Train: [57300/57525] ( 99.6%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:04\n",
      "  Train: [57400/57525] ( 99.8%) | Loss: 0.5990 | Speed: 45.6 batches/s | ETA: 00:02\n",
      "  Train: [57500/57525] (100.0%) | Loss: 0.5989 | Speed: 45.6 batches/s | ETA: 00:00\n",
      "  Running validation...\n",
      "    Val: [  50/7191] (  0.7%)\n",
      "    Val: [ 100/7191] (  1.4%)\n",
      "    Val: [ 150/7191] (  2.1%)\n",
      "    Val: [ 200/7191] (  2.8%)\n",
      "    Val: [ 250/7191] (  3.5%)\n",
      "    Val: [ 300/7191] (  4.2%)\n",
      "    Val: [ 350/7191] (  4.9%)\n",
      "    Val: [ 400/7191] (  5.6%)\n",
      "    Val: [ 450/7191] (  6.3%)\n",
      "    Val: [ 500/7191] (  7.0%)\n",
      "    Val: [ 550/7191] (  7.6%)\n",
      "    Val: [ 600/7191] (  8.3%)\n",
      "    Val: [ 650/7191] (  9.0%)\n",
      "    Val: [ 700/7191] (  9.7%)\n",
      "    Val: [ 750/7191] ( 10.4%)\n",
      "    Val: [ 800/7191] ( 11.1%)\n",
      "    Val: [ 850/7191] ( 11.8%)\n",
      "    Val: [ 900/7191] ( 12.5%)\n",
      "    Val: [ 950/7191] ( 13.2%)\n",
      "    Val: [1000/7191] ( 13.9%)\n",
      "    Val: [1050/7191] ( 14.6%)\n",
      "    Val: [1100/7191] ( 15.3%)\n",
      "    Val: [1150/7191] ( 16.0%)\n",
      "    Val: [1200/7191] ( 16.7%)\n",
      "    Val: [1250/7191] ( 17.4%)\n",
      "    Val: [1300/7191] ( 18.1%)\n",
      "    Val: [1350/7191] ( 18.8%)\n",
      "    Val: [1400/7191] ( 19.5%)\n",
      "    Val: [1450/7191] ( 20.2%)\n",
      "    Val: [1500/7191] ( 20.9%)\n",
      "    Val: [1550/7191] ( 21.6%)\n",
      "    Val: [1600/7191] ( 22.3%)\n",
      "    Val: [1650/7191] ( 22.9%)\n",
      "    Val: [1700/7191] ( 23.6%)\n",
      "    Val: [1750/7191] ( 24.3%)\n",
      "    Val: [1800/7191] ( 25.0%)\n",
      "    Val: [1850/7191] ( 25.7%)\n",
      "    Val: [1900/7191] ( 26.4%)\n",
      "    Val: [1950/7191] ( 27.1%)\n",
      "    Val: [2000/7191] ( 27.8%)\n",
      "    Val: [2050/7191] ( 28.5%)\n",
      "    Val: [2100/7191] ( 29.2%)\n",
      "    Val: [2150/7191] ( 29.9%)\n",
      "    Val: [2200/7191] ( 30.6%)\n",
      "    Val: [2250/7191] ( 31.3%)\n",
      "    Val: [2300/7191] ( 32.0%)\n",
      "    Val: [2350/7191] ( 32.7%)\n",
      "    Val: [2400/7191] ( 33.4%)\n",
      "    Val: [2450/7191] ( 34.1%)\n",
      "    Val: [2500/7191] ( 34.8%)\n",
      "    Val: [2550/7191] ( 35.5%)\n",
      "    Val: [2600/7191] ( 36.2%)\n",
      "    Val: [2650/7191] ( 36.9%)\n",
      "    Val: [2700/7191] ( 37.5%)\n",
      "    Val: [2750/7191] ( 38.2%)\n",
      "    Val: [2800/7191] ( 38.9%)\n",
      "    Val: [2850/7191] ( 39.6%)\n",
      "    Val: [2900/7191] ( 40.3%)\n",
      "    Val: [2950/7191] ( 41.0%)\n",
      "    Val: [3000/7191] ( 41.7%)\n",
      "    Val: [3050/7191] ( 42.4%)\n",
      "    Val: [3100/7191] ( 43.1%)\n",
      "    Val: [3150/7191] ( 43.8%)\n",
      "    Val: [3200/7191] ( 44.5%)\n",
      "    Val: [3250/7191] ( 45.2%)\n",
      "    Val: [3300/7191] ( 45.9%)\n",
      "    Val: [3350/7191] ( 46.6%)\n",
      "    Val: [3400/7191] ( 47.3%)\n",
      "    Val: [3450/7191] ( 48.0%)\n",
      "    Val: [3500/7191] ( 48.7%)\n",
      "    Val: [3550/7191] ( 49.4%)\n",
      "    Val: [3600/7191] ( 50.1%)\n",
      "    Val: [3650/7191] ( 50.8%)\n",
      "    Val: [3700/7191] ( 51.5%)\n",
      "    Val: [3750/7191] ( 52.1%)\n",
      "    Val: [3800/7191] ( 52.8%)\n",
      "    Val: [3850/7191] ( 53.5%)\n",
      "    Val: [3900/7191] ( 54.2%)\n",
      "    Val: [3950/7191] ( 54.9%)\n",
      "    Val: [4000/7191] ( 55.6%)\n",
      "    Val: [4050/7191] ( 56.3%)\n",
      "    Val: [4100/7191] ( 57.0%)\n",
      "    Val: [4150/7191] ( 57.7%)\n",
      "    Val: [4200/7191] ( 58.4%)\n",
      "    Val: [4250/7191] ( 59.1%)\n",
      "    Val: [4300/7191] ( 59.8%)\n",
      "    Val: [4350/7191] ( 60.5%)\n",
      "    Val: [4400/7191] ( 61.2%)\n",
      "    Val: [4450/7191] ( 61.9%)\n",
      "    Val: [4500/7191] ( 62.6%)\n",
      "    Val: [4550/7191] ( 63.3%)\n",
      "    Val: [4600/7191] ( 64.0%)\n",
      "    Val: [4650/7191] ( 64.7%)\n",
      "    Val: [4700/7191] ( 65.4%)\n",
      "    Val: [4750/7191] ( 66.1%)\n",
      "    Val: [4800/7191] ( 66.8%)\n",
      "    Val: [4850/7191] ( 67.4%)\n",
      "    Val: [4900/7191] ( 68.1%)\n",
      "    Val: [4950/7191] ( 68.8%)\n",
      "    Val: [5000/7191] ( 69.5%)\n",
      "    Val: [5050/7191] ( 70.2%)\n",
      "    Val: [5100/7191] ( 70.9%)\n",
      "    Val: [5150/7191] ( 71.6%)\n",
      "    Val: [5200/7191] ( 72.3%)\n",
      "    Val: [5250/7191] ( 73.0%)\n",
      "    Val: [5300/7191] ( 73.7%)\n",
      "    Val: [5350/7191] ( 74.4%)\n",
      "    Val: [5400/7191] ( 75.1%)\n",
      "    Val: [5450/7191] ( 75.8%)\n",
      "    Val: [5500/7191] ( 76.5%)\n",
      "    Val: [5550/7191] ( 77.2%)\n",
      "    Val: [5600/7191] ( 77.9%)\n",
      "    Val: [5650/7191] ( 78.6%)\n",
      "    Val: [5700/7191] ( 79.3%)\n",
      "    Val: [5750/7191] ( 80.0%)\n",
      "    Val: [5800/7191] ( 80.7%)\n",
      "    Val: [5850/7191] ( 81.4%)\n",
      "    Val: [5900/7191] ( 82.0%)\n",
      "    Val: [5950/7191] ( 82.7%)\n",
      "    Val: [6000/7191] ( 83.4%)\n",
      "    Val: [6050/7191] ( 84.1%)\n",
      "    Val: [6100/7191] ( 84.8%)\n",
      "    Val: [6150/7191] ( 85.5%)\n",
      "    Val: [6200/7191] ( 86.2%)\n",
      "    Val: [6250/7191] ( 86.9%)\n",
      "    Val: [6300/7191] ( 87.6%)\n",
      "    Val: [6350/7191] ( 88.3%)\n",
      "    Val: [6400/7191] ( 89.0%)\n",
      "    Val: [6450/7191] ( 89.7%)\n",
      "    Val: [6500/7191] ( 90.4%)\n",
      "    Val: [6550/7191] ( 91.1%)\n",
      "    Val: [6600/7191] ( 91.8%)\n",
      "    Val: [6650/7191] ( 92.5%)\n",
      "    Val: [6700/7191] ( 93.2%)\n",
      "    Val: [6750/7191] ( 93.9%)\n",
      "    Val: [6800/7191] ( 94.6%)\n",
      "    Val: [6850/7191] ( 95.3%)\n",
      "    Val: [6900/7191] ( 96.0%)\n",
      "    Val: [6950/7191] ( 96.6%)\n",
      "    Val: [7000/7191] ( 97.3%)\n",
      "    Val: [7050/7191] ( 98.0%)\n",
      "    Val: [7100/7191] ( 98.7%)\n",
      "    Val: [7150/7191] ( 99.4%)\n",
      "\n",
      "  Epoch 04 Summary:\n",
      "    Train MSE (norm): 0.5989 | Val MSE (norm): 0.5759\n",
      "    Time: Train=21.0min, Val=0.9min, Total=21.9min\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 05/5\n",
      "============================================================\n",
      "  Train: [  100/57525] (  0.2%) | Loss: 0.5947 | Speed: 31.0 batches/s | ETA: 30:52\n",
      "  Train: [  200/57525] (  0.3%) | Loss: 0.5992 | Speed: 36.9 batches/s | ETA: 25:54\n",
      "  Train: [  300/57525] (  0.5%) | Loss: 0.5999 | Speed: 39.5 batches/s | ETA: 24:09\n",
      "  Train: [  400/57525] (  0.7%) | Loss: 0.5988 | Speed: 40.9 batches/s | ETA: 23:15\n",
      "  Train: [  500/57525] (  0.9%) | Loss: 0.5961 | Speed: 41.8 batches/s | ETA: 22:43\n",
      "  Train: [  600/57525] (  1.0%) | Loss: 0.5963 | Speed: 42.4 batches/s | ETA: 22:21\n",
      "  Train: [  700/57525] (  1.2%) | Loss: 0.5959 | Speed: 42.9 batches/s | ETA: 22:04\n",
      "  Train: [  800/57525] (  1.4%) | Loss: 0.5924 | Speed: 43.2 batches/s | ETA: 21:52\n",
      "  Train: [  900/57525] (  1.6%) | Loss: 0.5903 | Speed: 43.4 batches/s | ETA: 21:44\n",
      "  Train: [ 1000/57525] (  1.7%) | Loss: 0.5901 | Speed: 43.6 batches/s | ETA: 21:35\n",
      "  Train: [ 1100/57525] (  1.9%) | Loss: 0.5909 | Speed: 43.8 batches/s | ETA: 21:27\n",
      "  Train: [ 1200/57525] (  2.1%) | Loss: 0.5920 | Speed: 44.0 batches/s | ETA: 21:21\n",
      "  Train: [ 1300/57525] (  2.3%) | Loss: 0.5939 | Speed: 44.0 batches/s | ETA: 21:17\n",
      "  Train: [ 1400/57525] (  2.4%) | Loss: 0.5938 | Speed: 44.0 batches/s | ETA: 21:16\n",
      "  Train: [ 1500/57525] (  2.6%) | Loss: 0.5935 | Speed: 44.1 batches/s | ETA: 21:10\n",
      "  Train: [ 1600/57525] (  2.8%) | Loss: 0.5927 | Speed: 44.2 batches/s | ETA: 21:05\n",
      "  Train: [ 1700/57525] (  3.0%) | Loss: 0.5924 | Speed: 44.2 batches/s | ETA: 21:01\n",
      "  Train: [ 1800/57525] (  3.1%) | Loss: 0.5915 | Speed: 44.3 batches/s | ETA: 20:58\n",
      "  Train: [ 1900/57525] (  3.3%) | Loss: 0.5916 | Speed: 44.2 batches/s | ETA: 20:58\n",
      "  Train: [ 2000/57525] (  3.5%) | Loss: 0.5920 | Speed: 44.2 batches/s | ETA: 20:56\n",
      "  Train: [ 2100/57525] (  3.7%) | Loss: 0.5926 | Speed: 44.3 batches/s | ETA: 20:52\n",
      "  Train: [ 2200/57525] (  3.8%) | Loss: 0.5934 | Speed: 44.3 batches/s | ETA: 20:48\n",
      "  Train: [ 2300/57525] (  4.0%) | Loss: 0.5934 | Speed: 44.4 batches/s | ETA: 20:44\n",
      "  Train: [ 2400/57525] (  4.2%) | Loss: 0.5932 | Speed: 44.4 batches/s | ETA: 20:41\n",
      "  Train: [ 2500/57525] (  4.3%) | Loss: 0.5938 | Speed: 44.5 batches/s | ETA: 20:37\n",
      "  Train: [ 2600/57525] (  4.5%) | Loss: 0.5932 | Speed: 44.5 batches/s | ETA: 20:33\n",
      "  Train: [ 2700/57525] (  4.7%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 20:29\n",
      "  Train: [ 2800/57525] (  4.9%) | Loss: 0.5939 | Speed: 44.6 batches/s | ETA: 20:26\n",
      "  Train: [ 2900/57525] (  5.0%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 20:22\n",
      "  Train: [ 3000/57525] (  5.2%) | Loss: 0.5937 | Speed: 44.7 batches/s | ETA: 20:19\n",
      "  Train: [ 3100/57525] (  5.4%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 20:17\n",
      "  Train: [ 3200/57525] (  5.6%) | Loss: 0.5942 | Speed: 44.7 batches/s | ETA: 20:14\n",
      "  Train: [ 3300/57525] (  5.7%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 20:11\n",
      "  Train: [ 3400/57525] (  5.9%) | Loss: 0.5937 | Speed: 44.8 batches/s | ETA: 20:08\n",
      "  Train: [ 3500/57525] (  6.1%) | Loss: 0.5938 | Speed: 44.8 batches/s | ETA: 20:05\n",
      "  Train: [ 3600/57525] (  6.3%) | Loss: 0.5933 | Speed: 44.8 batches/s | ETA: 20:03\n",
      "  Train: [ 3700/57525] (  6.4%) | Loss: 0.5930 | Speed: 44.8 batches/s | ETA: 20:01\n",
      "  Train: [ 3800/57525] (  6.6%) | Loss: 0.5932 | Speed: 44.8 batches/s | ETA: 19:58\n",
      "  Train: [ 3900/57525] (  6.8%) | Loss: 0.5933 | Speed: 44.9 batches/s | ETA: 19:55\n",
      "  Train: [ 4000/57525] (  7.0%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 19:52\n",
      "  Train: [ 4100/57525] (  7.1%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 19:49\n",
      "  Train: [ 4200/57525] (  7.3%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 19:46\n",
      "  Train: [ 4300/57525] (  7.5%) | Loss: 0.5931 | Speed: 44.9 batches/s | ETA: 19:44\n",
      "  Train: [ 4400/57525] (  7.6%) | Loss: 0.5927 | Speed: 44.9 batches/s | ETA: 19:42\n",
      "  Train: [ 4500/57525] (  7.8%) | Loss: 0.5925 | Speed: 45.0 batches/s | ETA: 19:39\n",
      "  Train: [ 4600/57525] (  8.0%) | Loss: 0.5929 | Speed: 45.0 batches/s | ETA: 19:36\n",
      "  Train: [ 4700/57525] (  8.2%) | Loss: 0.5932 | Speed: 45.0 batches/s | ETA: 19:34\n",
      "  Train: [ 4800/57525] (  8.3%) | Loss: 0.5938 | Speed: 45.0 batches/s | ETA: 19:31\n",
      "  Train: [ 4900/57525] (  8.5%) | Loss: 0.5938 | Speed: 45.0 batches/s | ETA: 19:29\n",
      "  Train: [ 5000/57525] (  8.7%) | Loss: 0.5939 | Speed: 45.0 batches/s | ETA: 19:26\n",
      "  Train: [ 5100/57525] (  8.9%) | Loss: 0.5942 | Speed: 45.0 batches/s | ETA: 19:24\n",
      "  Train: [ 5200/57525] (  9.0%) | Loss: 0.5941 | Speed: 45.0 batches/s | ETA: 19:21\n",
      "  Train: [ 5300/57525] (  9.2%) | Loss: 0.5946 | Speed: 45.1 batches/s | ETA: 19:18\n",
      "  Train: [ 5400/57525] (  9.4%) | Loss: 0.5949 | Speed: 45.1 batches/s | ETA: 19:16\n",
      "  Train: [ 5500/57525] (  9.6%) | Loss: 0.5947 | Speed: 45.1 batches/s | ETA: 19:14\n",
      "  Train: [ 5600/57525] (  9.7%) | Loss: 0.5945 | Speed: 45.1 batches/s | ETA: 19:11\n",
      "  Train: [ 5700/57525] (  9.9%) | Loss: 0.5946 | Speed: 45.1 batches/s | ETA: 19:09\n",
      "  Train: [ 5800/57525] ( 10.1%) | Loss: 0.5942 | Speed: 45.1 batches/s | ETA: 19:07\n",
      "  Train: [ 5900/57525] ( 10.3%) | Loss: 0.5943 | Speed: 45.1 batches/s | ETA: 19:04\n",
      "  Train: [ 6000/57525] ( 10.4%) | Loss: 0.5944 | Speed: 45.1 batches/s | ETA: 19:01\n",
      "  Train: [ 6100/57525] ( 10.6%) | Loss: 0.5942 | Speed: 45.1 batches/s | ETA: 18:59\n",
      "  Train: [ 6200/57525] ( 10.8%) | Loss: 0.5942 | Speed: 45.1 batches/s | ETA: 18:57\n",
      "  Train: [ 6300/57525] ( 11.0%) | Loss: 0.5942 | Speed: 45.1 batches/s | ETA: 18:55\n",
      "  Train: [ 6400/57525] ( 11.1%) | Loss: 0.5943 | Speed: 45.1 batches/s | ETA: 18:52\n",
      "  Train: [ 6500/57525] ( 11.3%) | Loss: 0.5944 | Speed: 45.1 batches/s | ETA: 18:50\n",
      "  Train: [ 6600/57525] ( 11.5%) | Loss: 0.5946 | Speed: 45.1 batches/s | ETA: 18:48\n",
      "  Train: [ 6700/57525] ( 11.6%) | Loss: 0.5949 | Speed: 45.1 batches/s | ETA: 18:46\n",
      "  Train: [ 6800/57525] ( 11.8%) | Loss: 0.5947 | Speed: 45.1 batches/s | ETA: 18:43\n",
      "  Train: [ 6900/57525] ( 12.0%) | Loss: 0.5945 | Speed: 45.1 batches/s | ETA: 18:41\n",
      "  Train: [ 7000/57525] ( 12.2%) | Loss: 0.5948 | Speed: 45.1 batches/s | ETA: 18:39\n",
      "  Train: [ 7100/57525] ( 12.3%) | Loss: 0.5951 | Speed: 45.1 batches/s | ETA: 18:37\n",
      "  Train: [ 7200/57525] ( 12.5%) | Loss: 0.5952 | Speed: 45.1 batches/s | ETA: 18:35\n",
      "  Train: [ 7300/57525] ( 12.7%) | Loss: 0.5951 | Speed: 45.1 batches/s | ETA: 18:33\n",
      "  Train: [ 7400/57525] ( 12.9%) | Loss: 0.5952 | Speed: 45.1 batches/s | ETA: 18:32\n",
      "  Train: [ 7500/57525] ( 13.0%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 18:30\n",
      "  Train: [ 7600/57525] ( 13.2%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 18:28\n",
      "  Train: [ 7700/57525] ( 13.4%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 18:26\n",
      "  Train: [ 7800/57525] ( 13.6%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 18:23\n",
      "  Train: [ 7900/57525] ( 13.7%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 18:21\n",
      "  Train: [ 8000/57525] ( 13.9%) | Loss: 0.5948 | Speed: 45.0 batches/s | ETA: 18:19\n",
      "  Train: [ 8100/57525] ( 14.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 18:17\n",
      "  Train: [ 8200/57525] ( 14.3%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 18:15\n",
      "  Train: [ 8300/57525] ( 14.4%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 18:13\n",
      "  Train: [ 8400/57525] ( 14.6%) | Loss: 0.5953 | Speed: 45.0 batches/s | ETA: 18:11\n",
      "  Train: [ 8500/57525] ( 14.8%) | Loss: 0.5951 | Speed: 45.0 batches/s | ETA: 18:09\n",
      "  Train: [ 8600/57525] ( 15.0%) | Loss: 0.5954 | Speed: 45.0 batches/s | ETA: 18:07\n",
      "  Train: [ 8700/57525] ( 15.1%) | Loss: 0.5955 | Speed: 45.0 batches/s | ETA: 18:04\n",
      "  Train: [ 8800/57525] ( 15.3%) | Loss: 0.5953 | Speed: 45.0 batches/s | ETA: 18:02\n",
      "  Train: [ 8900/57525] ( 15.5%) | Loss: 0.5952 | Speed: 45.0 batches/s | ETA: 18:00\n",
      "  Train: [ 9000/57525] ( 15.6%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 17:58\n",
      "  Train: [ 9100/57525] ( 15.8%) | Loss: 0.5951 | Speed: 45.0 batches/s | ETA: 17:56\n",
      "  Train: [ 9200/57525] ( 16.0%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 17:53\n",
      "  Train: [ 9300/57525] ( 16.2%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 17:51\n",
      "  Train: [ 9400/57525] ( 16.3%) | Loss: 0.5950 | Speed: 45.0 batches/s | ETA: 17:49\n",
      "  Train: [ 9500/57525] ( 16.5%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 17:47\n",
      "  Train: [ 9600/57525] ( 16.7%) | Loss: 0.5949 | Speed: 45.0 batches/s | ETA: 17:45\n",
      "  Train: [ 9700/57525] ( 16.9%) | Loss: 0.5948 | Speed: 45.0 batches/s | ETA: 17:42\n",
      "  Train: [ 9800/57525] ( 17.0%) | Loss: 0.5948 | Speed: 45.0 batches/s | ETA: 17:40\n",
      "  Train: [ 9900/57525] ( 17.2%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 17:38\n",
      "  Train: [10000/57525] ( 17.4%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 17:36\n",
      "  Train: [10100/57525] ( 17.6%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 17:34\n",
      "  Train: [10200/57525] ( 17.7%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 17:32\n",
      "  Train: [10300/57525] ( 17.9%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 17:30\n",
      "  Train: [10400/57525] ( 18.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 17:28\n",
      "  Train: [10500/57525] ( 18.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 17:25\n",
      "  Train: [10600/57525] ( 18.4%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 17:23\n",
      "  Train: [10700/57525] ( 18.6%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 17:21\n",
      "  Train: [10800/57525] ( 18.8%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 17:19\n",
      "  Train: [10900/57525] ( 18.9%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 17:17\n",
      "  Train: [11000/57525] ( 19.1%) | Loss: 0.5941 | Speed: 45.0 batches/s | ETA: 17:14\n",
      "  Train: [11100/57525] ( 19.3%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 17:12\n",
      "  Train: [11200/57525] ( 19.5%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 17:10\n",
      "  Train: [11300/57525] ( 19.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 17:08\n",
      "  Train: [11400/57525] ( 19.8%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 17:06\n",
      "  Train: [11500/57525] ( 20.0%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 17:04\n",
      "  Train: [11600/57525] ( 20.2%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 17:01\n",
      "  Train: [11700/57525] ( 20.3%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 16:59\n",
      "  Train: [11800/57525] ( 20.5%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 16:57\n",
      "  Train: [11900/57525] ( 20.7%) | Loss: 0.5937 | Speed: 44.9 batches/s | ETA: 16:55\n",
      "  Train: [12000/57525] ( 20.9%) | Loss: 0.5937 | Speed: 44.9 batches/s | ETA: 16:53\n",
      "  Train: [12100/57525] ( 21.0%) | Loss: 0.5937 | Speed: 44.9 batches/s | ETA: 16:50\n",
      "  Train: [12200/57525] ( 21.2%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:48\n",
      "  Train: [12300/57525] ( 21.4%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:46\n",
      "  Train: [12400/57525] ( 21.6%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:44\n",
      "  Train: [12500/57525] ( 21.7%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 16:42\n",
      "  Train: [12600/57525] ( 21.9%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:39\n",
      "  Train: [12700/57525] ( 22.1%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 16:37\n",
      "  Train: [12800/57525] ( 22.3%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:35\n",
      "  Train: [12900/57525] ( 22.4%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:33\n",
      "  Train: [13000/57525] ( 22.6%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:31\n",
      "  Train: [13100/57525] ( 22.8%) | Loss: 0.5935 | Speed: 44.9 batches/s | ETA: 16:28\n",
      "  Train: [13200/57525] ( 22.9%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 16:26\n",
      "  Train: [13300/57525] ( 23.1%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 16:24\n",
      "  Train: [13400/57525] ( 23.3%) | Loss: 0.5937 | Speed: 44.9 batches/s | ETA: 16:22\n",
      "  Train: [13500/57525] ( 23.5%) | Loss: 0.5936 | Speed: 44.9 batches/s | ETA: 16:20\n",
      "  Train: [13600/57525] ( 23.6%) | Loss: 0.5937 | Speed: 44.9 batches/s | ETA: 16:17\n",
      "  Train: [13700/57525] ( 23.8%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 16:15\n",
      "  Train: [13800/57525] ( 24.0%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 16:13\n",
      "  Train: [13900/57525] ( 24.2%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 16:11\n",
      "  Train: [14000/57525] ( 24.3%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 16:09\n",
      "  Train: [14100/57525] ( 24.5%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 16:06\n",
      "  Train: [14200/57525] ( 24.7%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 16:04\n",
      "  Train: [14300/57525] ( 24.9%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 16:02\n",
      "  Train: [14400/57525] ( 25.0%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 16:00\n",
      "  Train: [14500/57525] ( 25.2%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 15:57\n",
      "  Train: [14600/57525] ( 25.4%) | Loss: 0.5938 | Speed: 44.9 batches/s | ETA: 15:55\n",
      "  Train: [14700/57525] ( 25.6%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 15:53\n",
      "  Train: [14800/57525] ( 25.7%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 15:51\n",
      "  Train: [14900/57525] ( 25.9%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 15:48\n",
      "  Train: [15000/57525] ( 26.1%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:46\n",
      "  Train: [15100/57525] ( 26.2%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:44\n",
      "  Train: [15200/57525] ( 26.4%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 15:42\n",
      "  Train: [15300/57525] ( 26.6%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 15:40\n",
      "  Train: [15400/57525] ( 26.8%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:37\n",
      "  Train: [15500/57525] ( 26.9%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:35\n",
      "  Train: [15600/57525] ( 27.1%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:33\n",
      "  Train: [15700/57525] ( 27.3%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:31\n",
      "  Train: [15800/57525] ( 27.5%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:29\n",
      "  Train: [15900/57525] ( 27.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:27\n",
      "  Train: [16000/57525] ( 27.8%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:24\n",
      "  Train: [16100/57525] ( 28.0%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:22\n",
      "  Train: [16200/57525] ( 28.2%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:20\n",
      "  Train: [16300/57525] ( 28.3%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 15:18\n",
      "  Train: [16400/57525] ( 28.5%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:16\n",
      "  Train: [16500/57525] ( 28.7%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 15:13\n",
      "  Train: [16600/57525] ( 28.9%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:11\n",
      "  Train: [16700/57525] ( 29.0%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:09\n",
      "  Train: [16800/57525] ( 29.2%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 15:07\n",
      "  Train: [16900/57525] ( 29.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:05\n",
      "  Train: [17000/57525] ( 29.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 15:02\n",
      "  Train: [17100/57525] ( 29.7%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 15:00\n",
      "  Train: [17200/57525] ( 29.9%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 14:58\n",
      "  Train: [17300/57525] ( 30.1%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 14:56\n",
      "  Train: [17400/57525] ( 30.2%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 14:54\n",
      "  Train: [17500/57525] ( 30.4%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 14:52\n",
      "  Train: [17600/57525] ( 30.6%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:49\n",
      "  Train: [17700/57525] ( 30.8%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:47\n",
      "  Train: [17800/57525] ( 30.9%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:45\n",
      "  Train: [17900/57525] ( 31.1%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:43\n",
      "  Train: [18000/57525] ( 31.3%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:40\n",
      "  Train: [18100/57525] ( 31.5%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:38\n",
      "  Train: [18200/57525] ( 31.6%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:36\n",
      "  Train: [18300/57525] ( 31.8%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 14:34\n",
      "  Train: [18400/57525] ( 32.0%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 14:32\n",
      "  Train: [18500/57525] ( 32.2%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 14:29\n",
      "  Train: [18600/57525] ( 32.3%) | Loss: 0.5945 | Speed: 44.9 batches/s | ETA: 14:27\n",
      "  Train: [18700/57525] ( 32.5%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 14:25\n",
      "  Train: [18800/57525] ( 32.7%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 14:23\n",
      "  Train: [18900/57525] ( 32.9%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 14:21\n",
      "  Train: [19000/57525] ( 33.0%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 14:19\n",
      "  Train: [19100/57525] ( 33.2%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:16\n",
      "  Train: [19200/57525] ( 33.4%) | Loss: 0.5949 | Speed: 44.8 batches/s | ETA: 14:14\n",
      "  Train: [19300/57525] ( 33.6%) | Loss: 0.5949 | Speed: 44.8 batches/s | ETA: 14:12\n",
      "  Train: [19400/57525] ( 33.7%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:10\n",
      "  Train: [19500/57525] ( 33.9%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:08\n",
      "  Train: [19600/57525] ( 34.1%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:05\n",
      "  Train: [19700/57525] ( 34.2%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:03\n",
      "  Train: [19800/57525] ( 34.4%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 14:01\n",
      "  Train: [19900/57525] ( 34.6%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 13:59\n",
      "  Train: [20000/57525] ( 34.8%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 13:57\n",
      "  Train: [20100/57525] ( 34.9%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 13:54\n",
      "  Train: [20200/57525] ( 35.1%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 13:52\n",
      "  Train: [20300/57525] ( 35.3%) | Loss: 0.5948 | Speed: 44.8 batches/s | ETA: 13:50\n",
      "  Train: [20400/57525] ( 35.5%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 13:48\n",
      "  Train: [20500/57525] ( 35.6%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 13:46\n",
      "  Train: [20600/57525] ( 35.8%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 13:43\n",
      "  Train: [20700/57525] ( 36.0%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:41\n",
      "  Train: [20800/57525] ( 36.2%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:39\n",
      "  Train: [20900/57525] ( 36.3%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 13:37\n",
      "  Train: [21000/57525] ( 36.5%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:35\n",
      "  Train: [21100/57525] ( 36.7%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:32\n",
      "  Train: [21200/57525] ( 36.9%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:30\n",
      "  Train: [21300/57525] ( 37.0%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:28\n",
      "  Train: [21400/57525] ( 37.2%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:26\n",
      "  Train: [21500/57525] ( 37.4%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:23\n",
      "  Train: [21600/57525] ( 37.5%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:21\n",
      "  Train: [21700/57525] ( 37.7%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:19\n",
      "  Train: [21800/57525] ( 37.9%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:17\n",
      "  Train: [21900/57525] ( 38.1%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:15\n",
      "  Train: [22000/57525] ( 38.2%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 13:13\n",
      "  Train: [22100/57525] ( 38.4%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:11\n",
      "  Train: [22200/57525] ( 38.6%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:08\n",
      "  Train: [22300/57525] ( 38.8%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:06\n",
      "  Train: [22400/57525] ( 38.9%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:04\n",
      "  Train: [22500/57525] ( 39.1%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 13:02\n",
      "  Train: [22600/57525] ( 39.3%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:59\n",
      "  Train: [22700/57525] ( 39.5%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:57\n",
      "  Train: [22800/57525] ( 39.6%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:55\n",
      "  Train: [22900/57525] ( 39.8%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:53\n",
      "  Train: [23000/57525] ( 40.0%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:50\n",
      "  Train: [23100/57525] ( 40.2%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:48\n",
      "  Train: [23200/57525] ( 40.3%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:46\n",
      "  Train: [23300/57525] ( 40.5%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:43\n",
      "  Train: [23400/57525] ( 40.7%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:41\n",
      "  Train: [23500/57525] ( 40.9%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:39\n",
      "  Train: [23600/57525] ( 41.0%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:36\n",
      "  Train: [23700/57525] ( 41.2%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:34\n",
      "  Train: [23800/57525] ( 41.4%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:32\n",
      "  Train: [23900/57525] ( 41.5%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:30\n",
      "  Train: [24000/57525] ( 41.7%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:27\n",
      "  Train: [24100/57525] ( 41.9%) | Loss: 0.5945 | Speed: 44.8 batches/s | ETA: 12:25\n",
      "  Train: [24200/57525] ( 42.1%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:23\n",
      "  Train: [24300/57525] ( 42.2%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:21\n",
      "  Train: [24400/57525] ( 42.4%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:18\n",
      "  Train: [24500/57525] ( 42.6%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:16\n",
      "  Train: [24600/57525] ( 42.8%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:14\n",
      "  Train: [24700/57525] ( 42.9%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 12:12\n",
      "  Train: [24800/57525] ( 43.1%) | Loss: 0.5946 | Speed: 44.8 batches/s | ETA: 12:09\n",
      "  Train: [24900/57525] ( 43.3%) | Loss: 0.5947 | Speed: 44.8 batches/s | ETA: 12:07\n",
      "  Train: [25000/57525] ( 43.5%) | Loss: 0.5948 | Speed: 44.9 batches/s | ETA: 12:05\n",
      "  Train: [25100/57525] ( 43.6%) | Loss: 0.5948 | Speed: 44.9 batches/s | ETA: 12:02\n",
      "  Train: [25200/57525] ( 43.8%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 12:00\n",
      "  Train: [25300/57525] ( 44.0%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:58\n",
      "  Train: [25400/57525] ( 44.2%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:55\n",
      "  Train: [25500/57525] ( 44.3%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:53\n",
      "  Train: [25600/57525] ( 44.5%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:51\n",
      "  Train: [25700/57525] ( 44.7%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:48\n",
      "  Train: [25800/57525] ( 44.9%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:46\n",
      "  Train: [25900/57525] ( 45.0%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:44\n",
      "  Train: [26000/57525] ( 45.2%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:42\n",
      "  Train: [26100/57525] ( 45.4%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:39\n",
      "  Train: [26200/57525] ( 45.5%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:37\n",
      "  Train: [26300/57525] ( 45.7%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:35\n",
      "  Train: [26400/57525] ( 45.9%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:32\n",
      "  Train: [26500/57525] ( 46.1%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:30\n",
      "  Train: [26600/57525] ( 46.2%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:28\n",
      "  Train: [26700/57525] ( 46.4%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:26\n",
      "  Train: [26800/57525] ( 46.6%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:23\n",
      "  Train: [26900/57525] ( 46.8%) | Loss: 0.5947 | Speed: 44.9 batches/s | ETA: 11:21\n",
      "  Train: [27000/57525] ( 46.9%) | Loss: 0.5946 | Speed: 44.9 batches/s | ETA: 11:19\n",
      "  Train: [27100/57525] ( 47.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 11:16\n",
      "  Train: [27200/57525] ( 47.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 11:14\n",
      "  Train: [27300/57525] ( 47.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 11:12\n",
      "  Train: [27400/57525] ( 47.6%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 11:09\n",
      "  Train: [27500/57525] ( 47.8%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 11:07\n",
      "  Train: [27600/57525] ( 48.0%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 11:05\n",
      "  Train: [27700/57525] ( 48.2%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 11:03\n",
      "  Train: [27800/57525] ( 48.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 11:00\n",
      "  Train: [27900/57525] ( 48.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:58\n",
      "  Train: [28000/57525] ( 48.7%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:56\n",
      "  Train: [28100/57525] ( 48.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:53\n",
      "  Train: [28200/57525] ( 49.0%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:51\n",
      "  Train: [28300/57525] ( 49.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:49\n",
      "  Train: [28400/57525] ( 49.4%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 10:47\n",
      "  Train: [28500/57525] ( 49.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:44\n",
      "  Train: [28600/57525] ( 49.7%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:42\n",
      "  Train: [28700/57525] ( 49.9%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:40\n",
      "  Train: [28800/57525] ( 50.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:38\n",
      "  Train: [28900/57525] ( 50.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:36\n",
      "  Train: [29000/57525] ( 50.4%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:33\n",
      "  Train: [29100/57525] ( 50.6%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:31\n",
      "  Train: [29200/57525] ( 50.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:29\n",
      "  Train: [29300/57525] ( 50.9%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 10:27\n",
      "  Train: [29400/57525] ( 51.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:25\n",
      "  Train: [29500/57525] ( 51.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:22\n",
      "  Train: [29600/57525] ( 51.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:20\n",
      "  Train: [29700/57525] ( 51.6%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:18\n",
      "  Train: [29800/57525] ( 51.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:16\n",
      "  Train: [29900/57525] ( 52.0%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:14\n",
      "  Train: [30000/57525] ( 52.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:11\n",
      "  Train: [30100/57525] ( 52.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:09\n",
      "  Train: [30200/57525] ( 52.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:07\n",
      "  Train: [30300/57525] ( 52.7%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:05\n",
      "  Train: [30400/57525] ( 52.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:02\n",
      "  Train: [30500/57525] ( 53.0%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 10:00\n",
      "  Train: [30600/57525] ( 53.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:58\n",
      "  Train: [30700/57525] ( 53.4%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:56\n",
      "  Train: [30800/57525] ( 53.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:53\n",
      "  Train: [30900/57525] ( 53.7%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:51\n",
      "  Train: [31000/57525] ( 53.9%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:49\n",
      "  Train: [31100/57525] ( 54.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:47\n",
      "  Train: [31200/57525] ( 54.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:45\n",
      "  Train: [31300/57525] ( 54.4%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:42\n",
      "  Train: [31400/57525] ( 54.6%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:40\n",
      "  Train: [31500/57525] ( 54.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:38\n",
      "  Train: [31600/57525] ( 54.9%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:36\n",
      "  Train: [31700/57525] ( 55.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:33\n",
      "  Train: [31800/57525] ( 55.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:31\n",
      "  Train: [31900/57525] ( 55.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:29\n",
      "  Train: [32000/57525] ( 55.6%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 09:27\n",
      "  Train: [32100/57525] ( 55.8%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 09:25\n",
      "  Train: [32200/57525] ( 56.0%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 09:22\n",
      "  Train: [32300/57525] ( 56.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:20\n",
      "  Train: [32400/57525] ( 56.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:18\n",
      "  Train: [32500/57525] ( 56.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:16\n",
      "  Train: [32600/57525] ( 56.7%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 09:14\n",
      "  Train: [32700/57525] ( 56.8%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 09:11\n",
      "  Train: [32800/57525] ( 57.0%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:09\n",
      "  Train: [32900/57525] ( 57.2%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:07\n",
      "  Train: [33000/57525] ( 57.4%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 09:05\n",
      "  Train: [33100/57525] ( 57.5%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 09:02\n",
      "  Train: [33200/57525] ( 57.7%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 09:00\n",
      "  Train: [33300/57525] ( 57.9%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 08:58\n",
      "  Train: [33400/57525] ( 58.1%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 08:56\n",
      "  Train: [33500/57525] ( 58.2%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 08:54\n",
      "  Train: [33600/57525] ( 58.4%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 08:51\n",
      "  Train: [33700/57525] ( 58.6%) | Loss: 0.5947 | Speed: 45.0 batches/s | ETA: 08:49\n",
      "  Train: [33800/57525] ( 58.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:47\n",
      "  Train: [33900/57525] ( 58.9%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:45\n",
      "  Train: [34000/57525] ( 59.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:42\n",
      "  Train: [34100/57525] ( 59.3%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:40\n",
      "  Train: [34200/57525] ( 59.5%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:38\n",
      "  Train: [34300/57525] ( 59.6%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:36\n",
      "  Train: [34400/57525] ( 59.8%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:34\n",
      "  Train: [34500/57525] ( 60.0%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:31\n",
      "  Train: [34600/57525] ( 60.1%) | Loss: 0.5946 | Speed: 45.0 batches/s | ETA: 08:29\n",
      "  Train: [34700/57525] ( 60.3%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 08:27\n",
      "  Train: [34800/57525] ( 60.5%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 08:25\n",
      "  Train: [34900/57525] ( 60.7%) | Loss: 0.5945 | Speed: 45.0 batches/s | ETA: 08:23\n",
      "  Train: [35000/57525] ( 60.8%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:20\n",
      "  Train: [35100/57525] ( 61.0%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:18\n",
      "  Train: [35200/57525] ( 61.2%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:16\n",
      "  Train: [35300/57525] ( 61.4%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:14\n",
      "  Train: [35400/57525] ( 61.5%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:12\n",
      "  Train: [35500/57525] ( 61.7%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:09\n",
      "  Train: [35600/57525] ( 61.9%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 08:07\n",
      "  Train: [35700/57525] ( 62.1%) | Loss: 0.5943 | Speed: 45.0 batches/s | ETA: 08:05\n",
      "  Train: [35800/57525] ( 62.2%) | Loss: 0.5943 | Speed: 45.0 batches/s | ETA: 08:03\n",
      "  Train: [35900/57525] ( 62.4%) | Loss: 0.5943 | Speed: 45.0 batches/s | ETA: 08:01\n",
      "  Train: [36000/57525] ( 62.6%) | Loss: 0.5944 | Speed: 45.0 batches/s | ETA: 07:58\n",
      "  Train: [36100/57525] ( 62.8%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 07:56\n",
      "  Train: [36200/57525] ( 62.9%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 07:54\n",
      "  Train: [36300/57525] ( 63.1%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 07:52\n",
      "  Train: [36400/57525] ( 63.3%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 07:50\n",
      "  Train: [36500/57525] ( 63.5%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:47\n",
      "  Train: [36600/57525] ( 63.6%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:45\n",
      "  Train: [36700/57525] ( 63.8%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:43\n",
      "  Train: [36800/57525] ( 64.0%) | Loss: 0.5944 | Speed: 44.9 batches/s | ETA: 07:41\n",
      "  Train: [36900/57525] ( 64.1%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:39\n",
      "  Train: [37000/57525] ( 64.3%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:36\n",
      "  Train: [37100/57525] ( 64.5%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:34\n",
      "  Train: [37200/57525] ( 64.7%) | Loss: 0.5943 | Speed: 44.9 batches/s | ETA: 07:32\n",
      "  Train: [37300/57525] ( 64.8%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 07:30\n",
      "  Train: [37400/57525] ( 65.0%) | Loss: 0.5942 | Speed: 44.9 batches/s | ETA: 07:28\n",
      "  Train: [37500/57525] ( 65.2%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:25\n",
      "  Train: [37600/57525] ( 65.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:23\n",
      "  Train: [37700/57525] ( 65.5%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:21\n",
      "  Train: [37800/57525] ( 65.7%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:19\n",
      "  Train: [37900/57525] ( 65.9%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:16\n",
      "  Train: [38000/57525] ( 66.1%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:14\n",
      "  Train: [38100/57525] ( 66.2%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:12\n",
      "  Train: [38200/57525] ( 66.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:10\n",
      "  Train: [38300/57525] ( 66.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 07:08\n",
      "  Train: [38400/57525] ( 66.8%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 07:05\n",
      "  Train: [38500/57525] ( 66.9%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 07:03\n",
      "  Train: [38600/57525] ( 67.1%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 07:01\n",
      "  Train: [38700/57525] ( 67.3%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:59\n",
      "  Train: [38800/57525] ( 67.4%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:56\n",
      "  Train: [38900/57525] ( 67.6%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:54\n",
      "  Train: [39000/57525] ( 67.8%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 06:52\n",
      "  Train: [39100/57525] ( 68.0%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 06:50\n",
      "  Train: [39200/57525] ( 68.1%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:47\n",
      "  Train: [39300/57525] ( 68.3%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:45\n",
      "  Train: [39400/57525] ( 68.5%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:43\n",
      "  Train: [39500/57525] ( 68.7%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:41\n",
      "  Train: [39600/57525] ( 68.8%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:39\n",
      "  Train: [39700/57525] ( 69.0%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:36\n",
      "  Train: [39800/57525] ( 69.2%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:34\n",
      "  Train: [39900/57525] ( 69.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:32\n",
      "  Train: [40000/57525] ( 69.5%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:30\n",
      "  Train: [40100/57525] ( 69.7%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:27\n",
      "  Train: [40200/57525] ( 69.9%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:25\n",
      "  Train: [40300/57525] ( 70.1%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:23\n",
      "  Train: [40400/57525] ( 70.2%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 06:21\n",
      "  Train: [40500/57525] ( 70.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:18\n",
      "  Train: [40600/57525] ( 70.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:16\n",
      "  Train: [40700/57525] ( 70.8%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:14\n",
      "  Train: [40800/57525] ( 70.9%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:12\n",
      "  Train: [40900/57525] ( 71.1%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:10\n",
      "  Train: [41000/57525] ( 71.3%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:07\n",
      "  Train: [41100/57525] ( 71.4%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:05\n",
      "  Train: [41200/57525] ( 71.6%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:03\n",
      "  Train: [41300/57525] ( 71.8%) | Loss: 0.5941 | Speed: 44.9 batches/s | ETA: 06:01\n",
      "  Train: [41400/57525] ( 72.0%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:59\n",
      "  Train: [41500/57525] ( 72.1%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:56\n",
      "  Train: [41600/57525] ( 72.3%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:54\n",
      "  Train: [41700/57525] ( 72.5%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:52\n",
      "  Train: [41800/57525] ( 72.7%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:50\n",
      "  Train: [41900/57525] ( 72.8%) | Loss: 0.5940 | Speed: 44.9 batches/s | ETA: 05:48\n",
      "  Train: [42000/57525] ( 73.0%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 05:45\n",
      "  Train: [42100/57525] ( 73.2%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 05:43\n",
      "  Train: [42200/57525] ( 73.4%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 05:41\n",
      "  Train: [42300/57525] ( 73.5%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 05:39\n",
      "  Train: [42400/57525] ( 73.7%) | Loss: 0.5939 | Speed: 44.9 batches/s | ETA: 05:37\n",
      "  Train: [42500/57525] ( 73.9%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:35\n",
      "  Train: [42600/57525] ( 74.1%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:32\n",
      "  Train: [42700/57525] ( 74.2%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:30\n",
      "  Train: [42800/57525] ( 74.4%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:28\n",
      "  Train: [42900/57525] ( 74.6%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:26\n",
      "  Train: [43000/57525] ( 74.8%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:24\n",
      "  Train: [43100/57525] ( 74.9%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:21\n",
      "  Train: [43200/57525] ( 75.1%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:19\n",
      "  Train: [43300/57525] ( 75.3%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:17\n",
      "  Train: [43400/57525] ( 75.4%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:15\n",
      "  Train: [43500/57525] ( 75.6%) | Loss: 0.5940 | Speed: 44.8 batches/s | ETA: 05:12\n",
      "  Train: [43600/57525] ( 75.8%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:10\n",
      "  Train: [43700/57525] ( 76.0%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:08\n",
      "  Train: [43800/57525] ( 76.1%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:06\n",
      "  Train: [43900/57525] ( 76.3%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:04\n",
      "  Train: [44000/57525] ( 76.5%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 05:01\n",
      "  Train: [44100/57525] ( 76.7%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:59\n",
      "  Train: [44200/57525] ( 76.8%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:57\n",
      "  Train: [44300/57525] ( 77.0%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:55\n",
      "  Train: [44400/57525] ( 77.2%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:53\n",
      "  Train: [44500/57525] ( 77.4%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:50\n",
      "  Train: [44600/57525] ( 77.5%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:48\n",
      "  Train: [44700/57525] ( 77.7%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:46\n",
      "  Train: [44800/57525] ( 77.9%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:44\n",
      "  Train: [44900/57525] ( 78.1%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:41\n",
      "  Train: [45000/57525] ( 78.2%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:39\n",
      "  Train: [45100/57525] ( 78.4%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:37\n",
      "  Train: [45200/57525] ( 78.6%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:35\n",
      "  Train: [45300/57525] ( 78.7%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:33\n",
      "  Train: [45400/57525] ( 78.9%) | Loss: 0.5939 | Speed: 44.8 batches/s | ETA: 04:30\n",
      "  Train: [45500/57525] ( 79.1%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:28\n",
      "  Train: [45600/57525] ( 79.3%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:26\n",
      "  Train: [45700/57525] ( 79.4%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:24\n",
      "  Train: [45800/57525] ( 79.6%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:22\n",
      "  Train: [45900/57525] ( 79.8%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:19\n",
      "  Train: [46000/57525] ( 80.0%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:17\n",
      "  Train: [46100/57525] ( 80.1%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:15\n",
      "  Train: [46200/57525] ( 80.3%) | Loss: 0.5939 | Speed: 44.7 batches/s | ETA: 04:13\n",
      "  Train: [46300/57525] ( 80.5%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:11\n",
      "  Train: [46400/57525] ( 80.7%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:08\n",
      "  Train: [46500/57525] ( 80.8%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:06\n",
      "  Train: [46600/57525] ( 81.0%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:04\n",
      "  Train: [46700/57525] ( 81.2%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 04:02\n",
      "  Train: [46800/57525] ( 81.4%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:59\n",
      "  Train: [46900/57525] ( 81.5%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:57\n",
      "  Train: [47000/57525] ( 81.7%) | Loss: 0.5937 | Speed: 44.7 batches/s | ETA: 03:55\n",
      "  Train: [47100/57525] ( 81.9%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:53\n",
      "  Train: [47200/57525] ( 82.1%) | Loss: 0.5937 | Speed: 44.7 batches/s | ETA: 03:51\n",
      "  Train: [47300/57525] ( 82.2%) | Loss: 0.5937 | Speed: 44.7 batches/s | ETA: 03:48\n",
      "  Train: [47400/57525] ( 82.4%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:46\n",
      "  Train: [47500/57525] ( 82.6%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:44\n",
      "  Train: [47600/57525] ( 82.7%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:42\n",
      "  Train: [47700/57525] ( 82.9%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:39\n",
      "  Train: [47800/57525] ( 83.1%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:37\n",
      "  Train: [47900/57525] ( 83.3%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:35\n",
      "  Train: [48000/57525] ( 83.4%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:33\n",
      "  Train: [48100/57525] ( 83.6%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:31\n",
      "  Train: [48200/57525] ( 83.8%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:28\n",
      "  Train: [48300/57525] ( 84.0%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:26\n",
      "  Train: [48400/57525] ( 84.1%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:24\n",
      "  Train: [48500/57525] ( 84.3%) | Loss: 0.5938 | Speed: 44.7 batches/s | ETA: 03:22\n",
      "  Train: [48600/57525] ( 84.5%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:19\n",
      "  Train: [48700/57525] ( 84.7%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:17\n",
      "  Train: [48800/57525] ( 84.8%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:15\n",
      "  Train: [48900/57525] ( 85.0%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:13\n",
      "  Train: [49000/57525] ( 85.2%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:11\n",
      "  Train: [49100/57525] ( 85.4%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:08\n",
      "  Train: [49200/57525] ( 85.5%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:06\n",
      "  Train: [49300/57525] ( 85.7%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:04\n",
      "  Train: [49400/57525] ( 85.9%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 03:02\n",
      "  Train: [49500/57525] ( 86.0%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:59\n",
      "  Train: [49600/57525] ( 86.2%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:57\n",
      "  Train: [49700/57525] ( 86.4%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:55\n",
      "  Train: [49800/57525] ( 86.6%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:53\n",
      "  Train: [49900/57525] ( 86.7%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:50\n",
      "  Train: [50000/57525] ( 86.9%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:48\n",
      "  Train: [50100/57525] ( 87.1%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:46\n",
      "  Train: [50200/57525] ( 87.3%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:44\n",
      "  Train: [50300/57525] ( 87.4%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:42\n",
      "  Train: [50400/57525] ( 87.6%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:39\n",
      "  Train: [50500/57525] ( 87.8%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:37\n",
      "  Train: [50600/57525] ( 88.0%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:35\n",
      "  Train: [50700/57525] ( 88.1%) | Loss: 0.5938 | Speed: 44.6 batches/s | ETA: 02:33\n",
      "  Train: [50800/57525] ( 88.3%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:30\n",
      "  Train: [50900/57525] ( 88.5%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:28\n",
      "  Train: [51000/57525] ( 88.7%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:26\n",
      "  Train: [51100/57525] ( 88.8%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:24\n",
      "  Train: [51200/57525] ( 89.0%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:21\n",
      "  Train: [51300/57525] ( 89.2%) | Loss: 0.5937 | Speed: 44.6 batches/s | ETA: 02:19\n",
      "  Train: [51400/57525] ( 89.4%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:17\n",
      "  Train: [51500/57525] ( 89.5%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:15\n",
      "  Train: [51600/57525] ( 89.7%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 02:13\n",
      "  Train: [51700/57525] ( 89.9%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:10\n",
      "  Train: [51800/57525] ( 90.0%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:08\n",
      "  Train: [51900/57525] ( 90.2%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:06\n",
      "  Train: [52000/57525] ( 90.4%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:04\n",
      "  Train: [52100/57525] ( 90.6%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 02:01\n",
      "  Train: [52200/57525] ( 90.7%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:59\n",
      "  Train: [52300/57525] ( 90.9%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:57\n",
      "  Train: [52400/57525] ( 91.1%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:55\n",
      "  Train: [52500/57525] ( 91.3%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:52\n",
      "  Train: [52600/57525] ( 91.4%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:50\n",
      "  Train: [52700/57525] ( 91.6%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:48\n",
      "  Train: [52800/57525] ( 91.8%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:46\n",
      "  Train: [52900/57525] ( 92.0%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:43\n",
      "  Train: [53000/57525] ( 92.1%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:41\n",
      "  Train: [53100/57525] ( 92.3%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:39\n",
      "  Train: [53200/57525] ( 92.5%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:37\n",
      "  Train: [53300/57525] ( 92.7%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:34\n",
      "  Train: [53400/57525] ( 92.8%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:32\n",
      "  Train: [53500/57525] ( 93.0%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:30\n",
      "  Train: [53600/57525] ( 93.2%) | Loss: 0.5937 | Speed: 44.5 batches/s | ETA: 01:28\n",
      "  Train: [53700/57525] ( 93.4%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:25\n",
      "  Train: [53800/57525] ( 93.5%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:23\n",
      "  Train: [53900/57525] ( 93.7%) | Loss: 0.5936 | Speed: 44.5 batches/s | ETA: 01:21\n",
      "  Train: [54000/57525] ( 93.9%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:19\n",
      "  Train: [54100/57525] ( 94.0%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:16\n",
      "  Train: [54200/57525] ( 94.2%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:14\n",
      "  Train: [54300/57525] ( 94.4%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:12\n",
      "  Train: [54400/57525] ( 94.6%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:10\n",
      "  Train: [54500/57525] ( 94.7%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:07\n",
      "  Train: [54600/57525] ( 94.9%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 01:05\n",
      "  Train: [54700/57525] ( 95.1%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:03\n",
      "  Train: [54800/57525] ( 95.3%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 01:01\n",
      "  Train: [54900/57525] ( 95.4%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:58\n",
      "  Train: [55000/57525] ( 95.6%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:56\n",
      "  Train: [55100/57525] ( 95.8%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:54\n",
      "  Train: [55200/57525] ( 96.0%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:52\n",
      "  Train: [55300/57525] ( 96.1%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:49\n",
      "  Train: [55400/57525] ( 96.3%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:47\n",
      "  Train: [55500/57525] ( 96.5%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:45\n",
      "  Train: [55600/57525] ( 96.7%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:43\n",
      "  Train: [55700/57525] ( 96.8%) | Loss: 0.5935 | Speed: 44.5 batches/s | ETA: 00:41\n",
      "  Train: [55800/57525] ( 97.0%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:38\n",
      "  Train: [55900/57525] ( 97.2%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:36\n",
      "  Train: [56000/57525] ( 97.3%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:34\n",
      "  Train: [56100/57525] ( 97.5%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:32\n",
      "  Train: [56200/57525] ( 97.7%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:29\n",
      "  Train: [56300/57525] ( 97.9%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:27\n",
      "  Train: [56400/57525] ( 98.0%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:25\n",
      "  Train: [56500/57525] ( 98.2%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:23\n",
      "  Train: [56600/57525] ( 98.4%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:20\n",
      "  Train: [56700/57525] ( 98.6%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:18\n",
      "  Train: [56800/57525] ( 98.7%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:16\n",
      "  Train: [56900/57525] ( 98.9%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:14\n",
      "  Train: [57000/57525] ( 99.1%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:11\n",
      "  Train: [57100/57525] ( 99.3%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:09\n",
      "  Train: [57200/57525] ( 99.4%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:07\n",
      "  Train: [57300/57525] ( 99.6%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:05\n",
      "  Train: [57400/57525] ( 99.8%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:02\n",
      "  Train: [57500/57525] (100.0%) | Loss: 0.5934 | Speed: 44.5 batches/s | ETA: 00:00\n",
      "  Running validation...\n",
      "    Val: [  50/7191] (  0.7%)\n",
      "    Val: [ 100/7191] (  1.4%)\n",
      "    Val: [ 150/7191] (  2.1%)\n",
      "    Val: [ 200/7191] (  2.8%)\n",
      "    Val: [ 250/7191] (  3.5%)\n",
      "    Val: [ 300/7191] (  4.2%)\n",
      "    Val: [ 350/7191] (  4.9%)\n",
      "    Val: [ 400/7191] (  5.6%)\n",
      "    Val: [ 450/7191] (  6.3%)\n",
      "    Val: [ 500/7191] (  7.0%)\n",
      "    Val: [ 550/7191] (  7.6%)\n",
      "    Val: [ 600/7191] (  8.3%)\n",
      "    Val: [ 650/7191] (  9.0%)\n",
      "    Val: [ 700/7191] (  9.7%)\n",
      "    Val: [ 750/7191] ( 10.4%)\n",
      "    Val: [ 800/7191] ( 11.1%)\n",
      "    Val: [ 850/7191] ( 11.8%)\n",
      "    Val: [ 900/7191] ( 12.5%)\n",
      "    Val: [ 950/7191] ( 13.2%)\n",
      "    Val: [1000/7191] ( 13.9%)\n",
      "    Val: [1050/7191] ( 14.6%)\n",
      "    Val: [1100/7191] ( 15.3%)\n",
      "    Val: [1150/7191] ( 16.0%)\n",
      "    Val: [1200/7191] ( 16.7%)\n",
      "    Val: [1250/7191] ( 17.4%)\n",
      "    Val: [1300/7191] ( 18.1%)\n",
      "    Val: [1350/7191] ( 18.8%)\n",
      "    Val: [1400/7191] ( 19.5%)\n",
      "    Val: [1450/7191] ( 20.2%)\n",
      "    Val: [1500/7191] ( 20.9%)\n",
      "    Val: [1550/7191] ( 21.6%)\n",
      "    Val: [1600/7191] ( 22.3%)\n",
      "    Val: [1650/7191] ( 22.9%)\n",
      "    Val: [1700/7191] ( 23.6%)\n",
      "    Val: [1750/7191] ( 24.3%)\n",
      "    Val: [1800/7191] ( 25.0%)\n",
      "    Val: [1850/7191] ( 25.7%)\n",
      "    Val: [1900/7191] ( 26.4%)\n",
      "    Val: [1950/7191] ( 27.1%)\n",
      "    Val: [2000/7191] ( 27.8%)\n",
      "    Val: [2050/7191] ( 28.5%)\n",
      "    Val: [2100/7191] ( 29.2%)\n",
      "    Val: [2150/7191] ( 29.9%)\n",
      "    Val: [2200/7191] ( 30.6%)\n",
      "    Val: [2250/7191] ( 31.3%)\n",
      "    Val: [2300/7191] ( 32.0%)\n",
      "    Val: [2350/7191] ( 32.7%)\n",
      "    Val: [2400/7191] ( 33.4%)\n",
      "    Val: [2450/7191] ( 34.1%)\n",
      "    Val: [2500/7191] ( 34.8%)\n",
      "    Val: [2550/7191] ( 35.5%)\n",
      "    Val: [2600/7191] ( 36.2%)\n",
      "    Val: [2650/7191] ( 36.9%)\n",
      "    Val: [2700/7191] ( 37.5%)\n",
      "    Val: [2750/7191] ( 38.2%)\n",
      "    Val: [2800/7191] ( 38.9%)\n",
      "    Val: [2850/7191] ( 39.6%)\n",
      "    Val: [2900/7191] ( 40.3%)\n",
      "    Val: [2950/7191] ( 41.0%)\n",
      "    Val: [3000/7191] ( 41.7%)\n",
      "    Val: [3050/7191] ( 42.4%)\n",
      "    Val: [3100/7191] ( 43.1%)\n",
      "    Val: [3150/7191] ( 43.8%)\n",
      "    Val: [3200/7191] ( 44.5%)\n",
      "    Val: [3250/7191] ( 45.2%)\n",
      "    Val: [3300/7191] ( 45.9%)\n",
      "    Val: [3350/7191] ( 46.6%)\n",
      "    Val: [3400/7191] ( 47.3%)\n",
      "    Val: [3450/7191] ( 48.0%)\n",
      "    Val: [3500/7191] ( 48.7%)\n",
      "    Val: [3550/7191] ( 49.4%)\n",
      "    Val: [3600/7191] ( 50.1%)\n",
      "    Val: [3650/7191] ( 50.8%)\n",
      "    Val: [3700/7191] ( 51.5%)\n",
      "    Val: [3750/7191] ( 52.1%)\n",
      "    Val: [3800/7191] ( 52.8%)\n",
      "    Val: [3850/7191] ( 53.5%)\n",
      "    Val: [3900/7191] ( 54.2%)\n",
      "    Val: [3950/7191] ( 54.9%)\n",
      "    Val: [4000/7191] ( 55.6%)\n",
      "    Val: [4050/7191] ( 56.3%)\n",
      "    Val: [4100/7191] ( 57.0%)\n",
      "    Val: [4150/7191] ( 57.7%)\n",
      "    Val: [4200/7191] ( 58.4%)\n",
      "    Val: [4250/7191] ( 59.1%)\n",
      "    Val: [4300/7191] ( 59.8%)\n",
      "    Val: [4350/7191] ( 60.5%)\n",
      "    Val: [4400/7191] ( 61.2%)\n",
      "    Val: [4450/7191] ( 61.9%)\n",
      "    Val: [4500/7191] ( 62.6%)\n",
      "    Val: [4550/7191] ( 63.3%)\n",
      "    Val: [4600/7191] ( 64.0%)\n",
      "    Val: [4650/7191] ( 64.7%)\n",
      "    Val: [4700/7191] ( 65.4%)\n",
      "    Val: [4750/7191] ( 66.1%)\n",
      "    Val: [4800/7191] ( 66.8%)\n",
      "    Val: [4850/7191] ( 67.4%)\n",
      "    Val: [4900/7191] ( 68.1%)\n",
      "    Val: [4950/7191] ( 68.8%)\n",
      "    Val: [5000/7191] ( 69.5%)\n",
      "    Val: [5050/7191] ( 70.2%)\n",
      "    Val: [5100/7191] ( 70.9%)\n",
      "    Val: [5150/7191] ( 71.6%)\n",
      "    Val: [5200/7191] ( 72.3%)\n",
      "    Val: [5250/7191] ( 73.0%)\n",
      "    Val: [5300/7191] ( 73.7%)\n",
      "    Val: [5350/7191] ( 74.4%)\n",
      "    Val: [5400/7191] ( 75.1%)\n",
      "    Val: [5450/7191] ( 75.8%)\n",
      "    Val: [5500/7191] ( 76.5%)\n",
      "    Val: [5550/7191] ( 77.2%)\n",
      "    Val: [5600/7191] ( 77.9%)\n",
      "    Val: [5650/7191] ( 78.6%)\n",
      "    Val: [5700/7191] ( 79.3%)\n",
      "    Val: [5750/7191] ( 80.0%)\n",
      "    Val: [5800/7191] ( 80.7%)\n",
      "    Val: [5850/7191] ( 81.4%)\n",
      "    Val: [5900/7191] ( 82.0%)\n",
      "    Val: [5950/7191] ( 82.7%)\n",
      "    Val: [6000/7191] ( 83.4%)\n",
      "    Val: [6050/7191] ( 84.1%)\n",
      "    Val: [6100/7191] ( 84.8%)\n",
      "    Val: [6150/7191] ( 85.5%)\n",
      "    Val: [6200/7191] ( 86.2%)\n",
      "    Val: [6250/7191] ( 86.9%)\n",
      "    Val: [6300/7191] ( 87.6%)\n",
      "    Val: [6350/7191] ( 88.3%)\n",
      "    Val: [6400/7191] ( 89.0%)\n",
      "    Val: [6450/7191] ( 89.7%)\n",
      "    Val: [6500/7191] ( 90.4%)\n",
      "    Val: [6550/7191] ( 91.1%)\n",
      "    Val: [6600/7191] ( 91.8%)\n",
      "    Val: [6650/7191] ( 92.5%)\n",
      "    Val: [6700/7191] ( 93.2%)\n",
      "    Val: [6750/7191] ( 93.9%)\n",
      "    Val: [6800/7191] ( 94.6%)\n",
      "    Val: [6850/7191] ( 95.3%)\n",
      "    Val: [6900/7191] ( 96.0%)\n",
      "    Val: [6950/7191] ( 96.6%)\n",
      "    Val: [7000/7191] ( 97.3%)\n",
      "    Val: [7050/7191] ( 98.0%)\n",
      "    Val: [7100/7191] ( 98.7%)\n",
      "    Val: [7150/7191] ( 99.4%)\n",
      "\n",
      "  Epoch 05 Summary:\n",
      "    Train MSE (norm): 0.5934 | Val MSE (norm): 0.5745\n",
      "    Time: Train=21.5min, Val=0.9min, Total=22.5min\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "LEARNING_RATE = 2.2e-4\n",
    "WEIGHT_DECAY = 8e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH  = 512\n",
    "\n",
    "def iter_minibatches(indexes, batch_size=256, shuffle=True, epoch=None, use_normalized=True):\n",
    "    \"\"\"\n",
    "    Generate minibatches. If use_normalized=True, returns normalized targets.\n",
    "    \"\"\"\n",
    "    idx = np.asarray(indexes)\n",
    "    if shuffle:\n",
    "        if epoch is not None:\n",
    "            rng = np.random.default_rng(42 + epoch)\n",
    "        else:\n",
    "            rng = np.random.default_rng()\n",
    "        rng.shuffle(idx)\n",
    "    \n",
    "    target_array = y_norm if use_normalized else y\n",
    "    \n",
    "    for start in range(0, len(idx), batch_size):\n",
    "        mb = idx[start:start+batch_size]\n",
    "        yield (\n",
    "            torch.from_numpy(X_seq[mb]).to(device),           # (B, 4, 23) float32\n",
    "            torch.from_numpy(X_cell[mb]).long().to(device),   # (B,) int64\n",
    "            torch.from_numpy(X_ph[mb]).long().to(device),     # (B,) int64\n",
    "            torch.from_numpy(X_chr[mb]).long().to(device),    # (B,) int64\n",
    "            torch.from_numpy(X_strand[mb]).long().to(device), # (B,) int64\n",
    "            torch.from_numpy(X_screen[mb]).long().to(device), # (B,) int64\n",
    "            torch.from_numpy(target_array[mb]).to(device),    # (B,) float32\n",
    "        )\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_sum, n_train = 0.0, 0\n",
    "    batch_count = 0\n",
    "    total_train_batches = len(idx_train) // BATCH + (1 if len(idx_train) % BATCH != 0 else 0)\n",
    "    last_update_time = time.time()\n",
    "    \n",
    "    for seq, cl, ph, ch, st, scr, tgt_norm in iter_minibatches(idx_train, batch_size=BATCH, shuffle=True, epoch=epoch, use_normalized=True):\n",
    "        pred_norm = model(seq, cl, ph, ch, st, scr)\n",
    "        loss = criterion(pred_norm, tgt_norm)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_sum += loss.item() * tgt_norm.size(0)\n",
    "        n_train   += tgt_norm.size(0)\n",
    "        batch_count += 1\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if batch_count % 100 == 0 or (current_time - last_update_time) >= 30:\n",
    "            progress = (batch_count / total_train_batches) * 100\n",
    "            elapsed = current_time - epoch_start\n",
    "            batches_per_sec = batch_count / elapsed if elapsed > 0 else 0\n",
    "            eta_seconds = (total_train_batches - batch_count) / batches_per_sec if batches_per_sec > 0 else 0\n",
    "            eta_min = int(eta_seconds // 60)\n",
    "            eta_sec = int(eta_seconds % 60)\n",
    "            current_loss = train_sum / n_train if n_train > 0 else 0.0\n",
    "            \n",
    "            print(f\"  Train: [{batch_count:5d}/{total_train_batches}] ({progress:5.1f}%) | \"\n",
    "                  f\"Loss: {current_loss:.4f} | \"\n",
    "                  f\"Speed: {batches_per_sec:.1f} batches/s | \"\n",
    "                  f\"ETA: {eta_min:02d}:{eta_sec:02d}\", flush=True)\n",
    "            last_update_time = current_time\n",
    "\n",
    "    train_loss = train_sum / n_train if n_train > 0 else 0.0\n",
    "    train_time = time.time() - epoch_start\n",
    "    \n",
    "    print(\"  Running validation...\", flush=True)\n",
    "    val_start = time.time()\n",
    "    model.eval()\n",
    "    val_sum, n_val = 0.0, 0\n",
    "    val_batch_count = 0\n",
    "    total_val_batches = len(idx_val) // BATCH + (1 if len(idx_val) % BATCH != 0 else 0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq, cl, ph, ch, st, scr, tgt_norm in iter_minibatches(idx_val, batch_size=BATCH, shuffle=False, use_normalized=True):\n",
    "            pred_norm = model(seq, cl, ph, ch, st, scr)\n",
    "            loss = criterion(pred_norm, tgt_norm)\n",
    "            val_sum += loss.item() * tgt_norm.size(0)\n",
    "            n_val   += tgt_norm.size(0)\n",
    "            val_batch_count += 1\n",
    "            \n",
    "            if val_batch_count % 50 == 0:\n",
    "                val_progress = (val_batch_count / total_val_batches) * 100\n",
    "                print(f\"    Val: [{val_batch_count:4d}/{total_val_batches}] ({val_progress:5.1f}%)\", flush=True)\n",
    "\n",
    "    val_loss = val_sum / n_val if n_val > 0 else 0.0\n",
    "    val_time = time.time() - val_start\n",
    "    total_time = time.time() - epoch_start\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"\\n  Epoch {epoch:02d} Summary:\")\n",
    "    print(f\"    Train MSE (norm): {train_loss:.4f} | Val MSE (norm): {val_loss:.4f}\")\n",
    "    print(f\"    Time: Train={train_time/60:.1f}min, Val={val_time/60:.1f}min, Total={total_time/60:.1f}min\")\n",
    "    print(f\"{'='*60}\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'MSE': 0.38142815814306374, 'Pearson': 0.6516409461316826, 'Spearman': 0.5244778973105289, 'Accuracy': 0.6940650766902328}\n",
      "Test: {'MSE': 0.38301759073216407, 'Pearson': 0.6513514160595977, 'Spearman': 0.5244435260986505, 'Accuracy': 0.6938502223511529}\n"
     ]
    }
   ],
   "source": [
    "def mse_doc(yhat, y):\n",
    "    yhat = np.asarray(yhat, dtype=np.float64)\n",
    "    y    = np.asarray(y,    dtype=np.float64)\n",
    "    n = y.size\n",
    "    return float(np.sum((y - yhat)**2) / n)\n",
    "\n",
    "def pearson_doc(x, y):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    n      = x.size\n",
    "    sum_x  = np.sum(x)\n",
    "    sum_y  = np.sum(y)\n",
    "    sum_xy = np.sum(x * y)\n",
    "    sum_x2 = np.sum(x * x)\n",
    "    sum_y2 = np.sum(y * y)\n",
    "    denom = np.sqrt((n * sum_x2 - sum_x * sum_x) * (n * sum_y2 - sum_y * sum_y))\n",
    "    return float((n * sum_xy - sum_x * sum_y) / denom) if denom != 0.0 else 0.0\n",
    "\n",
    "def _ranks_avg(a):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    order = np.argsort(a, kind=\"mergesort\")\n",
    "    ranks = np.empty_like(order, dtype=np.float64)\n",
    "    sa = a[order]\n",
    "    diff = np.concatenate(([True], sa[1:] != sa[:-1], [True]))\n",
    "    idx = np.flatnonzero(diff)\n",
    "    for s, e in zip(idx[:-1], idx[1:]):\n",
    "        ranks[order[s:e]] = 0.5 * (s + e - 1) + 1.0\n",
    "    return ranks\n",
    "\n",
    "def spearman_doc(x, y):\n",
    "    rx = _ranks_avg(x)\n",
    "    ry = _ranks_avg(y)\n",
    "    d  = rx - ry\n",
    "    n  = rx.size\n",
    "    denom = n * (n * n - 1.0)\n",
    "    return float(1.0 - (6.0 * np.sum(d * d)) / denom) if denom != 0.0 else 0.0\n",
    "\n",
    "def accuracy_direction(yhat, y):\n",
    "    yhat = np.asarray(yhat, dtype=np.float64)\n",
    "    y    = np.asarray(y,    dtype=np.float64)\n",
    "    return float(np.mean((yhat >= 0) == (y >= 0)))\n",
    "\n",
    "@torch.no_grad()\n",
    "def preds_and_trues(indexes, batch_size=256):\n",
    "    \"\"\"\n",
    "    Get predictions and true values. Predictions are de-normalized from normalized space.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ps_norm, ys_norm = [], []\n",
    "    for seq, cl, ph, ch, st, scr, tgt_norm in iter_minibatches(indexes, batch_size=batch_size, shuffle=False, use_normalized=True):\n",
    "        out_norm = model(seq, cl, ph, ch, st, scr)\n",
    "        ps_norm.append(out_norm.detach().cpu().numpy())\n",
    "        ys_norm.append(tgt_norm.detach().cpu().numpy())\n",
    "    \n",
    "    yhat_norm = np.concatenate(ps_norm)\n",
    "    y_norm = np.concatenate(ys_norm)\n",
    "\n",
    "    yhat_real = yhat_norm * sigma + mu\n",
    "    y_real = y_norm * sigma + mu\n",
    "    \n",
    "    return yhat_real, y_real\n",
    "\n",
    "def eval_split(indexes):\n",
    "    yhat, y = preds_and_trues(indexes, batch_size=256)\n",
    "    return {\n",
    "        \"MSE\": mse_doc(yhat, y),\n",
    "        \"Pearson\": pearson_doc(yhat, y),\n",
    "        \"Spearman\": spearman_doc(yhat, y),\n",
    "        \"Accuracy\": accuracy_direction(yhat, y),\n",
    "    }\n",
    "\n",
    "print(\"Validation:\", eval_split(idx_val))\n",
    "print(\"Test:\",       eval_split(idx_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
